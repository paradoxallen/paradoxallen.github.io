<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>机器学习(五) 常见算法优缺点</title>
      <link href="/65434/"/>
      <url>/65434/</url>
      <content type="html"><![CDATA[<h4 id="前文传送"><a href="#前文传送" class="headerlink" title="前文传送"></a>前文传送</h4><p><a href="https://paradoxallen.github.io/9731/">机器学习(一) 算法介绍</a></p><p><a href="https://paradoxallen.github.io/9731/">机器学习(二) 模型调优</a></p><p><a href="https://paradoxallen.github.io/62602/">机器学习(三) 模型结果应用</a></p><p><a href="https://paradoxallen.github.io/21484/">机器学习(四) 常见算法优缺点</a></p><p>文章结构：</p><ul><li><p><strong>什么是感知器分类算法</strong></p></li><li><p><strong>在Python中实现感知器学习算法</strong></p></li></ul><p><em>在iris（鸢尾花）数据集上训练一个感知器模型</em></p><ul><li><strong>自适应线性神经元和融合学习</strong></li></ul><p><em>使用梯度下降方法来最小化损失函数</em></p><p><em>在Python中实现一个自适应的线性神经元</em></p><a id="more"></a><hr><h3 id="什么是感知器分类算法"><a href="#什么是感知器分类算法" class="headerlink" title="什么是感知器分类算法"></a><strong>什么是感知器分类算法</strong></h3><p>设想我们改变逻辑回归算法，“迫使”它只能输出-1或1抑或其他定值。在这种情况下，之前的逻辑函数‍‍g就会变成阈值函数sign：</p><p><img src="http://i4.bvimg.com/647637/5ceeec4c3896d4f6.png" alt=""></p><p><img src="http://i4.bvimg.com/647637/3a51f1d2122e938a.png" alt=""></p><p>如果我们令假设为hθ(x)=g(θTx)hθ(x)=g(θTx)，将其带入之前的迭代法中：</p><p><img src="http://i4.bvimg.com/647637/1ea8a43feab7ac88.png" alt=""></p><p>至此我们就得出了感知器学习算法。简单地来说，感知器学习算法是神经网络中的一个概念，单层感知器是最简单的神经网络，输入层和输出层直接相连。</p><p><img src="http://i4.bvimg.com/647637/8a3bcfa1b5cd38cd.png" alt=""></p><p>每一个输入端和其上的权值相乘，然后将这些乘积相加得到乘积和，这个结果与阈值相比较（一般为0），若大于阈值输出端就取1，反之，输出端取-1。</p><p>初始权重向量W=[0,0,0]，更新公式W(i)=W(i)+ΔW(i)；ΔW(i)=η<em>(y-y’)</em>X(i)； </p><p>η：学习率，介于[0,1]之间 </p><p>y：输入样本的正确分类 </p><p>y’：感知器计算出来的分类 </p><p>通过上面公式不断更新权值，直到达到分类要求。</p><p><img src="http://i4.bvimg.com/647637/3e5ea78692abac79.jpg" alt=""></p><p>初始化权重向量W，与输入向量做点乘，将结果与阈值作比较，得到分类结果1或-1。</p><hr><h3 id="在Python中实现感知器学习算法"><a href="#在Python中实现感知器学习算法" class="headerlink" title="在Python中实现感知器学习算法"></a><strong>在Python中实现感知器学习算法</strong></h3><p>下面直接贴上实现代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Perceptron(object):</span><br><span class="line">    &quot;&quot;&quot;Perceptron classifier.</span><br><span class="line"></span><br><span class="line">    Parameters</span><br><span class="line">    ------------</span><br><span class="line">    eta : float</span><br><span class="line">        Learning rate (between 0.0 and 1.0)</span><br><span class="line">    n_iter : int</span><br><span class="line">        Passes over the training dataset.</span><br><span class="line"></span><br><span class="line">    Attributes</span><br><span class="line">    -----------</span><br><span class="line">    w_ : 1d-array</span><br><span class="line">        Weights after fitting.</span><br><span class="line">    errors_ : list</span><br><span class="line">        Number of misclassifications (updates) in each epoch.</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, eta=0.01, n_iter=10):</span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line"></span><br><span class="line">    def fit(self, X, y):</span><br><span class="line">        &quot;&quot;&quot;Fit training data.</span><br><span class="line"></span><br><span class="line">        Parameters</span><br><span class="line">        ----------</span><br><span class="line">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span><br><span class="line">            Training vectors, where n_samples is the number of samples and</span><br><span class="line">            n_features is the number of features.</span><br><span class="line">        y : array-like, shape = [n_samples]</span><br><span class="line">            Target values.</span><br><span class="line"></span><br><span class="line">        Returns</span><br><span class="line">        -------</span><br><span class="line">        self : object</span><br><span class="line"></span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.w_ = np.zeros(1 + X.shape[1])</span><br><span class="line">        self.errors_ = []</span><br><span class="line"></span><br><span class="line">        for _ in range(self.n_iter):</span><br><span class="line">            errors = 0</span><br><span class="line">            for xi, target in zip(X, y):</span><br><span class="line">                update = self.eta * (target - self.predict(xi))</span><br><span class="line">                self.w_[1:] += update * xi</span><br><span class="line">                self.w_[0] += update</span><br><span class="line">                errors += int(update != 0.0)</span><br><span class="line">            self.errors_.append(errors)</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">    def net_input(self, X):</span><br><span class="line">        &quot;&quot;&quot;Calculate net input&quot;&quot;&quot;</span><br><span class="line">        return np.dot(X, self.w_[1:]) + self.w_[0]</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        &quot;&quot;&quot;Return class label after unit step&quot;&quot;&quot;</span><br><span class="line">        return np.where(self.net_input(X) &gt;= 0.0, 1, -1)</span><br></pre></td></tr></table></figure><p><strong>特别说明：</strong></p><p>学习速率η(eta)只有在权重（一般取值0或者很小的数）为非零值的时候，才会对分类结果产生作用。如果所有的权重都初始化为0，学习速率参数eta只影响权重向量的大小，而不影响其方向，为了使学习速率影响分类结果，权重需要初始化为非零值。需要更改的代码中的相应行在下面突出显示:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def __init__(self, eta=0.01, n_iter=50, random_seed=1): # add random_seed=1</span><br><span class="line">    ...</span><br><span class="line">    self.random_seed = random_seed # add this line</span><br><span class="line">def fit(self, X, y):</span><br><span class="line">    ...</span><br><span class="line">    # self.w_ = np.zeros(1 + X.shape[1]) ## remove this line</span><br><span class="line">    rgen = np.random.RandomState(self.random_seed) # add this line</span><br><span class="line">    self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1]) # add this line</span><br></pre></td></tr></table></figure></p><p><strong>在iris（鸢尾）数据集上训练一个感知器模型</strong></p><p><strong>读取iris数据集</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import collections</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(&apos;https://archive.ics.uci.edu/ml/&apos;</span><br><span class="line">        &apos;machine-learning-databases/iris/iris.data&apos;, header=None)</span><br><span class="line">print (df.head())</span><br><span class="line">print (&quot;\n&quot;)</span><br><span class="line">print (df.describe())</span><br><span class="line">print (&quot;\n&quot;)</span><br><span class="line">print (collections.Counter(df[4]))</span><br></pre></td></tr></table></figure></p><p>output：</p><p><img src="http://i4.bvimg.com/647637/a583bd20347fb68b.jpg" alt=""></p><p><strong>可视化iris数据</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 为了显示中文(这里是Mac的解决方法，其他的大家可以去百度一下)</span><br><span class="line">from matplotlib.font_manager import FontProperties</span><br><span class="line">font = FontProperties(fname=&apos;/System/Library/Fonts/STHeiti Light.ttc&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 选择 setosa and versicolor类型的花</span><br><span class="line">y = df.iloc[0:100, 4].values</span><br><span class="line">y = np.where(y == &apos;Iris-setosa&apos;, -1, 1)</span><br><span class="line"></span><br><span class="line"># 提取它们的特征 （sepal length and petal length）</span><br><span class="line">X = df.iloc[0:100, [0, 2]].values</span><br><span class="line"></span><br><span class="line"># 可视化数据，因为数据有经过处理，总共150行数据，1-50行是setosa花，51-100是versicolor花，101-150是virginica花</span><br><span class="line">plt.scatter(X[:50, 0], X[:50, 1],</span><br><span class="line">            color=&apos;red&apos;, marker=&apos;o&apos;, label=&apos;setosa&apos;)</span><br><span class="line">plt.scatter(X[50:100, 0], X[50:100, 1],</span><br><span class="line">            color=&apos;blue&apos;, marker=&apos;x&apos;, label=&apos;versicolor&apos;)</span><br><span class="line"></span><br><span class="line">plt.xlabel(&apos;sepal 长度 [cm]&apos;,FontProperties=font,fontsize=14)</span><br><span class="line">plt.ylabel(&apos;petal 长度 [cm]&apos;,FontProperties=font,fontsize=14)</span><br><span class="line">plt.legend(loc=&apos;upper left&apos;)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>output：</p><p><img src="http://i4.bvimg.com/647637/1420ac757d167952.png" alt=""></p><p><strong>训练感知器模型</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Perceptron是我们前面定义的感知器算法函数，这里就直接调用就好</span><br><span class="line">ppn = Perceptron(eta=0.1, n_iter=10)</span><br><span class="line"></span><br><span class="line">ppn.fit(X, y)</span><br><span class="line"></span><br><span class="line">plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker=&apos;o&apos;)</span><br><span class="line">plt.xlabel(&apos;迭代次数&apos;,FontProperties=font,fontsize=14)</span><br><span class="line">plt.ylabel(&apos;权重更新次数（错误次数）&apos;,FontProperties=font,fontsize=14)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>output：</p><p><img src="http://i4.bvimg.com/647637/0557d85f969d74b5.png" alt=""></p><p><strong>绘制函数决策区域</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib.colors import ListedColormap</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def plot_decision_regions(X, y, classifier, resolution=0.02):</span><br><span class="line"></span><br><span class="line">    # setup marker generator and color map</span><br><span class="line">    markers = (&apos;s&apos;, &apos;x&apos;, &apos;o&apos;, &apos;^&apos;, &apos;v&apos;)</span><br><span class="line">    colors = (&apos;red&apos;, &apos;blue&apos;, &apos;lightgreen&apos;, &apos;gray&apos;, &apos;cyan&apos;)</span><br><span class="line">    cmap = ListedColormap(colors[:len(np.unique(y))])</span><br><span class="line"></span><br><span class="line">    # plot the decision surface</span><br><span class="line">    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1</span><br><span class="line">    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1</span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),</span><br><span class="line">                           np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)</span><br><span class="line">    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)</span><br><span class="line">    plt.xlim(xx1.min(), xx1.max())</span><br><span class="line">    plt.ylim(xx2.min(), xx2.max())</span><br><span class="line"></span><br><span class="line">    # plot class samples</span><br><span class="line">    for idx, cl in enumerate(np.unique(y)):</span><br><span class="line">        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],</span><br><span class="line">                    alpha=0.8, c=cmap(idx),</span><br><span class="line">                    edgecolor=&apos;black&apos;,</span><br><span class="line">                    marker=markers[idx], </span><br><span class="line">                    label=cl)</span><br><span class="line">plot_decision_regions(X, y, classifier=ppn)</span><br><span class="line">plt.xlabel(&apos;sepal 长度 [cm]&apos;,FontProperties=font,fontsize=14)</span><br><span class="line">plt.ylabel(&apos;petal 长度 [cm]&apos;,FontProperties=font,fontsize=14)</span><br><span class="line">plt.legend(loc=&apos;upper left&apos;)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>output：</p><p><img src="http://i4.bvimg.com/647637/d0436f465dbb6d06.png" alt=""></p><hr><h3 id="自适应线性神经元和融合学习"><a href="#自适应线性神经元和融合学习" class="headerlink" title="自适应线性神经元和融合学习"></a><strong>自适应线性神经元和融合学习</strong></h3><p><strong>使用梯度下降方法来最小化损失函数</strong></p><p>梯度下降的方法十分常见，具体的了解可以参考附录的文章[2]，如今，梯度下降主要用于在神经网络模型中进行权重更新，即在一个方向上更新和调整模型的参数，来最小化损失函数。</p><p><img src="http://i4.bvimg.com/647637/09c54e58b0ce88f3.jpg" alt=""><br>图：梯度下降原理过程演示</p><p><strong>在Python中实现一个自适应的线性神经元</strong></p><p>先贴上定义的python函数，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"># 定义神经元函数</span><br><span class="line">class AdalineGD(object):</span><br><span class="line">    &quot;&quot;&quot;ADAptive LInear NEuron classifier.</span><br><span class="line"></span><br><span class="line">    Parameters</span><br><span class="line">    ------------</span><br><span class="line">    eta : float</span><br><span class="line">        Learning rate (between 0.0 and 1.0)</span><br><span class="line">    n_iter : int</span><br><span class="line">        Passes over the training dataset.</span><br><span class="line"></span><br><span class="line">    Attributes</span><br><span class="line">    -----------</span><br><span class="line">    w_ : 1d-array</span><br><span class="line">        Weights after fitting.</span><br><span class="line">    cost_ : list</span><br><span class="line">        Sum-of-squares cost function value in each epoch.</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, eta=0.01, n_iter=50):</span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line"></span><br><span class="line">    def fit(self, X, y):</span><br><span class="line">        &quot;&quot;&quot; Fit training data.</span><br><span class="line"></span><br><span class="line">        Parameters</span><br><span class="line">        ----------</span><br><span class="line">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span><br><span class="line">            Training vectors, where n_samples is the number of samples and</span><br><span class="line">            n_features is the number of features.</span><br><span class="line">        y : array-like, shape = [n_samples]</span><br><span class="line">            Target values.</span><br><span class="line"></span><br><span class="line">        Returns</span><br><span class="line">        -------</span><br><span class="line">        self : object</span><br><span class="line"></span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.w_ = np.zeros(1 + X.shape[1])</span><br><span class="line">        self.cost_ = []</span><br><span class="line"></span><br><span class="line">        for i in range(self.n_iter):</span><br><span class="line">            net_input = self.net_input(X)</span><br><span class="line">            # Please note that the &quot;activation&quot; method has no effect</span><br><span class="line">            # in the code since it is simply an identity function. We</span><br><span class="line">            # could write `output = self.net_input(X)` directly instead.</span><br><span class="line">            # The purpose of the activation is more conceptual, i.e.,  </span><br><span class="line">            # in the case of logistic regression, we could change it to</span><br><span class="line">            # a sigmoid function to implement a logistic regression classifier.</span><br><span class="line">            output = self.activation(X)</span><br><span class="line">            errors = (y - output)</span><br><span class="line">            self.w_[1:] += self.eta * X.T.dot(errors)</span><br><span class="line">            self.w_[0] += self.eta * errors.sum()</span><br><span class="line">            cost = (errors**2).sum() / 2.0</span><br><span class="line">            self.cost_.append(cost)</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">    def net_input(self, X):</span><br><span class="line">        &quot;&quot;&quot;Calculate net input&quot;&quot;&quot;</span><br><span class="line">        return np.dot(X, self.w_[1:]) + self.w_[0]</span><br><span class="line"></span><br><span class="line">    def activation(self, X):</span><br><span class="line">        &quot;&quot;&quot;Compute linear activation&quot;&quot;&quot;</span><br><span class="line">        return self.net_input(X)</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        &quot;&quot;&quot;Return class label after unit step&quot;&quot;&quot;</span><br><span class="line">        return np.where(self.activation(X) &gt;= 0.0, 1, -1)</span><br></pre></td></tr></table></figure></p><p><strong>查看不同学习率下的错误率随迭代次数的变化情况：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))</span><br><span class="line"></span><br><span class="line"># 可视化W调整的过程中，错误率随迭代次数的变化</span><br><span class="line">ada1 = AdalineGD(n_iter=10, eta=0.01).fit(X, y)</span><br><span class="line">ax[0].plot(range(1, len(ada1.cost_) + 1), np.log10(ada1.cost_), marker=&apos;o&apos;)</span><br><span class="line">ax[0].set_xlabel(&apos;Epochs&apos;)</span><br><span class="line">ax[0].set_ylabel(&apos;log(Sum-squared-error)&apos;)</span><br><span class="line">ax[0].set_title(&apos;Adaline - Learning rate 0.01&apos;)</span><br><span class="line"></span><br><span class="line">ada2 = AdalineGD(n_iter=10, eta=0.0001).fit(X, y)</span><br><span class="line">ax[1].plot(range(1, len(ada2.cost_) + 1), ada2.cost_, marker=&apos;o&apos;)</span><br><span class="line">ax[1].set_xlabel(&apos;Epochs&apos;)</span><br><span class="line">ax[1].set_ylabel(&apos;Sum-squared-error&apos;)</span><br><span class="line">ax[1].set_title(&apos;Adaline - Learning rate 0.0001&apos;)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>output：</p><p><img src="http://i4.bvimg.com/647637/71c5d16340efe1bc.png" alt=""></p><p><strong>iris数据的应用情况：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 标准化特征</span><br><span class="line">X_std = np.copy(X)</span><br><span class="line">X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()</span><br><span class="line">X_std[:, 1] = (X[:, 1] - X[:, 1].mean()) / X[:, 1].std()</span><br><span class="line"># 调用函数开始训练</span><br><span class="line">ada = AdalineGD(n_iter=15, eta=0.01)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line"># 绘制效果</span><br><span class="line">plot_decision_regions(X_std, y, classifier=ada)</span><br><span class="line">plt.title(&apos;Adaline - Gradient Descent&apos;)</span><br><span class="line">plt.xlabel(&apos;sepal length [standardized]&apos;)</span><br><span class="line">plt.ylabel(&apos;petal length [standardized]&apos;)</span><br><span class="line">plt.legend(loc=&apos;upper left&apos;)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"># 可视化W调整的过程中，错误率随迭代次数的变化</span><br><span class="line">plt.plot(range(1, len(ada.cost_) + 1), ada.cost_, marker=&apos;o&apos;)</span><br><span class="line">plt.xlabel(&apos;Epochs&apos;)</span><br><span class="line">plt.ylabel(&apos;Sum-squared-error&apos;)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>output：</p><p><img src="http://i4.bvimg.com/647637/505a411eac1ca35a.png" alt=""></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>1）<a href="https://blog.csdn.net/u013719780/article/details/51755409" target="_blank" rel="noopener">机器学习系列：感知器</a><br>2）<a href="https://blog.csdn.net/zyq522376829/article/details/66632699" target="_blank" rel="noopener">机器学习入门系列04，Gradient Descent（梯度下降法）</a><br>3）<a href="https://zhuanlan.zhihu.com/p/27449596?utm_source=weibo&amp;utm_medium=social" target="_blank" rel="noopener">一文看懂各种神经网络优化算法：从梯度下降到Adam方法</a><br>4）<a href="https://blog.csdn.net/huakai16/article/details/77701020" target="_blank" rel="noopener">机器学习与神经网络（三）：自适应线性神经元的介绍和Python代码实现</a><br>5）<a href="http://nbviewer.jupyter.org/github/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb" target="_blank" rel="noopener">《Training Machine Learning Algorithms for Classification》</a></p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习(四) 常见算法优缺点</title>
      <link href="/21484/"/>
      <url>/21484/</url>
      <content type="html"><![CDATA[<h4 id="前文传送"><a href="#前文传送" class="headerlink" title="前文传送"></a>前文传送</h4><p><a href="https://paradoxallen.github.io/9731/">机器学习(一) 算法介绍</a></p><p><a href="https://paradoxallen.github.io/9731/">机器学习(二) 模型调优</a></p><p><a href="https://paradoxallen.github.io/62602/">机器学习(三) 模型结果应用</a></p><p>机器学习算法我们了解了很多，但是放在一起来比较优缺点是缺少的，本篇文章就一些常见的算法来进行一次优缺点梳理。</p><a id="more"></a><hr><h3 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a><strong>决策树算法</strong></h3><h4 id="一、决策树优点"><a href="#一、决策树优点" class="headerlink" title="一、决策树优点"></a><strong>一、决策树优点</strong></h4><p>1、决策树易于理解和解释，可以可视化分析，容易提取出规则。</p><p>2、可以同时处理标称型和数值型数据。</p><p>3、测试数据集时，运行速度比较快。</p><p>4、决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。</p><h4 id="二、决策树缺点"><a href="#二、决策树缺点" class="headerlink" title="二、决策树缺点"></a><strong>二、决策树缺点</strong></h4><p>1、对缺失数据处理比较困难。</p><p>2、容易出现过拟合问题。</p><p>3、忽略数据集中属性的相互关联。</p><p>4、ID3算法计算信息增益时结果偏向数值比较多的特征。</p><h4 id="三、改进措施"><a href="#三、改进措施" class="headerlink" title="三、改进措施"></a><strong>三、改进措施</strong></h4><p>1、对决策树进行剪枝。可以采用交叉验证法和加入正则化的方法。</p><p>2、使用基于决策树的combination算法，如bagging算法，randomforest算法，可以解决过拟合的问题</p><h4 id="四、常见算法"><a href="#四、常见算法" class="headerlink" title="四、常见算法"></a><strong>四、常见算法</strong></h4><h5 id="一）C4-5算法"><a href="#一）C4-5算法" class="headerlink" title="一）C4.5算法"></a><strong>一）C4.5算法</strong></h5><p>ID3算法是以信息论为基础，以信息熵和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。</p><p>C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有：</p><ul><li><p>用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；</p></li><li><p>在树构造过程中进行剪枝；</p></li><li><p>能处理非离散的数据；</p></li><li><p>能处理不完整的数据。</p></li></ul><p><strong>优点</strong>：产生的分类规则易于理解，准确率较高。</p><p><strong>缺点</strong>：</p><p>1）在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效；</p><p>2）C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</p><h5 id="二）CART分类与回归树"><a href="#二）CART分类与回归树" class="headerlink" title="二）CART分类与回归树"></a><strong>二）CART分类与回归树</strong></h5><p>是一种决策树分类方法，采用基于最小距离的基尼指数估计函数，用来决定由该子数<br>据集生成的决策树的拓展形。如果目标变量是标称的，称为分类树；如果目标变量是连续的，称为回归树。分类树是使用树结构算法将数据分成离散类的方法。</p><p><strong>优点</strong></p><p>1）非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。</p><p>2）在面对诸如存在缺失值、变量数多等问题时CART 显得非常稳健。</p><hr><h3 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a><strong>分类算法</strong></h3><h4 id="一、KNN算法"><a href="#一、KNN算法" class="headerlink" title="一、KNN算法"></a><strong>一、KNN算法</strong></h4><p><strong>KNN算法的优点</strong> </p><p>1、KNN是一种在线技术，新数据可以直接加入数据集而不必进行重新训练</p><p>2、KNN理论简单，容易实现</p><p><strong>KNN算法的缺点</strong></p><p>1、对于样本容量大的数据集计算量比较大。</p><p>2、样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多。</p><p>3、KNN每一次分类都会重新进行一次全局运算。</p><p>4、k值大小的选择。</p><p><strong>KNN算法应用领域</strong></p><p>文本分类、模式识别、聚类分析，多分类领域</p><h4 id="二、支持向量机（SVM）"><a href="#二、支持向量机（SVM）" class="headerlink" title="二、支持向量机（SVM）"></a><strong>二、支持向量机（SVM）</strong></h4><p>支持向量机是一种基于分类边界的方法。其基本原理是（以二维数据为例）：如果训练数据分布在二维平面上的点，它们按照其分类聚集在不同的区域。基于分类边界的分类算法的目标是，通过训练，找到这些分类之间的边界（直线的――称为线性划分，曲线的――称为非线性划分）。对于多维数据（如N维），可以将它们视为N维空间中的点，而分类边界就是N维空间中的面，称为超面（超面比N维空间少一维）。线性分类器使用超平面类型的边界，非线性分类器使用超曲面。</p><p>支持向量机的原理是将低维空间的点映射到高维空间，使它们成为线性可分，再使用线性划分的原理来判断分类边界。在高维空间中是一种线性划分，而在原有的数据空间中，是一种非线性划分。</p><p><strong>SVM优点</strong></p><p>1、解决小样本下机器学习问题。<br>2、解决非线性问题。<br>3、无局部极小值问题。（相对于神经网络等算法）<br>4、可以很好的处理高维数据集。<br>5、泛化能力比较强。</p><p><strong>SVM缺点</strong></p><p>1、对于核函数的高维映射解释力不强，尤其是径向基函数。<br>2、对缺失数据敏感。</p><p><strong>SVM应用领域</strong></p><p>文本分类、图像识别、主要二分类领域</p><h4 id="三、朴素贝叶斯算法"><a href="#三、朴素贝叶斯算法" class="headerlink" title="三、朴素贝叶斯算法"></a><strong>三、朴素贝叶斯算法</strong></h4><p><strong>朴素贝叶斯算法优点</strong></p><p>1、对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已。<br>2、支持增量式运算。即可以实时的对新增的样本进行训练。<br>3、朴素贝叶斯对结果解释容易理解。</p><p><strong>朴素贝叶斯缺点</strong></p><p>1、由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。</p><p><strong>朴素贝叶斯应用领域</strong></p><p>文本分类、欺诈检测中使用较多</p><h4 id="四、Logistic回归算法"><a href="#四、Logistic回归算法" class="headerlink" title="四、Logistic回归算法"></a><strong>四、Logistic回归算法</strong></h4><p><strong>logistic回归优点</strong></p><p>1、计算代价不高，易于理解和实现</p><p><strong>logistic回归缺点</strong></p><p>1、容易产生欠拟合。</p><p>2、分类精度不高。</p><p><strong>logistic回归应用领域</strong></p><p>用于二分类领域，可以得出概率值，适用于根据分类概率排名的领域，如搜索排名等。</p><p>Logistic回归的扩展softmax可以应用于多分类领域，如手写字识别等。</p><hr><h3 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a><strong>聚类算法</strong></h3><h4 id="一、K-means-算法"><a href="#一、K-means-算法" class="headerlink" title="一、K means 算法"></a><strong>一、K means 算法</strong></h4><p>是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k&lt; n。 算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。<br>其中N为样本数，K是簇数，rnk b表示n属于第k个簇，uk 是第k个中心点的值。然后求出最优的uk</p><p><strong>优点</strong>：算法速度很快</p><p><strong>缺点</strong>：分组的数目k是一个输入参数，不合适的k可能返回较差的结果。</p><h4 id="二、EM最大期望算法"><a href="#二、EM最大期望算法" class="headerlink" title="二、EM最大期望算法"></a><strong>二、EM最大期望算法</strong></h4><p>EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。</p><p>EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。</p><hr><h3 id="集成算法（AdaBoost算法）"><a href="#集成算法（AdaBoost算法）" class="headerlink" title="集成算法（AdaBoost算法）"></a><strong>集成算法（AdaBoost算法）</strong></h3><h4 id="一、-AdaBoost算法优点"><a href="#一、-AdaBoost算法优点" class="headerlink" title="一、  AdaBoost算法优点"></a><strong>一、  AdaBoost算法优点</strong></h4><p>1、很好的利用了弱分类器进行级联。</p><p>2、可以将不同的分类算法作为弱分类器。</p><p>3、AdaBoost具有很高的精度。</p><p>4、相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重。</p><h4 id="二、Adaboost算法缺点"><a href="#二、Adaboost算法缺点" class="headerlink" title="二、Adaboost算法缺点"></a><strong>二、Adaboost算法缺点</strong></h4><p>1、AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定。</p><p>2、数据不平衡导致分类精度下降。</p><p>3、训练比较耗时，每次重新选择当前分类器最好切分点。</p><h4 id="三、AdaBoost应用领域"><a href="#三、AdaBoost应用领域" class="headerlink" title="三、AdaBoost应用领域"></a><strong>三、AdaBoost应用领域</strong></h4><p>模式识别、计算机视觉领域，用于二分类和多分类场景</p><hr><h3 id="人工神经网络算法"><a href="#人工神经网络算法" class="headerlink" title="人工神经网络算法"></a><strong>人工神经网络算法</strong></h3><h4 id="一、神经网络优点"><a href="#一、神经网络优点" class="headerlink" title="一、神经网络优点"></a><strong>一、神经网络优点</strong></h4><p>1、分类准确度高，学习能力极强。</p><p>2、对噪声数据鲁棒性和容错性较强。</p><p>3、有联想能力，能逼近任意非线性关系。</p><h4 id="二、神经网络缺点"><a href="#二、神经网络缺点" class="headerlink" title="二、神经网络缺点"></a><strong>二、神经网络缺点</strong></h4><p>1、神经网络参数较多，权值和阈值。</p><p>2、黑盒过程，不能观察中间结果。</p><p>3、学习过程比较长，有可能陷入局部极小值。</p><h4 id="三、人工神经网络应用领域"><a href="#三、人工神经网络应用领域" class="headerlink" title="三、人工神经网络应用领域"></a><strong>三、人工神经网络应用领域</strong></h4><p>目前深度神经网络已经应用与计算机视觉，自然语言处理，语音识别等领域并取得很好的效果。</p><hr><h3 id="排序算法（PageRank）"><a href="#排序算法（PageRank）" class="headerlink" title="排序算法（PageRank）"></a><strong>排序算法（PageRank）</strong></h3><p>PageRank是google的页面排序算法，是基于从许多优质的网页链接过来的网页，必定还是优质网页的回归关系，来判定所有网页的重要性。（也就是说，一个人有着越多牛X朋友的人，他是牛X的概率就越大。）</p><h4 id="一、PageRank优点"><a href="#一、PageRank优点" class="headerlink" title="一、PageRank优点"></a><strong>一、PageRank优点</strong></h4><p>完全独立于查询，只依赖于网页链接结构，可以离线计算。</p><h4 id="二、PageRank缺点"><a href="#二、PageRank缺点" class="headerlink" title="二、PageRank缺点"></a><strong>二、PageRank缺点</strong></h4><p>1）PageRank算法忽略了网页搜索的时效性。</p><p>2）旧网页排序很高，存在时间长，积累了大量的in-links，拥有最新资讯的新网页排名却很低，因为它们几乎没有in-links。</p><hr><h3 id="关联规则算法（Apriori算法）"><a href="#关联规则算法（Apriori算法）" class="headerlink" title="关联规则算法（Apriori算法）"></a><strong>关联规则算法（Apriori算法）</strong></h3><p>Apriori算法是一种挖掘关联规则的算法，用于挖掘其内含的、未知的却又实际存在的数据关系，其核心是基于两阶段频集思想的递推算法 。</p><p><strong>Apriori算法分为两个阶段：</strong></p><p>1）寻找频繁项集</p><p>2）由频繁项集找关联规则</p><p><strong>算法缺点：</strong></p><p>1）在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素；</p><p>2） 每次计算项集的支持度时，都对数据库中    的全部记录进行了一遍扫描比较，需要很大的I/O负载。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1）Jason Brownlee  《How To Use Machine Learning Results》</p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习(三) 模型结果应用</title>
      <link href="/62602/"/>
      <url>/62602/</url>
      <content type="html"><![CDATA[<h4 id="前文传送"><a href="#前文传送" class="headerlink" title="前文传送"></a>前文传送</h4><p><a href="https://paradoxallen.github.io/9731/">机器学习(一) 算法介绍</a></p><p><a href="https://paradoxallen.github.io/9731/">机器学习(二) 模型调优</a></p><p>当你有了一个相当不错的模型结果了，这个时间就需要上线应用了，但实际上这个过程也是需要注意很多东西的呢，比如汇报你的项目结果、上线计划沟通、上线后的监控等等，这都是相当重要的。</p><a id="more"></a><hr><p>永远要记得，建立模型只是为了解决业务问题，<strong>模型只是一个工具而已</strong>，所以，脱离具体业务场景的模型都是假的。所以，在一开始，就要对自己的目标进行明确，在做完了模型后再度审视自己目标，看下自己做出来的模型是否仍是解决这个目标。</p><p>根据你试图解决的问题类型，我们可以大致分为两种呈现方式：</p><ul><li><p><strong>报告汇报式</strong></p></li><li><p><strong>部署上线式</strong></p></li></ul><p>当然了，实际上更多的是两种方式的融合，即两个都需要做，那么下面我们就分别来说一下这两种方式在实际操作上都需要做些什么呗。</p><h2 id="报告汇报式"><a href="#报告汇报式" class="headerlink" title="报告汇报式"></a>报告汇报式</h2><p>一旦你发现了一个很不错的模型，并且训练的结果也很不错，你此时就需要总结这一切内容，并很好的展示给你的观众（可以是老板、客户或者是同事等），而此时如何完美地展示显得格外重要。</p><p>展示的最好方式我个人觉得是ppt，但有些地方更偏好于单页报告，不过也不影响，下面罗列的内容，都是可以在这两种方式内容上展示的，不管你现在做的模型是什么，比赛的、教程的，还是工作的，都可以试着去总结这些关键点，完成一次报告的撰写。</p><ul><li><p><strong><em>Context</em></strong> (Why): 定义问题存在的大背景，并且说明研究的动机或目的。</p></li><li><p><strong><em>Problem</em></strong> (Question): 简单扼要地把问题描述一个具体需要解决的问题并回答它。</p></li><li><p><strong><em>Solution</em></strong> (Answer): 简单扼要地描述关于上一个环节提出的问题的解决方案，而且要详细具体。</p></li><li><p><strong><em>Findings</em></strong>: 罗列一下你在建模过程中发现的一些有价值的点，比如在数据上的发现，又或者是原先方式的缺点及现有方式的优点，也可以是模型在性能方面的优势等等。</p></li><li><p><strong><em>Limitations</em></strong>: 考虑模型能力所不能覆盖的点，或者是方案不能解决的点。不要回避这些问题，你不说别人也会问，而且，只有你重新认识模型的短处，才能知道模型的优点。</p></li><li><p><strong><em>Conclusions</em></strong> (Why+Question+Answer): 回顾目的、研究的问题及解决方案，并将它们尽可能压缩在几句话，让人能够记住。</p></li></ul><p>如果是自己平时做练习的项目，我觉得可以多按照上面的点来描述自己的项目结果，并且将报告上传到社区网络，让更多的人来评价，你从中也可以得到更多的反馈，这对你下一次的报告有很大的帮助。</p><h2 id="部署上线式"><a href="#部署上线式" class="headerlink" title="部署上线式"></a>部署上线式</h2><p>同样的，你有一个训练得很不错的模型，这时候需要将它部署到生产系统中，你需要确定很多东西，比如调用的环节、入参出参以及各种接口开发，下面有3个方面的内容需要在做这些事情之前进行考虑，分别是：<strong>算法实现、模型自动化测试、模型效果追踪</strong>。</p><p><strong>1）算法实现</strong></p><p>其实python里有很多算法都是可以直接通过库来调用的，但这对于一般情况下是很好用的，但是如果涉及到要具体部署应用，这要考虑的东西就多了。</p><p>在你考虑部署一个新模型在现有的生产系统上，你需要非常仔细地研究这可能需要产生的依赖项和“技术负债”（这里可以理解为一些所需的技术，包括硬软件）。所以，在建模前，需要考虑去查找能匹配你的方法的公司生产级别的库，要不然，等到要上线的时候，你就需要重复模型调优的过程了哦。</p><p><strong>2）模型自动化测试</strong></p><p>编写自动化测试代码，对模型的应用进行验证，监控在实际的使用过程中，并且能够重复实现模型效果的最低水平，尽可能是可以对不同的数据都可以随机性地测试。</p><p><strong>3）模型效果追踪</strong></p><p>增添一些基础设施来监控模型的性能，并且可以在精度低于最低水平的时候发出警报，追踪模型实时或者离线的数据样本的效果，包括入参。当你发现不仅仅是模型效果发生了很大的变化，就连入参也有很大的变化，那这个时候就需要考虑模型的更新或者重构了。</p><p>当然，有一些模型是可以实现在线自我学习并且更新自己的，但并不是所有的生产系统可以支持这种操作，毕竟这种还只是一个比较先进的办法，仍存在很多不太完善的地方。比较传统的方式还是对现有的模型进行人工管理，人工更新与切换，这样子显得更加明智而且稳健。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1）Jason Brownlee  《How To Use Machine Learning Results》</p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 模型 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习(二) 模型调优</title>
      <link href="/4840/"/>
      <url>/4840/</url>
      <content type="html"><![CDATA[<h4 id="前文传送"><a href="#前文传送" class="headerlink" title="前文传送"></a>前文传送</h4><p><a href="https://paradoxallen.github.io/9731/">机器学习(一)算法介绍</a></p><p>前面讲了一些机器学习的算法的介绍，如果有一些数据这时候也可以建立出自己的模型了，但是，如果模型的效果不尽人意，那么应该如何调整呢？</p><p>以下是一份关于模型调优的方法，每当出现效果不好的时候或者是在建模前，都可以按照这个来进行检查，话不多说，一起来看～</p><p><img src="http://i2.bvimg.com/647637/9208883f4c7aeb45.jpg" alt=""></p><a id="more"></a><hr><p>为了文章阅读的清晰，先在前面简单说明一下文章的目录框架。</p><p>本文存在的意义在于辅助大家提升机器学习模型的效果，方法有很多，如果你在其中的一个办法中找到了突破，仍可以回头再找其他，直到满足你的模型效果要求，主要从4个角度来进行方法的阐述，分别是：</p><ul><li>Improve Performance With Data.（数据）</li><li>Improve Performance With Algorithms.（算法选择）</li><li>Improve Performance With Algorithm Tuning.（算法调优）</li><li>Improve Performance With Ensembles.（效果集成）</li></ul><p>好的，下面就分别从这4个角度来说一下。</p><h3 id="1-Improve-Performance-With-Data（数据）"><a href="#1-Improve-Performance-With-Data（数据）" class="headerlink" title="1. Improve Performance With Data（数据）"></a>1. Improve Performance With Data（数据）</h3><p>事实上，你直接改变训练数据或者改变目标的定义，好效果会来得更加“不费吹灰之力”，有的时候还可能是最好的操作，所以有一句话说得很有道理：<strong>选择比努力重要哈哈哈</strong>。</p><p>话不多说，说下Strategy: 创建不同的目标样本并且尽量使用最底层的特征来训练模型算法。</p><p><strong>具体策略：</strong></p><p>获得更多的数据：一个好的深度学习模型需要更多的数据来训练，其他非线性的机器学习模型也是如此。</p><ul><li>开发更多变量：如果你实在不能获得更多的数据亦或是更好质量的数据，也许可以通过概率模型、统计模型来生成新的变量。</li><li>清洗数据：通过数据清洗，你可以对缺失值、异常值进行合理的填补与修复，从而提升数据整体的质量。</li><li>重新采样数据：其实可以通过对数据的重新采样来改变数据的分布和大小。对某一特定类型的样本进行采样，说不定可以更好滴表现出效果。又或者是使用更小的数据，从而加快速度。</li><li>问题解决思路的重新思考：有的时候，你可以把你目前正在“焦头烂耳”想要解决的“预测性”问题，换成回归、分类、时间序列、异常检测、排序、推荐等等的问题。</li><li>调整变量再入模：这里指的是对数据进行离散化、标准化等的操作。</li><li>改变现有的变量：这里相信大家也很常见，就是对变量进行对数转换或指数转换，让其特性能更好地表现。</li><li>对变量进行降维：有的时候降维后的变量有更好的表现哦。</li><li>特征选择：这个就是特征工程了，简单来说，就是你对特征（变量）进行重要性的排序，选择相对预测力强的特征进入模型。</li></ul><h3 id="2-Improve-Performance-With-Algorithms（算法选择）"><a href="#2-Improve-Performance-With-Algorithms（算法选择）" class="headerlink" title="2. Improve Performance With Algorithms（算法选择）"></a>2. Improve Performance With Algorithms（算法选择）</h3><p>机器学习其实都是关于算法的学习。</p><p>Strategy: 识别出优于平均值的算法，但要对其实验过程以及结果抱着怀疑态度，并反复思考。</p><p><strong>具体策略：</strong></p><ul><li>重采样方法：使用什么方法来估计效果？有个原则就是要充分利用可用的数据来验证，这里，k-fold交叉验证方法可以是最好的哦。</li><li>评价指标：不同的目标需要使用不同的评价指标，这个相信大家在学习混淆矩阵的时候应该有所了解，什么pv+，命中率等等，都是对于特定类型的目标有着非常有效的识别。如果是一个排序性的问题，而你却用了准确度的指标来衡量模型的好坏似乎也说不过去把？</li><li>关注线性算法：线性算法通常会不那么好用，但是却更好地被人类理解且可以快速测试，如果你发现某个线性算法表现地还行，请继续优化它。</li><li>关注非线性算法：非线性算法往往会需要更多的数据，通过更加复杂的计算来获得一个不错的效果。</li><li>从文献中找ideas：这个方法还经常做，从文献中可以了解到更多的经典算法在特定需要下的应用，通过对文献的阅读来扩充你的“解题”思路把。</li></ul><h3 id="3-Improve-Performance-With-Algorithm-Tuning（算法调优）"><a href="#3-Improve-Performance-With-Algorithm-Tuning（算法调优）" class="headerlink" title="3. Improve Performance With Algorithm Tuning（算法调优）"></a>3. Improve Performance With Algorithm Tuning（算法调优）</h3><p>模型调参也是一个非常费时间的环节，有的时候“好运”可以马上抽查出表现还不错的结果，并持续调参，就可以得到一个不错的结果。但如果要对其他所有的算法进行优化，那么需要的时间就可能是几天、几个星期或者几个月了。</p><p>Strategy: 充分利用性能良好的机器学习算法。</p><p><strong>具体策略：</strong></p><ul><li>诊断方法：不同的算法需要提供不同的可视化和诊断的方法。</li><li>调参的直觉：这个就很“玄学”了，但其实都是一些经验，当你调的参足够多，也可以大致可以对这些不同算法的参数有了自己的理解，自然就有了这些所谓的“直觉”。</li><li>随机搜索：在N维参数空间按某种分布（如正态分布）随机取值，因为参数空间的各个维度的重要性是不等的，随机搜索方法可以在不重要的维度上取巧。</li><li>网格搜索：先固定一个超参，然后对其他各个超参依次进行穷举搜索。</li><li>从文献中找ideas：从文献中了解这个算法用到了哪些算法，并且这些算法主要的取值值域，有益于自身工作的开展哦。</li><li>从知名网站中找ideas：国内我个人觉得知乎还是蛮可以的，关于这节的参数调参，也是有好多好文章，其外还有csdn也不错。</li></ul><h3 id="4-Improve-Performance-With-Ensembles（效果集成）"><a href="#4-Improve-Performance-With-Ensembles（效果集成）" class="headerlink" title="4. Improve Performance With Ensembles（效果集成）"></a>4. Improve Performance With Ensembles（效果集成）<code></code></h3><p>这个算法集成的方法也是非常常用的，你可以结合多个模型的结果，综合输出一个更加稳定且效果不错的结果。</p><p>Strategy: 结合各种模型的预测结果并输出。</p><p><strong>具体策略：</strong></p><ul><li>混合模型的预测值：你可以把多个模型的预测结果结合起来，你可以将多个训练效果还不错的模型的预测结合综合起来，输出一个“平均”结果。</li><li>混合不同数据的预测值：你也可以把不同的数据集训练出来模型的结果进行结合，作为一个输出。（这个与上面的区别在于数据集的特征不同）</li><li>混合数据样本：很拗口，其实意思就是将数据集拆分成不同的子数据集，用于训练同一个算法，最后输出综合的预测结果。这个也被称之为bootstrap aggregation 或 bagging。</li><li>使用模型的方法集成：你也可以使用一个新的模型来学习如何结合多个性能不错的模型结果，输出一个最优的结合。这被称之为堆叠泛化或叠加，通常在子模型有技巧时很有效，但在不同的方式下，聚合器模型是预测的一个简单的线性加权。这个过程可以重复多层深度。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>1）<a href="https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/" target="_blank" rel="noopener">A Tour of Machine Learning Algorithms</a></p><p>2）<a href="https://www.zhihu.com/question/34470160?sort=created" target="_blank" rel="noopener">机器学习各种算法怎么调参?</a></p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 模型 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习(一) 算法介绍</title>
      <link href="/9731/"/>
      <url>/9731/</url>
      <content type="html"><![CDATA[<p>前阵子阅读了院里一位博士研究生师兄的一篇有关基于神经网络算法对北京近五年的常规探空数据进行自组织分类，并揭示出大气污染物在不同边界层结构下的演变规律和相关机制的文章<a href="https://www.atmos-chem-phys.net/18/6771/2018/" target="_blank" rel="noopener">《Self-organized classification of boundary layer meteorology and associated characteristics of air quality in Beijing》</a>，看完顿时心生膜拜之情；然后恰巧也是那个时候吕教授在院群上也转发了一篇关于机器学习预测火势甚至天气的公众号文章<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODE1NDYyMA==&amp;mid=2653384819&amp;idx=2&amp;sn=523f27cb9442ab4af27137edd1280248&amp;chksm=bd1cc8608a6b4176d7cae939f794e082cf86b5bf0ac0deb53790f507f563f588b2148687957c&amp;mpshare=1&amp;scene=1&amp;srcid=0517RYcQWk5dWJCcqoI7jLCe#rd" target="_blank" rel="noopener">《机器学习成功解决“蝴蝶效应”！以后你终于可以相信天气预报了》</a>。</p><p>如此的机缘巧合，我自己也想在这一方向进行深入了解，从基本的概述理论方法开始。</p><a id="more"></a><hr><p>算法很多，如何做好分组有助于我们更好记住它们，主要有2条算法分组的方式：</p><ul><li><p>The first is a grouping of algorithms by the learning style.（通过算法的学习方式）</p></li><li><p>The second is a grouping of algorithms by similarity in form or function (like grouping similar animals together).（通过算法的功能）</p></li></ul><p>下面就会从这2个角度来阐述一下机器学习的算法。</p><p><img src="http://i4.bvimg.com/647637/c8333c245bbeada6.png" alt=""></p><h2 id="Algorithms-Grouped-by-Learning-Style（通过算法的学习方式）"><a href="#Algorithms-Grouped-by-Learning-Style（通过算法的学习方式）" class="headerlink" title="Algorithms Grouped by Learning Style（通过算法的学习方式）"></a>Algorithms Grouped by Learning Style（通过算法的学习方式）</h2><p>关于机器学习算法，有三种不同的学习方式：</p><h3 id="1-Supervised-Learning（监督学习）"><a href="#1-Supervised-Learning（监督学习）" class="headerlink" title="1. Supervised Learning（监督学习）"></a>1. Supervised Learning（监督学习）</h3><p>当输入的数据集（我们称之为训练集）的数据有标签，如好坏标签，分类标签等，那么通过这些数据来建立的预测或者分类模型，属于监督学习模型。</p><ul><li><p>经典问题：classification and regression.（分类与回归）</p></li><li><p>经典算法：Logistic Regression and the Back Propagation Neural Network.（逻辑回归算法与BP神经网络算法）</p></li></ul><p><img src="http://i4.bvimg.com/647637/98402ff904a2e723.png" alt=""></p><h3 id="2-Unsupervised-Learning（无监督学习）"><a href="#2-Unsupervised-Learning（无监督学习）" class="headerlink" title="2. Unsupervised Learning（无监督学习）"></a>2. Unsupervised Learning（无监督学习）</h3><p>与监督学习相反，训练集中的数据并没有标签，这意味着你需要从这堆没有标签的数据中去提炼它们的特点规则等等，可能是通过数学推理过程来系统地减少冗余，又或者是通过数据相似度来组织数据。</p><ul><li><p>经典问题：clustering, dimensionality reduction and association rule learning.（聚类、降维、规则学习）</p></li><li><p>经典算法：the Apriori algorithm and k-Means.（这个专用名词就不翻译了）</p></li></ul><p><img src="http://i4.bvimg.com/647637/1559c4d4bbbd73c2.png" alt=""></p><h3 id="3-Semi-Supervised-Learning（半监督学习）"><a href="#3-Semi-Supervised-Learning（半监督学习）" class="headerlink" title="3. Semi-Supervised Learning（半监督学习）"></a>3. Semi-Supervised Learning（半监督学习）</h3><p>顾名思义，半监督学习意味着训练数据有一部分有标签，而一些没有，一般而言，当训练数据量过少时，监督学习得到的模型效果不能满足需求，因此用半监督学习来增强效果。</p><ul><li><p>经典问题：classification and regression.</p></li><li><p>经典算法：半监督SVM，高斯模型，KNN模型</p></li></ul><p><img src="http://i4.bvimg.com/647637/fc0034f6bf008c55.png" alt=""></p><h2 id="Algorithms-Grouped-By-Similarity（通过算法的功能）"><a href="#Algorithms-Grouped-By-Similarity（通过算法的功能）" class="headerlink" title="Algorithms Grouped By Similarity（通过算法的功能）"></a>Algorithms Grouped By Similarity（通过算法的功能）</h2><p>根据算法的功能相似性来区分算法也是一种很好的办法，如基于树结构的算法或者基于神经网络的算法。所以我觉得从这个角度来了解这些算法会更加好。<br>即便这是一个很好的方式，但也绝非完美，仍会有一些算法不能简单地被归类，比如Learning Vector Quantization（LVQ，学习矢量量化算法），它既是神经网络，也是基于距离的算法，所以下面的归类也只是适用于大多数算法，但是常用的算法。</p><h3 id="1-Regression-Algorithms（回归算法）"><a href="#1-Regression-Algorithms（回归算法）" class="headerlink" title="1. Regression Algorithms（回归算法）"></a>1. Regression Algorithms（回归算法）</h3><p>回归更多地关注自变量与因变量之间的关系，并通过对误差的测算来建模，回归算法是对于数学统计的一个很好应用，也被纳入统计机器学习中。</p><p>常见的回归算法包括：</p><ul><li><p>Ordinary Least Squares Regression (OLSR，普通最小二乘回归)</p></li><li><p>Linear Regression（线性回归）</p></li><li><p>Logistic Regression（逻辑回归）</p></li><li><p>Stepwise Regression（逐步回归）</p></li><li><p>Adaptive Regression Splines (MARS，多元自适应回归)</p></li><li><p>Locally Estimated Scatterplot Smoothing (LOESS，本地散点平滑估计)</p></li></ul><p><img src="http://i4.bvimg.com/647637/7d5edfbfdacf0ce5.png" alt=""></p><h3 id="2-Instance-based-Algorithms（基于距离的算法）"><a href="#2-Instance-based-Algorithms（基于距离的算法）" class="headerlink" title="2. Instance-based Algorithms（基于距离的算法）"></a>2. Instance-based Algorithms（基于距离的算法）</h3><p>基于距离学习的模型非常常见，这类的模型是对训练集数据进行建模并比较新数据与之的距离，而距离的衡量有很多，常见的是欧氏距离、曼哈顿距离等。</p><p>常见的算法包括：</p><ul><li><p>k-Nearest Neighbor (kNN)</p></li><li><p>Learning Vector Quantization (LVQ，学习矢量量化)</p></li><li><p>Self-Organizing Map (SOM，自组织映射)</p></li><li><p>Locally Weighted Learning (LWL，局部加权学习)</p></li></ul><p><img src="http://i4.bvimg.com/647637/7bde9d592d1937db.png" alt=""></p><h3 id="3-Regularization-Algorithms（正则化算法）"><a href="#3-Regularization-Algorithms（正则化算法）" class="headerlink" title="3. Regularization Algorithms（正则化算法）"></a>3. Regularization Algorithms（正则化算法）</h3><p>正则化是对另一种方法(通常是回归方法)的扩展，使基于其复杂性的模型受到惩罚，支持更简单的模型，这些模型在泛化能力方面也比较好。</p><p>常见的正则化算法包括：<br>Ridge Regression（岭回归算法）<br>Least Absolute Shrinkage and Selection Operator (LASSO算法，稀疏约束)<br>Elastic Net（弹性网络）<br>Least-Angle Regression (LARS，最小角回归算法)</p><p><img src="http://i4.bvimg.com/647637/c6951c24ab35ec34.png" alt=""></p><h3 id="4-Decision-Tree-Algorithms（决策树算法）"><a href="#4-Decision-Tree-Algorithms（决策树算法）" class="headerlink" title="4. Decision Tree Algorithms（决策树算法）"></a>4. Decision Tree Algorithms（决策树算法）</h3><p>决策树方法构建基于数据中属性的实际值来建模的，决策树经常被训练用于分类和回归问题，决策树通常是快速和准确的，并且是机器学习中最受欢迎的。</p><p>常见的决策树算法包括：</p><ul><li><p>Classification and Regression Tree (CART，分类回归树算法)</p></li><li><p>Iterative Dichotomiser 3 (ID3)</p></li><li><p>C4.5 and C5.0 (不同版本的区别)</p></li><li><p>Chi-squared Automatic Interaction Detection (CHAID)</p></li><li><p>Decision Stump（决策树桩）</p></li><li><p>MD5（Message-Digest Algorithm，讯息摘要算法）</p></li><li><p>Decision Trees（条件决策树）</p></li></ul><p><img src="http://i4.bvimg.com/647637/822d6578c331ab38.png" alt=""></p><h3 id="5-Bayesian-Algorithms（贝叶斯算法）"><a href="#5-Bayesian-Algorithms（贝叶斯算法）" class="headerlink" title="5. Bayesian Algorithms（贝叶斯算法）"></a>5. Bayesian Algorithms（贝叶斯算法）</h3><p>基于贝叶斯定理的方式来构建的算法，常用语分类与回归问题。</p><p>常见的贝叶斯算法包括：</p><ul><li><p>Naive Bayes（朴素贝叶斯）</p></li><li><p>Gaussian Naive Bayes（高斯朴素贝叶斯）</p></li><li><p>Multinomial Naive Bayes（多项式朴素贝叶斯）</p></li><li><p>Averaged One-Dependence Estimators (AODE)</p></li><li><p>Belief Network (BBN，贝叶斯定理网络)</p></li><li><p>Bayesian Network (BN，贝叶斯网络)</p></li></ul><p><img src="http://i4.bvimg.com/647637/1c88f6233fffff9c.png" alt=""></p><h3 id="6-Clustering-Algorithms（聚类算法）"><a href="#6-Clustering-Algorithms（聚类算法）" class="headerlink" title="6. Clustering Algorithms（聚类算法）"></a>6. Clustering Algorithms（聚类算法）</h3><p>聚类分析又称群分析，它是研究（样品或指标）分类问题的一种统计分析方法，同时也是数据挖掘的一个重要算法。<br>聚类（Cluster）分析是由若干模式（Pattern）组成的，通常，模式是一个度量（Measurement）的向量，或者是多维空间中的一个点。<br>聚类分析以相似性为基础，在一个聚类中的模式之间比不在同一聚类中的模式之间具有更多的相似性。</p><p>常见的聚类算法包括：<br>k-Means<br>k-Medians<br>Expectation Maximisation (EM，Expectation Maximization Algorithm，是一种迭代算法)<br>Hierarchical Clustering（层次聚类）</p><p><img src="http://i4.bvimg.com/647637/ffcd3a96458da550.png" alt=""></p><h3 id="7-Association-Rule-Learning-Algorithms（关联规则学习算法）"><a href="#7-Association-Rule-Learning-Algorithms（关联规则学习算法）" class="headerlink" title="7. Association Rule Learning Algorithms（关联规则学习算法）"></a>7. Association Rule Learning Algorithms（关联规则学习算法）</h3><p>关联规则学习方法提取的规则最能解释数据中变量之间的关系，这些规则可以在大型多维数据集中发现重要和商业有用的关联，而被组织利用。</p><p>最常见的算法包括：</p><ul><li><p>Apriori algorithm</p></li><li><p>Eclat algorithm</p></li></ul><p><img src="http://i4.bvimg.com/647637/862e1ef2bd8cb2b6.png" alt=""></p><h3 id="8-Artificial-Neural-Network-Algorithms（人工神经网络算法）"><a href="#8-Artificial-Neural-Network-Algorithms（人工神经网络算法）" class="headerlink" title="8. Artificial Neural Network Algorithms（人工神经网络算法）"></a>8. Artificial Neural Network Algorithms（人工神经网络算法）</h3><p>人工神经网络是受生物神经网络结构和/或功能启发的模型，它们是一类模式匹配，通常用于回归和分类问题，但实际上是一个巨大的子字段，包含数百种算法和各种类型的问题类型。</p><p>最常见的算法包括：</p><ul><li><p>Perceptron（感知器）</p></li><li><p>Back-Propagation（反向传播法）</p></li><li><p>Hopfield Network（霍普菲尔网络）</p></li><li><p>Radial Basis Function Network (RBFN，径向基函数网络)</p></li></ul><p><img src="http://i4.bvimg.com/647637/f1c3d36096b5b753.png" alt=""></p><h3 id="9-Deep-Learning-Algorithms（深度学习算法）"><a href="#9-Deep-Learning-Algorithms（深度学习算法）" class="headerlink" title="9. Deep Learning Algorithms（深度学习算法）"></a>9. Deep Learning Algorithms（深度学习算法）</h3><p>深度学习方法是利用大量廉价计算的人工神经网络的更新，它关心的是构建更大更复杂的神经网络，正如上面所提到的，许多方法都与半监督学习问题有关，在这些问题中，大型数据集包含的标签数据非常少。</p><p>最常见的算法包括：</p><ul><li><p>Deep Boltzmann Machine (DBM)</p></li><li><p>Deep Belief Networks (DBN)</p></li><li><p>Convolutional Neural Network (CNN)</p></li><li><p>Stacked Auto-Encoders</p></li></ul><p><img src="http://i4.bvimg.com/647637/42c64e10881d9023.png" alt=""></p><h3 id="10-Dimensionality-Reduction-Algorithms（降维算法）"><a href="#10-Dimensionality-Reduction-Algorithms（降维算法）" class="headerlink" title="10. Dimensionality Reduction Algorithms（降维算法）"></a>10. Dimensionality Reduction Algorithms（降维算法）</h3><p>像聚类方法一样，维数的减少有利于寻找到数据的关联关系，但在这种情况下，是不受监督的方式，或者用较少的信息来概括或描述数据。<br>这些方法中的许多可以用于分类和回归。</p><p>常见的算法包括：</p><ul><li><p>Principal Component Analysis (PCA)</p></li><li><p>Principal Component Regression (PCR)</p></li><li><p>Partial Least Squares Regression (PLSR)</p></li><li><p>Sammon Mapping</p></li><li><p>Multidimensional Scaling (MDS)</p></li><li><p>Projection Pursuit</p></li><li><p>Linear Discriminant Analysis (LDA)</p></li><li><p>Mixture Discriminant Analysis (MDA)</p></li><li><p>Quadratic Discriminant Analysis (QDA)</p></li><li><p>Flexible Discriminant Analysis (FDA)</p></li></ul><p><img src="http://i4.bvimg.com/647637/aee45bf976e3f058.png" alt=""></p><h3 id="11-Ensemble-Algorithms（集成算法）"><a href="#11-Ensemble-Algorithms（集成算法）" class="headerlink" title="11. Ensemble Algorithms（集成算法）"></a>11. Ensemble Algorithms（集成算法）</h3><p>集成方法是由多个较弱的模型而组成的模型，这些模型是独立训练的，它们的预测在某种程度上是结合在一起来进行总体预测的。<br>这类算法是把更多精力放到了弱学习器身上，以及如何将它们结合起来。这是一门非常强大的技术，因此非常受欢迎。</p><p>常见的算法包括：</p><ul><li><p>Boosting</p></li><li><p>Bootstrapped Aggregation (Bagging)</p></li><li><p>AdaBoost</p></li><li><p>Stacked Generalization (blending)</p></li><li><p>Gradient Boosting Machines (GBM)</p></li><li><p>Gradient Boosted Regression Trees (GBRT)</p></li><li><p>Random Forest</p></li></ul><p><img src="http://i4.bvimg.com/647637/762ed312f28aa7be.png" alt=""></p><h3 id="12-Other-Algorithms（其他算法）"><a href="#12-Other-Algorithms（其他算法）" class="headerlink" title="12. Other Algorithms（其他算法）"></a>12. Other Algorithms（其他算法）</h3><p>还有很多算法没有被覆盖到，大概还有下面的算法：</p><p>Feature selection algorithms（特征选择算法）</p><ul><li><p>Algorithm accuracy evaluation（算法精度估计）</p></li><li><p>Performance measures（效果评估）</p></li><li><p>Computational intelligence (evolutionary algorithms, etc.)</p></li><li><p>Computer Vision (CV)</p></li><li><p>Natural Language Processing (NLP)</p></li><li><p>Recommender Systems</p></li><li><p>Reinforcement Learning</p></li><li><p>Graphical Models</p></li><li><p>And more…</p></li></ul><p>Further Reading<br>网络上对这些算法有更加详细的讲解，需要大家自己动手去查了，这样子才会更加了解这些算法内容，本文内容来自网络，还有一些我觉得很有用的资料也在下面，大家可以抽时间去细细研究哈。</p><p>##参考资料<br>1）<a href="https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/" target="_blank" rel="noopener">A Tour of Machine Learning Algorithms</a></p><p>2）<a href="https://www.zhihu.com/question/20691338/answer/53910077" target="_blank" rel="noopener">机器学习该如何入门——张松阳的回答</a></p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>统计推断(零) 章节简介</title>
      <link href="/5451/"/>
      <url>/5451/</url>
      <content type="html"><![CDATA[<p>《统计推断(翻译版·原书第2版)》从概率论的基础开始，通过例子与习题的旁征博引，引进了大量近代统计处理的新技术和一些国内同类教材中不常见而又广为使用的分布。</p><p>其内容既包括工科概率入门、经典统计和现代统计的基础，又加进了不少近代统计中数据处理的实用方法和思想，例如：Bootstrap再抽样法、刀切(Jackkrlife)估计、EM算法、Logistic回归、稳健(Robest)回归、Markov链、Monte Carlo方法等。</p><p>它的统计内容与国内流行的教材相比，理论较深，模型较多，案例的涉及面要广，理论的应用面要丰富，统计思想的阐述与算法更为具体。</p><p>《统计推断(翻译版·原书第2版)》可作为工科、管理类学科专业本科生、研究生的教材或参考书，也可供教师、工程技术人员自学之用。</p><a id="more"></a><hr><h3 id="章节简介"><a href="#章节简介" class="headerlink" title="章节简介"></a><strong>章节简介</strong></h3><p><strong>出版说明</strong><br><strong>第2版序</strong><br><strong>第1版序</strong><br><strong>译后序</strong><br><strong>第1章 概率论</strong><br>1.1 集合论<br>1.2 概率论基础<br>1.2.1 公理化基础<br>1.2.2 概率演算<br>1.2.3 计数<br>1.2.4 枚举结果<br>1.3 条件概率与独立性<br>1.4 随机变量<br>1.5 分布函数<br>1.6 概率密度函数和概率质量函数<br>1.7 习题<br>1.8 杂录<br><strong>第2章 变换和期望</strong><br>2.1 随机变量函数的分布<br>2.2 期望<br>2.3 矩和矩母函数<br>2.4 积分号下的求导<br>2.5 习题<br>2.6 杂录<br>2.6.1 矩列的唯一性<br>2.6.2 其他母函数<br>2.6.3 矩母函数能否唯一地确定分布？<br><strong>第3章 常见分布族</strong><br>3.1 引言<br>3.2 离散分布<br>3.3 连续分布<br>3.4 指数族<br>3.5 位置与尺度族<br>3.6 不等式与恒等式<br>3.6.1 概率不等式<br>3.6.2 恒等式<br>3.7 习题<br>3.8 杂录<br>3.8.1 Poisson假设<br>3.8.2 Chebychev不等式及其改进<br>3.8.3 再谈指数族<br><strong>第4章 多维随机变量</strong><br>4.1 联合分布与边缘分布<br>4.2 条件分布与独立性<br>4.3 二维变换<br>4.4 多层模型与混合分布<br>4.5 协方差与相关<br>4.6 多维分布<br>4.7 不等式<br>4.7.1 数值不等式<br>4.7.2 函数不等式<br>4.8 习题<br>4.9 杂录<br>4.9.1 交换悖论<br>4.9.2 算术－几何－调和平均值不等式<br>8.3.1 错误概率与功效函数<br>8.3.2 最大功效检验<br>8.3.3 并－检验与交－并检验的真实水平<br>8.3.4 P-值<br>8.3.5 损失函数最优性<br>8.4 习题<br>8.5 杂录<br>8.5.1 单调功效函数<br>8.5.2 似然比作为证据<br>8.5.3 P-值和后验概率<br>8.5.4 置信集P-值<br><strong>第9章 区间估计</strong><br>9.1 引言<br>9.2 区间估计量的求法<br>9.2.1 反转一个检验统计量<br>9.2.2 枢轴量<br>9.2.3 枢轴化累积分布函数<br>9.2.4 Bayes区间<br>9.3 区间估计量的评价方法<br>9.3.1 尺寸和覆盖概率<br>9.3.2 与检验相关的最优性<br>9.3.3 Bayes最优<br>9.3.4 损失函数最优<br>9.4 习题<br>9.5 杂录<br>9.5.1 置信方法<br>9.5.2 离散分布中的置信区间<br>9.5.3 Fieller定理<br>9.5.4 其他区间如何?<br><strong>第10章 渐近评价</strong><br>10.1 点估计<br>10.1.1 相合性<br>10.1.2 有效性<br>10.1.3 计算与比较<br>10.1.4 自助法标准误差<br>10.2 稳健性<br>10.2.1 均值和中位数<br>10.2.2 M_估计量<br>10.3 假设检验<br>10.3.1 LRT的渐近分布<br>10.3.2 其他大样本检验<br>10.4 区间估计<br>10.4.1 近似极大似然区间<br>10.4.2 其他大样本区间<br>10.5 习题<br>10.6 杂录<br>10.6.1 超有效性<br>10.6.2 适当的正则性条件<br>10.6.3 再谈自助法<br>10.6.4 影响函数<br>10.6.5 自助法区间<br>10.6.6 稳健区间<br><strong>第11章 方差分析和回归分析</strong><br>11.1 引言<br>11.2 一种方式分组的方差分析<br>11.2.1 模型和分布假定<br>11.2.2 经典的ANOVA假设<br>11.2.3 均值的线性组合的推断<br>11.2.4 ANOVAF检验<br>11.2.5 对比的同时估计<br>11.2.6 平方和的分解<br>11.3 简单线性回归<br>11.3.1 最小二乘：数学解<br>11.3.2 最佳线性无偏估计：统计解<br>11.3.3 模型和分布假定<br>11.3.4 正态误差下的估计和检验<br>11.3.5 在给定点x=x0处的估计和预测<br>11.3.6 同时估计和置信带<br>11.4 习题<br>11.5 杂录<br>11.5.1 Cochran定理<br>11.5.2 多重比较<br>11.5.3 随机化完全区组设计<br>11.5.4 其他类型的方差分析<br>11.5.5 置信带的形状<br>11.5.6 Stein悖论<br><strong>第12章 回归模型</strong><br>12.1 引言<br>12.2 变量有误差时的回归<br>12.2.1 函数关系和结构关系<br>12.2.2 最小二乘解<br>12.2.3 极大似然估计<br>12.2.4 置信集<br>12.3 罗吉斯蒂克回归<br>12.3.1 模型<br>12.3.2 估计<br>12.4 稳健回归<br>12.5 习题<br>12.6 杂录<br>12.6.1 函数和结构的意义<br>12.6.2 EIV模型中常规最小乘的相合性<br>12.6.3 EIV模型中的工具变量<br>12.6.4 罗吉斯蒂克似然方程<br>12.6.5 再谈稳健回归<br><strong>附录 计算机代数</strong><br><strong>常用分布表</strong><br><strong>参考文献</strong><br><strong>作者索引</strong><br><strong>名词索引</strong></p>]]></content>
      
      <categories>
          
          <category> 应用统计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Excel学习(三) 实战篇</title>
      <link href="/17615/"/>
      <url>/17615/</url>
      <content type="html"><![CDATA[<h4 id="前文传送"><a href="#前文传送" class="headerlink" title="前文传送"></a>前文传送</h4><p><a href="https://paradoxallen.github.io/19174/">Excel学习(一) 函数篇</a><br><a href="https://paradoxallen.github.io/12853/">Excel学习(二) 技巧篇</a></p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>此文针对数据分析EXCEL部分的入门。</p><p>重点是了解各种函数，包括但不限于sum，count，sumif，countif，find，if，left/right，时间转换等。Excel函数不需要学全，<strong>重要的是学会搜索</strong>。即如何将遇到的问题在搜索引擎上描述清楚。掌握vlookup和数据透视表足够，是最具性价比的两个技巧。</p><p>学会vlookup，SQL中的join，Python中的merge很容易理解。</p><p>学会数据透视表，SQL中的group，Python中的pivot_table也是同理。</p><p>这两个搞定，基本10万条以内的数据统计没啥难度。Excel是熟能生巧，多找练习题。还有需要养成好习惯，不要合并单元格，不要过于花哨。表格按照原始数据（sheet1）、加工数据（sheet2），图表（sheet3）的类型管理。</p><p>第三篇数据分析—技巧篇。主要将前两篇的内容以实战方式进行，简单地进行了一次数据分析。数据源采用了真实的爬虫数据，是5000行数据分析师岗位数据。</p><p>温馨提示：如果您已经熟悉Excel，大可不必再看这篇文章，或只挑选部分。</p><a id="more"></a><hr><p>这篇文章讲解实战，如何运用上两篇文章的知识进行分析。</p><p>演示过程分为五个步骤：<strong>明确目的，观察数据，清洗数据，分析过程，得出结论。</strong></p><p>这也是通常数据分析的简化流程。</p><hr><h3 id="明确目的"><a href="#明确目的" class="headerlink" title="明确目的"></a>明确目的</h3><p>数据分析的大忌是不知道分析方向和目的，拿着一堆数据不知所措。<strong>一切数据分析都是以业务为核心目的</strong>，而不是以数据为目的。</p><p>数据用来解决什么问题？</p><p>是进行汇总统计制作成报表？</p><p>是进行数据可视化，作为一张信息图？</p><p>是验证某一类业务假设？</p><p>是希望提高某一个指标的KPI？</p><p>永远不要妄图在一堆数据中找出自己的结论，太难。目标在前，数据在后。哪怕给自己设立一个很简单的目标，例如计算业务的平均值，也比没有方向好。因为有了平均值可以想数字比预期是高了还是低了，原因在哪里，数据靠谱吗？为了找出原因还需要哪些数据。</p><p>既然有五千多条数据分析师的岗位数据。不妨在看数据前想一下自己会怎么运用数据。</p><p>数据分析师是一个什么样的岗位？</p><p>它的工资和薪酬是多少？</p><p>它有什么特点，需要掌握哪些能力？</p><p>哪类公司更会招聘数据分析师？</p><p>等等。有了目标和方向后，后续则是将目标拆解为实际过程。</p><hr><h3 id="观察数据"><a href="#观察数据" class="headerlink" title="观察数据"></a>观察数据</h3><p><img src="https://i.imgur.com/OKfRHrB.jpg" alt=""></p><p>拿出数据别急切计算，先观察数据。</p><p>字段名称都是英文，我是通过Json获取的数据，所以整体数据都较为规整。往后绝大部分的数据源的字段名都是英文。因为比起拼音和汉字，它更适合编程环境下。</p><p>先看一下columns的含义。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">city：城市</span><br><span class="line"></span><br><span class="line">companyFullName：公司全名</span><br><span class="line"></span><br><span class="line">companyId：公司ID</span><br><span class="line"></span><br><span class="line">companyLabelList：公司介绍标签</span><br><span class="line"></span><br><span class="line">companyShortName：公司简称</span><br><span class="line"></span><br><span class="line">companySize：公司大小</span><br><span class="line"></span><br><span class="line">businessZones：公司所在商区</span><br><span class="line"></span><br><span class="line">firstType：职位所属一级类目</span><br><span class="line"></span><br><span class="line">secondType：职业所属二级类目</span><br><span class="line"></span><br><span class="line">education：教育要求</span><br><span class="line"></span><br><span class="line">industryField：公司所属领域</span><br><span class="line"></span><br><span class="line">positionId：职位ID</span><br><span class="line"></span><br><span class="line">positionAdvantage：职位福利</span><br><span class="line"></span><br><span class="line">positionName：职位名称</span><br><span class="line"></span><br><span class="line">positionLables：职位标签</span><br><span class="line"></span><br><span class="line">salary：薪水</span><br><span class="line"></span><br><span class="line">workYear：工作年限要求</span><br></pre></td></tr></table></figure><p>数据基本涵盖了职位分析的所需。职位中的职位描述没有抓下来，一来纯文本不适合这次初级分析，二来文本需要分词以及文本挖掘，后续有机会再讲。</p><p>首先看一下哪些字段数据可以去除。<code>companyId</code>和<code>positionId</code>是数据的唯一标示，类似该职位的身份证号，这次分析用不到关联vlookup，我们先隐藏。<code>companyFullName</code>和<code>companyShortName</code>则重复了，只需要留一个公司名称，<code>companyFullName</code>依旧隐藏。</p><p>尽量不删除数据，而是隐藏，保证原始数据的完整，谁知道以后会不会用到呢？</p><p><img src="https://i.imgur.com/B3voXgf.jpg" alt=""></p><p>接下来进行数据清洗和转换。因为只是Excel级别的数据分析，不会有哑变量离散化标准化的操作。我简单归纳一下。</p><p><strong>数据有无缺失值</strong></p><p>数据的缺失值很大程度上影响分析结果。引起缺失的原因很多，例如技术原因，爬虫没有完全抓去，例如本身的缺失，该岗位的HR没有填写。</p><p>如果某一字段缺失数据较多（超过50%），分析过程中要考虑是否删除该字段，因为缺失过多就没有业务意义了。</p><p>Excel中可以通过选取该列，在屏幕的右下角查看计数，以此判别有无缺失。</p><p><code>companyLabelList、businessZones、positionLables</code>都有缺失，但不多。不影响实际分析。</p><p><strong>数据是否一致化</strong></p><p>一致化指的是数据是否有统一的标准或命名。例如上海市数据分析有限公司和上海数据分析有限公司，差别就在一个市字，主观上肯定会认为是同一家公司，但是对机器和程序依旧会把它们认成两家。会影响计数、数据透视的结果。</p><p>我们看一下表格中的<code>positionName</code></p><p><img src="https://i.imgur.com/EVbGN3f.jpg" alt=""></p><p>各类职位千奇百怪啊，什么品牌保护分析师实习生、足球分析师、商业数据分析、大数据业务分析师、数据合同管理助理。并不是纯粹的数据分析岗位。</p><p>为什么呢？这是招聘网站的原因，有些职位明确为数据分析师，有些职位要求具备数据分析能力，但是又干其他活。招聘网站为了照顾这种需求，采用关联法，只要和数据分析相关职位，都会在数据分析师的搜索结果中出现。我的爬虫没有过滤其他数据，这就需要手动清洗。</p><p>这会不会影响我们的分析？当然会。像大数据工程师是数据的另外发展方向，但不能归纳到数据分析岗位下，后续我们需要将数据分析强相关的职位挑选出来。</p><p><strong>数据是否有脏数据</strong></p><p>脏数据是分析过程中很讨厌的环节。例如乱码，错位，重复值，未匹配数据，加密数据等。能影响到分析的都算脏数据，没有一致化也可以算。</p><p>我们看表格中有没有重复数据。</p><p>这里有一个快速窍门，使用Excel的删除重复项功能，快速定位是否有重复数据，还记得<code>positionId</code>么？因为它是唯一标示，如果重复了，就说明有重复的职位数据。看来不删除它是正确的。</p><p>对<code>positionId</code>列进行重复项删除操作</p><p><img src="https://i.imgur.com/NKWu2cR.jpg" alt=""></p><p>有1845个重复值。数据重复了。这是我当时爬取完数据时，将北京地区多爬取一次人为制作出的脏数据。接下来全选所有数据，进行删除重复项，保留5032行（含表头字段）数据。</p><p><strong>数据标准结构</strong></p><p>数据标准结构，就是将特殊结构的数据进行转换和规整。</p><p>表格中，<code>companyLableList</code>就是以数组形式保存（JSON中的数组）</p><p><img src="https://i.imgur.com/uU7AVNo.jpg" alt=""></p><p>看来福利倒是不错，哈哈，不过这会影响我们的分析。<code>businessZones、positionAdvantage和positionLables</code>也是同样问题，我们后续得将这类格式拆分开来。</p><p><img src="https://i.imgur.com/pop4oIH.jpg" alt=""></p><p>薪水的话用了几K表示，但这是文本，并不能直接用于计算。而且是一个范围，后续得按照最高薪水和最低薪水拆成两列。</p><p>OK，数据大概都了解了，那么下一步就是将数据洗干净。</p><hr><h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>数据清洗可以新建Sheet，方便和原始数据区分开来。</p><p>先清洗薪水吧，大家肯定对钱感兴趣。将<code>salary</code>拆成最高薪水和最低薪水有三种办法。</p><p><strong>一是直接分列</strong>，以<code>&quot;-&quot;</code>为拆分符，得到两列数据，然后利用替换功能删除 k这个字符串。得到结果。</p><p><strong>二是自动填充功能</strong>，填写已填写的内容自动计算填充所有列。但我这个版本没有，就不演示了。</p><p><strong>三是利用文本查找的思想</strong>，重点讲一下这个。先用<code>=FIND(&quot;k&quot;,O2,1)</code>。查找第一个<code>K</code>（最低薪酬）出现的位置。</p><p><img src="https://i.imgur.com/zUVtDC4.jpg" alt=""></p><p>我们知道第一个k出现的位置，此时<code>=LEFT(O2,FIND(&quot;k&quot;,O2,1))</code>得到的结果就是<code>7K</code>，要去除掉<code>k</code>，<code>FIND(&quot;k&quot;,O2,1)</code>再减去1即可。</p><p><img src="https://i.imgur.com/443spNJ.jpg" alt=""></p><p>最高薪水也是同样的思路，但不能使用<code>k</code>，因为第二个薪水位置不固定。需要利用<code>find</code>查找<code>&quot;-&quot;</code>位置,然后截取 从<code>&quot;-&quot;</code> 到最后第二个位置的字符串。</p><pre><code>=MID(O2,FIND(&quot;-&quot;,O2,1)+1,LEN(O2)-FIND(&quot;-&quot;,O2,1)-1)</code></pre><p><img src="https://i.imgur.com/61k6qsj.jpg" alt=""></p><p>因为薪水是一个范围，我们不可能拿范围计算平均工资。那怎么办呢？我们只能取最高薪水和最低薪水的平均数作为该岗位薪资。这是数据来源的缺陷，因为我们并不能知道应聘者实际能拿多少。这是薪水计算的误差。</p><p><img src="https://i.imgur.com/eOw0B0w.jpg" alt=""></p><p>我们检查一下有没有错误，利用筛选功能快速定位。</p><p><img src="https://i.imgur.com/OuAa3zN.jpg" alt=""></p><p>居然有<code>#VALUE！</code>错误，看一下原因。</p><p><img src="https://i.imgur.com/BQvT1z6.jpg" alt=""></p><p>原来是大写<code>K</code>，因为<code>find</code>对大小写敏感，此时用<code>search</code>函数，或者将K替换成k都能解决。</p><p>另外还有一个错误是很多HR将工资写成<code>5K</code>以上，这样就无法计算<code>topSalar</code>。为了计算方便，将<code>topSalary</code>等于<code>bottomSalary</code>，虽然也有误差。</p><p>这就是我强调数据一致性的原因。</p><p><code>companyLabelList</code>是公司标签，诸如技能培训啊、五险一金啊等等。直接用分列即可。大家需要注意，分列会覆盖掉右列单元格，所以记得复制到最后一列再分。</p><p><img src="https://i.imgur.com/UpTMB87.jpg" alt=""></p><p>符号用搜索替换法删除即可。</p><p><code>positionLables、positionAdvantage、businessZones</code>同样也可以用分列法。如果观察过数据会知道，<code>companyLabelList</code>公司标签都是固定的内容，而其他三个不是。这些都是HR自己填写，所以就会有各种乱七八糟不统一的描述。</p><p><img src="https://i.imgur.com/AoHOT6x.jpg" alt=""></p><p>这些内容均是自定义，没有特别大的分析价值。如果要分析，必须花费很长的时间在清洗过程。主要思路是把这些内容统一成几十个固定标签。在这里我将不浪费时间讲解了，主要利用Python分词和词典进行快速清洗。</p><p>因为时间和性价比问题，<code>positionAdvantage</code>和<code>businessZones</code>我就不分列了。只清洗<code>positionLables</code>职位标签。某一个职位最多的标签有13个。</p><p><code>[&#39;实习生&#39;, &#39;主管&#39;, &#39;经理&#39;,&#39;顾问&#39;, &#39;销售&#39;, &#39;客户代表&#39;, &#39;分析师&#39;, &#39;职业培训&#39;, &#39;教育&#39;, &#39;培训&#39;, &#39;金融&#39;, &#39;证券&#39;, &#39;讲师&#39;]</code><br>这个职位叫金融证券分析师助理讲师助理，我真不知道为什么实习生、主管、经理这三个标签放在一起，我也是哔了狗了。反正大家数据分析做久了，会遇到很多<code>Magic Data</code>。</p><p>接下来是<code>positionName</code>，上文已经讲过有各种乱七八糟或非数据分析师职位，所以我们需要排除掉明显不是数据分析师的岗位。</p><p>单独针对<code>positionName</code>用数据透视表。统计各名称出现的次数。</p><p><img src="https://i.imgur.com/5U6EQdf.jpg" alt=""></p><p>出现次数为3次以下的职位，有约一千，都是各类特别称谓，HR你们为什么要这样写…要这样写…这样写。更改职位名称似乎不现实，那就用关键词查找的思路，找出包含有数据分析、分析师、数据运营等关键词的岗位。虽然依旧会有金融分析师这类非纯数据的岗位。</p><p>用<code>find</code>和数组函数结合 <code>=IF(COUNT(FIND({&quot;数据分析&quot;,&quot;数据运营&quot;,&quot;分析师&quot;},M33)),&quot;1&quot;,&quot;0&quot;)，shift+ctrl+enter</code>输入。就得到了多条件查找后的结果。</p><p>单纯的<code>find</code>只会查找数据分析这个词，必须嵌套<code>count</code>才会变成真数组。</p><p><img src="https://i.imgur.com/zJFvq0n.jpg" alt=""></p><p><code>1为包含，0不包含</code>。将1过滤出来，这就是需要分析的最终数据。</p><p>当然大家如果感兴趣，也可以看一下大数据工程师，数据产品经理这些岗位。</p><hr><h3 id="分析过程-amp-得出结论"><a href="#分析过程-amp-得出结论" class="headerlink" title="分析过程&amp;得出结论"></a>分析过程&amp;得出结论</h3><p>分析过程有很多玩法。因为主要数据均是文本格式，所以偏向汇总统计的计算。如果数值型的数据比较多，就会涉及到统计、比例等概念。如果有时间类数据，那么还会有趋势、变化的概念。</p><p>整体分析使用数据透视表完成，先利用数据透视表获得汇总型统计。</p><p><img src="https://i.imgur.com/W4w1AsB.jpg" alt=""></p><p>看来北京的数据分析岗位机会远较其他城市多。1-3年和3-5年两个时间段的缺口更大。应届毕业生似乎比1年一下经验的更吃香。爬取时间为11月，这时候校招陆续开始，大公司会有闲暇校招，实际岗位应该更多。小公司则倾向发布。这是招聘网站的限制。</p><p>看一下公司对数据分析师的缺口如何。</p><p><img src="https://i.imgur.com/8xBiZqa.jpg" alt=""></p><p>似乎是公司越大，需要的数据分析师越多。</p><p>但这样的分析并不准确。因为这只是一个汇总数据，而不是比例数据，我们需要计算的是不同类型企业人均招聘数。</p><p>如果北京的互联网公司特别多，那么即使有1000多个岗位发布也不算缺口大，如果南京的互联网公司少，即使只招聘30个，也是充满需求的。</p><p>还有一种情况是企业刚好招聘满数据分析师，就不发布岗位了，数据包含的只是正在招聘数据分析师的企业，这些都是限制分析的因素。我们要明确。</p><p>有兴趣大家可以深入研究。</p><p>看一下各城市招聘Top5公司。</p><p><img src="https://i.imgur.com/j4lsjT3.jpg" alt=""></p><p>北京的美团以78个数据分析职位招聘力压群雄，甚至一定程度上拉高了北京的数据。而个推则在上海和杭州都发布了多个数据分析师职位，不知道是HR的意外，还是要大规模补充业务线（在我写这篇文章的时候，约有一半职位已经下线）。</p><p>比较奇怪的是阿里巴巴并没有在杭州上榜，看来是该阶段招聘需求不大，或者数据分析师有其他招聘渠道。</p><p>没有上榜不代表不要数据分析师，但是上榜的肯定现阶段对数据分析师有需求。</p><p>我们看一下数据分析师的薪水，可能是大家最感兴趣的了。</p><p><img src="https://i.imgur.com/ifz87wL.jpg" alt=""></p><p>我们看到南京、西安在应届生中数据最高，是因为招聘职位不多，因为单独一两个企业的高薪影响了平均数，其余互联网二线城市同理。当工作年限达到3年以上，北上深杭的数据分析师薪资则明显高于其他城市。</p><p>数据会有误差性么？会的，因为存在薪资极值影响。而数据透视表没有中位数选项。我们也可以单独用分位数进行计算，降低误差。</p><p>薪资可以用更细的维度计算，比如学历、比如公司行业领域，是否博士生远高于本科生，是否金融业薪资高于O2O。</p><p>另外数据分析师的薪资，可能包括奖金、年终奖、季度奖等隐形福利。部分企业会在<code>positionAdvantage</code>的内容上说明，大家可以用筛选过滤出16薪这类关键词。作为横向对比。</p><p><img src="https://i.imgur.com/iy0Gy0U.jpg" alt=""></p><p>我们看一下数据分析的职位标签，数据透视后汇总。</p><p><img src="https://i.imgur.com/B63AFJS.jpg" alt=""></p><p><code>分析师、数据、数据分析</code>是最多的标签。除此以外，<code>需求分析，BI，数据挖掘</code>也出现在前列。看来不少数据分析师的要求掌握数据挖掘，将标签和薪水关联，是另外一种分析思路。职位标签并不是最优的解法，了解一个职位最好的必然是职位描述。</p><p>分析过程不多做篇幅了，主要使用数据透视表进行多维度分析，没有其他复杂的技巧。下图很直观的展现了多维度的应用。</p><p><img src="https://i.imgur.com/vRSysg5.jpg" alt=""></p><p>我们的分析也属于多维度，<code>城市、工作年限、企业大小、企业领域</code>等，利用不同维度形成一个直观的二位表格，而维度则是通过早期的数据清洗统一化标准化。这是一种很常见的分析技巧。</p><p>后续的数据报告，涉及到可视化制作，因为字不如表、表不如图，就放在后面讲解了。</p><p>最后多说几下：</p><p><strong>1.最好的分析，是拿数据分析师们的在职数据，而不是企业招聘数据。</strong></p><p><strong>2.承认招聘数据的非客观性，招聘要求与对数据分析师的实际要求是有差异的。</strong></p><hr><p>####写在最后<br>除了Excel的这三部分内容，还有一些也需要进一步了解的：</p><p>了解单元格格式，后期的数据类型包括各类timestamp，date，string，int，bigint，char，factor，float等。</p><p>了解数组，以及怎么用（excel的数组挺难用），Python和R也会涉及到 list。</p><p>了解函数和参数，当进阶为编程型的数据分析师时，会让你更快的掌握。</p><p>了解中文编码，UTF8和ASCII，包括CSV的delimiter等。</p><p>养成一个好习惯，不要合并单元格，不要过于花哨。表格按照原始数据、加工数据，图表的类型管理。</p><p>作者：秦路<br>链接：<a href="https://www.zhihu.com/question/29265587/answer/125091104" target="_blank" rel="noopener">https://www.zhihu.com/question/29265587/answer/125091104</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>1）<a href="https://www.zhihu.com/question/29265587/answer/125091104" target="_blank" rel="noopener">秦路-数据分析</a></p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Excel </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Excel学习(二) 技巧篇</title>
      <link href="/12853/"/>
      <url>/12853/</url>
      <content type="html"><![CDATA[<h4 id="前文传送"><a href="#前文传送" class="headerlink" title="前文传送"></a>前文传送</h4><p><a href="https://paradoxallen.github.io/19174/">Excel学习(一) 函数篇</a></p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>此文针对数据分析EXCEL部分的入门。</p><p>重点是了解各种函数，包括但不限于sum，count，sumif，countif，find，if，left/right，时间转换等。Excel函数不需要学全，<strong>重要的是学会搜索</strong>。即如何将遇到的问题在搜索引擎上描述清楚。掌握vlookup和数据透视表足够，是最具性价比的两个技巧。</p><p>学会vlookup，SQL中的join，Python中的merge很容易理解。</p><p>学会数据透视表，SQL中的group，Python中的pivot_table也是同理。</p><p>这两个搞定，基本10万条以内的数据统计没啥难度。Excel是熟能生巧，多找练习题。还有需要养成好习惯，不要合并单元格，不要过于花哨。表格按照原始数据（sheet1）、加工数据（sheet2），图表（sheet3）的类型管理。</p><p>第二篇数据分析—技巧篇。主要简单讲解很有性价比的功能，提高工作效率。</p><p>温馨提示：如果您已经熟悉Excel，大可不必再看这篇文章，或只挑选部分。</p><a id="more"></a><hr><p>本次讲解依然是提纲，图文部分引用自百度经验。内容方面照旧会补充SQL和Python。</p><hr><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><p>Excel的快捷键很多，以下主要是能提高效率。</p><p><code>Ctrl+方向键</code>，对单元格光标快速移动，移动到数据边缘（空格位置）。</p><p><code>Ctrl+Shift+方向键</code>，对单元格快读框选，选择到数据边缘（空格位置）。</p><p><code>Ctrl+空格键</code>，选定整列。</p><p><code>Shift+空格键</code>，选定整行。</p><p><code>Ctrl+A</code>，选择整张表。</p><p><code>Alt+Enter</code>，换行。</p><p><code>Ctrl+Enter</code>，以当前单元格为始，往下填充数据和函数。</p><p><code>Ctrl+S</code>，快读保存。</p><p><code>Ctrl+Z</code>，撤回当前操作。</p><p>如果是效率达人，可以学习更多快捷键。Mac用户的Ctrl一般需要用command替换。</p><h3 id="格式转换"><a href="#格式转换" class="headerlink" title="格式转换"></a>格式转换</h3><p>Excel的格式及转换很容易忽略，但格式会如影随形伴随数据分析者的一切场景，是后续SQL和Python数据类型的基础。</p><p>通常我们将Excel格式分为数值、文本、时间。</p><p>数值常见整数型 Int和小数/浮点型 Float。两者的界限很模糊。在SQL和Python中，则会牵扯的复杂，涉及运算效率，计算精度等。</p><p>文本分为中文和英文，存储字节，字符长度不同。中文很容易遇到编码问题，尤其是Python2。Win和Mac环境也有差异。大家遇到的乱码一般都属于中文编码错误。</p><p>时间格式在Excel中可以和数值直接互换，也能用加减法进行天数换算。</p><p>时间格式有不同表达。例如<code>2016年11月11日，2016/11/11，2016-11-11</code>等。当数据源多就会变得混乱。我们可以用自定义格式规范时间。</p><p>这里了解一下时间格式的概念，列举是一些较通用的范例（<strong>不同编程语言还是有差异的</strong>）。</p><p><code>YYYY</code>代表通配的四位数年格式</p><p><code>MM</code>代表通配的两位数月格式</p><p><code>DD</code>代表通配的两位数日格式</p><p><code>HH</code>代表通配的的两位数小时（24小时）格式</p><p><code>hh</code>代表通配的两位数小（12小时制）格式</p><p><code>mm</code>代表通配的两位数分格式</p><p><code>ss</code>代表通配的两位数秒格式</p><p>例如<code>2016/11/11</code>可以写成：<code>yyyy/MM/dd</code></p><p><code>2016-11-11 23:59:59</code>可以写成：<code>yyyy-MM-dd HH:mm:ss</code></p><p><img src="https://i.imgur.com/nlur0Cl.jpg" alt=""></p><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>数组很多人都不会用到，甚至不知道有这个功能。依旧是数据分析越往后用到越多，它类似R语言的Array和Python的<code>List</code>。</p><p>数组由多个元素组成。普通函数的计算结果是一个值，数组类函数的计算结果返回多个值。</p><p>数组用大括号表示，当函数中使用到数组，应该用<code>Ctrl+Shift+Enter</code>输入，不然会报错。</p><p>先看数组的最基础使用。选择<code>A1:D1</code>区域，输入<code>={1,2,3,4}</code>。记住是大括号。然后<code>Ctrl+Shift+Enter</code>。我们发现数组里的四个值被分别传到四个单元格中，这是数组的独有用法。</p><p><img src="https://i.imgur.com/BPaet6B.jpg" alt=""></p><p>我们再来看一下数组和函数的应用。利用{}，我们能做到1匹配a，2匹配b，3匹配c。也就是一一对应。专业说法是<code>Mapping</code>。</p><pre><code>=lookup(查找值，{1,2,3}，{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;})</code></pre><p>Excel的数组具体应用，大家可以搜索学习，可以提高一定的效率。但是Python的数组更为强大，我的重点就不放在这块了。</p><h3 id="分列"><a href="#分列" class="headerlink" title="分列"></a>分列</h3><p>Excel可以将多个单元格的内容合并，但是不擅长拆分。分列功能可以将某一列按照特定规则拆分。常常用来进行数据清洗。</p><p><img src="https://i.imgur.com/vimBLy5.jpg" alt=""></p><p>上文我有一列地区的数据，我想要将市和区分成两列。我们可以用mid和find函数查找市截取字符。但最快的做法就是用“市”分列。</p><p><img src="https://i.imgur.com/5FhN3mL.jpg" alt=""></p><p>出一个思考题，如果市和自治区区都存在应该如何分列？</p><p>SQL和Python中有类似的<code>spilt ( )</code>函数。</p><h3 id="合并单元个格"><a href="#合并单元个格" class="headerlink" title="合并单元个格"></a>合并单元个格</h3><p>单元格作为报表整理使用，除非是最终输出格式，例如打印。否则不要随意合并单元格。</p><p>一旦使用合并单元格，绝大多数函数都不能正常使用，影响批量的数据处理和格式转换。合并单元格也会造成Python和SQL的读取错误。</p><h3 id="数据透视表"><a href="#数据透视表" class="headerlink" title="数据透视表"></a>数据透视表</h3><p>数据透视表是非常强大的功能，当初学会时惊为天人。</p><p>数据透视表的主要功能是将数据聚合，按照各子段进行<code>sum( )，count( )</code>的运算。</p><p>下图我选择我选择想要计算的数据，然后点击创建透视表。</p><p><img src="https://i.imgur.com/n9BMOzA.jpg" alt=""></p><p>此时会新建一个Sheet，这是数据透视表的优点，将原始数据和汇总计算数据分离。</p><p>数据透视表的核心思想是聚合运算，将字段名相同的数据聚合起来，所谓数以类分。</p><p>列和行的设置，则是按不同轴向展现数据。简单说，你想要什么结构的报表，就用什么样的拖拽方式。</p><p><img src="https://i.imgur.com/7TGmIVc.jpg" alt=""></p><p>聚合功能有一点类似SQL中的<code>gorup by</code>，python中则有更为强大的<code>pandas.pivot_table( )</code>。</p><h3 id="删除重复项"><a href="#删除重复项" class="headerlink" title="删除重复项"></a>删除重复项</h3><p>一种数据清洗和检验的快速方式。想要验证某一列有多少个唯一值，或者数据清洗，都可以使用。</p><p>类似SQL中的<code>distinct</code> ,python中的<code>set</code></p><h3 id="条件格式"><a href="#条件格式" class="headerlink" title="条件格式"></a>条件格式</h3><p>条件格式可以当作数据可视化的应用。如果我们要使用函数在大量数据中找出前三的值，可能会用到<code>rank( )</code>函数，排序，然后过滤出<code>1，2，3</code>。</p><p>用条件格式则是另外一种快速方法，直接用颜色标出，非常直观。</p><p><img src="https://i.imgur.com/NlLrhKr.jpg" alt=""><br><img src="https://i.imgur.com/xxoRsIE.jpg" alt=""></p><h3 id="冻结首行首列"><a href="#冻结首行首列" class="headerlink" title="冻结首行首列"></a>冻结首行首列</h3><p>Excel的首行一般是各字段名<code>Header</code>，俗称表头，当行数和列数过多的时候，观察数据比较麻烦。我们可以通过固定住首行，方便浏览和操作。</p><p><code>Header</code>是一个较为重要的概念。在Python和R中，<code>read_csv</code>函数，会有一个专门的参数<code>header=true</code>，来判断是否读取表头作为<code>columns</code>的名字。</p><h3 id="自定义下拉菜单（数据有效性）"><a href="#自定义下拉菜单（数据有效性）" class="headerlink" title="自定义下拉菜单（数据有效性）"></a>自定义下拉菜单（数据有效性）</h3><p>数据有效性是一种约束，针对单元格限制其输入，也就是让其只能固定几个值。下拉菜单是一种高阶应用，通过允许下拉箭头即可。</p><p><img src="https://i.imgur.com/QO0Ru7S.jpg" alt=""><br><img src="https://i.imgur.com/hfJAJVC.jpg" alt=""></p><h3 id="自定义名称"><a href="#自定义名称" class="headerlink" title="自定义名称"></a>自定义名称</h3><p>自定义名称是一个很好用的技巧，我们可以为一个区域，变量、或者数组定义一个名称。后续要经常使用的话，直接引用即可，无需再次定位。这是复用的概念。</p><p><img src="https://i.imgur.com/DROuDqO.jpg" alt=""></p><p>我们将<code>A1:A3</code>区域命名为<code>NUM</code><br>直接使用<code>=sum(NUM)</code> ，等价于<code>sum(A1:A3)</code>。</p><p><img src="https://i.imgur.com/UFyXjOg.jpg" alt=""></p><p>新手们理解数据库，可以将其想象成无数张表sheet。每一张表都有自己唯一的名字，就像上图的<code>NUM</code>一样。数据库操作就是引用表名进行查找、关联等操作。使用<code>sum，count</code>等函数。</p><h3 id="查找公式错误"><a href="#查找公式错误" class="headerlink" title="查找公式错误"></a>查找公式错误</h3><p>公式报错也不知道错在哪里的时候可以使用，尤其是各类<code>IF</code>嵌套或者多表关联，逻辑复杂时。查找公式错误是逐步运算的，方便定位。</p><p><img src="https://i.imgur.com/7RfPtPt.jpg" alt=""><br><img src="https://i.imgur.com/8xm8ffn.jpg" alt=""></p><h3 id="分组和分级显示"><a href="#分组和分级显示" class="headerlink" title="分组和分级显示"></a>分组和分级显示</h3><p>分组和分级显示，常用在报表中，在报表行数多到一定程度时，通过分组达到快速切换和隐藏的目的。越是专业度的报表（咨询、财务等），越可以学习这块。在数据菜单下。</p><p><img src="https://i.imgur.com/ckuyEmM.jpg" alt=""></p><h3 id="分析工具库"><a href="#分析工具库" class="headerlink" title="分析工具库"></a>分析工具库</h3><p>分析工具库是高阶分析的利器，包含很多统计计算，检验功能等工具。Excel是默认不安装的，要安装需要加载项，在工具菜单下（不同版本安装方式会有一点小差异）。</p><p><img src="https://i.imgur.com/769vRzG.jpg" alt=""></p><p>分析工具库是统计包，规划求解是计算最优解，类似决策树。这两者的分析方法以后详细论述。</p><p><img src="https://i.imgur.com/NeSkSr0.jpg" alt=""></p><p>Mac似乎有阉割。</p><h3 id="第三方应用"><a href="#第三方应用" class="headerlink" title="第三方应用"></a>第三方应用</h3><p>Excel是支持第三方插件的，第三方插件拥有非常强大的功能。甚至完成BI的工作。</p><p><img src="https://i.imgur.com/QdlkYp0.jpg" alt=""></p><p>应用商店里微软的<code>Power系列</code>都挺好的。下图就是<code>Power Map</code></p><p><img src="https://i.imgur.com/JLzHZg7.jpg" alt=""></p><p>第三方应用商店Mac没有，非常可惜。Win用户请用最新版本，老版本是没有插件的。</p><p>Excel更多技巧可以在<a href="https://www.zhihu.com/topic/19567930/hot" target="_blank" rel="noopener">知乎Microsoft Excel-热门问答-知乎</a> 下搜索。主要是和数据分析相关的。</p><hr><p>主要的Excel技巧和函数已经都已经讲解完毕。Excel博大精深，有一句说的挺好，我们大部分实际用到的功能只有20%。熟练掌握这20%功能，日常工作足够应付。重要的还是解决问题的能力。</p><p>接下来是Excel实战内容，下一篇文章会直接用到5000行真实的数据分析师的职位数据。没错，用数据分析师的数据进行分析，有点拗口。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>1）<a href="https://www.zhihu.com/question/29265587/answer/125091104" target="_blank" rel="noopener">秦路-数据分析</a></p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Excel </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Excel学习(一) 函数篇</title>
      <link href="/19174/"/>
      <url>/19174/</url>
      <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>此文针对数据分析EXCEL部分的入门。</p><p>重点是了解各种函数，包括但不限于sum，count，sumif，countif，find，if，left/right，时间转换等。Excel函数不需要学全，<strong>重要的是学会搜索</strong>。即如何将遇到的问题在搜索引擎上描述清楚。掌握vlookup和数据透视表足够，是最具性价比的两个技巧。</p><p>学会vlookup，SQL中的join，Python中的merge很容易理解。</p><p>学会数据透视表，SQL中的group，Python中的pivot_table也是同理。</p><p>这两个搞定，基本10万条以内的数据统计没啥难度。Excel是熟能生巧，多找练习题。还有需要养成好习惯，不要合并单元格，不要过于花哨。表格按照原始数据（sheet1）、加工数据（sheet2），图表（sheet3）的类型管理。</p><p>第一篇数据分析—函数篇。主要简单讲解常用的函数，以及与之对应的SQL/Python函数。</p><p>温馨提示：如果您已经熟悉Excel，大可不必再看这篇文章，或只挑选部分。</p><a id="more"></a><hr><p>世界上的数据分析师分为两类，使用Excel的分析师，和其他分析师。</p><p>每一个数据新人的入门工具都离不开Excel。因为Excel涵盖的功能足够多。</p><p>很多传统行业的数据分析师只要求掌握Excel即可，会SPSS/SAS是加分项。即使在挖掘满街走，Python不如狗的互联网数据分析界，Excel也是不可替代的。</p><p>Excel有很多强大的函数，这篇文章主要介绍各种函数的用途。实战会后续文章讲解。</p><p>函数可以被我们想象成一个盒子，专门负责将输入转换成输出，不同的函数对应不同的输出。</p><pre><code>=Vlookup( lookup_value ,table_array,col_index_num,[range_lookup] )</code></pre><p>上文的Vlookup就是一个经典函数。函数中包含参数，括号里的部分都是参数。我们可以把参数想象成盒子上的开关。vlookup就有四个开关，不同开关组合决定了函数的输入和输出。</p><pre><code>=Vlookup( 参数1，参数2，参数3，参数4)</code></pre><p>复杂的原理不需要了解。这篇文章是常用函数汇总。甚至你不需要特别记忆怎么使用函数，<strong>应用Excel函数最重要的能力是学会搜索</strong>。因为绝大部分函数网上已经有相应的解释，图文结合，非常详尽。</p><p>学会将遇到的问题转换成搜索语句，如不会vlookup，不会关联多张表的数据，在网上搜索：excel怎么匹配多张表的数据。于是就学会了。这里推荐使用百度，因为前三行的结果基本是百度经验，对新人学习很友好。（后续图片均引用自百度经验）</p><p>在理解函数的基础上，会适当引入高层次的内容，SQL和Python（内建函数）。将其和Excel结合学习，如果大家吃透了Excel的函数，那么后续学习会轻松不少。</p><hr><h3 id="清洗处理类"><a href="#清洗处理类" class="headerlink" title="清洗处理类"></a>清洗处理类</h3><p>主要是文本、格式以及脏数据的清洗和转换。很多数据并不是直接拿来就能用的，需要经过数据分析人员的清理。数据越多，这个步骤花费的时间越长。</p><p><strong>Trim</strong></p><p>清除掉字符串两边的空格。</p><p><em>MySQL有同名函数，Python有近似函数strip。</em></p><p><strong>Concatenate</strong></p><pre><code>=Concatenate(单元格1，单元格2……)</code></pre><p>合并单元格中的内容，还有另一种合并方式是&amp; 。”我”&amp;”很”&amp;”帅” ＝ 我很帅。当需要合并的内容过多时，concatenate的效率快也优雅。</p><p><em>MySQL有近似函数concat。</em></p><p><strong>Replace</strong></p><pre><code>=Replace（指定字符串，哪个位置开始替换，替换几个字符，替换成什么）</code></pre><p>替换掉单元格的字符串，清洗使用较多。</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Substitute</strong></p><p>和replace接近，区别是替换为全局替换，没有起始位置的概念</p><p><strong>Left／Right／Mid</strong></p><pre><code>=Mid(指定字符串，开始位置，截取长度)</code></pre><p>截取字符串中的字符。Left/Right（指定字符串，截取长度）。left为从左，right为从右，mid如上文示意。</p><p><em>MySQL中有同名函数。</em></p><p><strong>Len／Lenb</strong></p><p>返回字符串的长度，在len中，中文计算为一个，在lenb中，中文计算为两个。<br><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Find</strong></p><pre><code>=Find（要查找字符，指定字符串，第几个字符）</code></pre><p>查找某字符串出现的位置，可以指定为第几次出现，与Left／Right／Mid结合能完成简单的文本提取<br><em>MySQL中有近似函数 find_in_set，Python中有同名函数。</em></p><p><strong>Search</strong></p><p>和Find类似，区别是Search大小写不敏感，但支持＊通配符</p><p><strong>Text</strong></p><p>将数值转化为指定的文本格式，可以和时间序列函数一起看</p><hr><h3 id="关联匹配类"><a href="#关联匹配类" class="headerlink" title="关联匹配类"></a>关联匹配类</h3><p>在进行多表关联或者行列比对时用到的函数，越复杂的表用得越多。多说一句，良好的表习惯可以减少这类函数的使用。</p><p><strong>Lookup</strong></p><pre><code>=Lookup（查找的值，值所在的位置，返回相应位置的值）</code></pre><p>最被忽略的函数，功能性和Vlookup一样，但是引申有数组匹配和二分法。</p><p><strong>Vlookup</strong></p><pre><code>=Vlookup(查找的值，哪里找，找哪个位置的值，是否精准匹配)</code></pre><p>Excel第一大难关，因为涉及的逻辑对新手较复杂，通俗的理解是查找到某个值然后黏贴过来。</p><p><strong>Index</strong></p><pre><code>＝Index（查找的区域，区域内第几行，区域内第几列）</code></pre><p>和Match组合，媲美Vlookup，但是功能更强大。</p><p><strong>Match</strong></p><pre><code>＝Match（查找指定的值，查找所在区域，查找方式的参数）</code></pre><p>和Lookup类似，但是可以按照指定方式查找，比如大于、小于或等于。返回值所在的位置。</p><p><strong>Row</strong></p><p>返回单元格所在的行</p><p><strong>Column</strong></p><p>返回单元格所在的列</p><p><strong>Offset</strong></p><pre><code>＝Offset（指定点，偏移多少行，偏移多少列，返回多少行，返回多少列）</code></pre><p>建立坐标系，以坐标系为原点，返回距离原点的值或者区域。正数代表向下或向右，负数则相反。</p><hr><h3 id="逻辑运算类"><a href="#逻辑运算类" class="headerlink" title="逻辑运算类"></a>逻辑运算类</h3><p>数据分析中不得不用到逻辑运算，逻辑运算返回的均是布尔类型，True和False。很多复杂的数据分析会牵扯到较多的逻辑运算</p><p><strong>IF</strong></p><p>经典的如果但是，在后期的Python中，也会经常用到，当然会有许多更优雅的写法。也有ifs用法，取代if(and())的写法。</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>And</strong></p><p>全部参数为True，则返回True，经常用于多条件判断。</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Or</strong></p><p>只要参数有一个True，则返回Ture，经常用于多条件判断。</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>IS系列</strong></p><p>常用判断检验，返回的都是布尔数值True和False。常用ISERR，ISERROR，ISNA，ISTEXT，可以和IF嵌套使用。</p><hr><h3 id="计算统计类"><a href="#计算统计类" class="headerlink" title="计算统计类"></a>计算统计类</h3><p>常用的基础计算、分析、统计函数，以描述性统计为准。具体含义在后续的统计章节再展开。<br><strong>Sum／Sumif／Sumifs</strong></p><p>统计满足条件的单元格总和，SQL有中同名函数。</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Sumproduct</strong></p><p>统计总和相关，如果有两列数据销量和单价，现在要求卖出增加，用sumproduct是最方便的。</p><p><em>MySQL中有同名函数。</em></p><p><strong>Count／Countif／Countifs</strong></p><p>统计满足条件的字符串个数</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Max</strong></p><p>返回数组或引用区域的最大值</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Min</strong></p><p>返回数组或引用区域的最小值</p><p><em>MySQL中有同名函数，Python中有同名函数。</em></p><p><strong>Rank</strong></p><p>排序，返回指定值在引用区域的排名，重复值同一排名。</p><p><em>SQL中有近似函数row_number() </em>。</p><p><strong>Rand／Randbetween</strong></p><p>常用随机抽样，前者返回0~1之间的随机值，后者可以指定范围。</p><p><em>MySQL中有同名函数。</em></p><p><strong>Averagea</strong></p><p>求平均值，也有Averageaif，Averageaifs</p><p><em>MySQL中有同名函数，python有近似函数mean。</em></p><p><strong>Quartile</strong></p><pre><code>=Quartile（指定区域，分位参数）</code></pre><p>计算四分位数，比如1~100的数字中，25分位就是按从小到大排列，在25%位置的数字，即25。参数0代表最小值，参数4代表最大值，1~3对应25、50（中位数）、75分位</p><p><strong>Stdev</strong></p><p>求标准差，统计型函数，后续数据分析再讲到</p><p><strong>Substotal</strong></p><pre><code>=Substotal（引用区域，参数）</code></pre><p>汇总型函数，将平均值、计数、最大最小、相乘、标准差、求和、方差等参数化，换言之，只要会了这个函数，上面的都可以抛弃掉了。</p><p><strong>Int／Round</strong></p><p>取整函数，int向下取整，round按小数位取数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">round(3.1415,2) =3.14 ;</span><br><span class="line">round(3.1415,1)=3.1</span><br></pre></td></tr></table></figure></p><hr><h3 id="时间序列类"><a href="#时间序列类" class="headerlink" title="时间序列类"></a>时间序列类</h3><p>专门用于处理时间格式以及转换，时间序列在金融、财务等数据分析中占有较大比重。时机序列的处理函数比我列举了还要复杂，比如时区、分片、复杂计算等。这里只做一个简单概述。</p><p><strong>Year</strong></p><p>返回日期中的年</p><p><em>MySQL中有同名函数。</em></p><p><strong>Month</strong></p><p>返回日期中的月</p><p><em>MySQL中有同名函数。</em></p><p><strong>Weekday</strong></p><pre><code>=Weekday(指定时间，参数)</code></pre><p>返回指定时间为一周中的第几天，参数为1代表从星期日开始算作第一天，参数为2代表从星期一开始算作第一天（中西方差异）。我们中国用2为参数即可。</p><p><em>MySQL中有同名函数。</em></p><p><strong>Weeknum</strong></p><pre><code>=Weeknum(指定时间，参数)</code></pre><p>返回一年中的第几个星期，后面的参数类同weekday，意思是从周日算还是周一。</p><p><em>MySQL中有近似函数 week。</em></p><p><strong>Day</strong></p><p>返回日期中的日（第几号）</p><p><em>MySQL中有同名函数。</em></p><p><strong>Date</strong></p><pre><code>=Date（年，月，日）</code></pre><p>时间转换函数，等于将year()，month()，day()合并</p><p><em>MySQL中有近似函数 date_format。</em></p><p><strong>Now</strong></p><p>返回当前时间戳，动态函数</p><p><em>MySQL中有同名函数。</em></p><p><strong>Today</strong></p><p>返回今天的日期，动态函数</p><p><em>MySQL中有同名函数。</em></p><p><strong>Datedif</strong></p><pre><code>=Datedif（开始日期，结束日期，参数）</code></pre><p>日期计算函数，计算两日期的差。参数决定返回的是年还是月等。</p><p><em>MySQL中有近似函数 DateDiff。</em></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>1）<a href="https://www.zhihu.com/question/29265587/answer/125091104" target="_blank" rel="noopener">秦路-数据分析</a></p>]]></content>
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Excel </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>博客搭建——利用GitHub+Hexo</title>
      <link href="/13431/"/>
      <url>/13431/</url>
      <content type="html"><![CDATA[<p>一直想有一个可以记录的属于自己的博客，最近在知乎上看到了利用<a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>+<a href="https://github.com/" target="_blank" rel="noopener">GitHub</a>搭建博客的教程，于是乎搭建了自己的博客<a href="https://paradoxallen.github.io/">paradoxallen</a>。</p><p>然而在此过程也遇到了一些bug，希望以下图文并茂的教程（虽然已经有挺多类似的教程…但主要是想自己写一篇文章!!!而且保证超级详细!!!）可以帮助大家少走弯路，搭建属于自己的博客。</p><a id="more"></a><hr><h2 id="GitHub配置"><a href="#GitHub配置" class="headerlink" title="GitHub配置"></a>GitHub配置</h2><p><a href="https://github.com/" target="_blank" rel="noopener">https://github.com/ </a>登录GitHub账号,如无GitHub帐号需要注册一个</p><p><img src="http://i1.bvimg.com/647637/c2c87e3a66d3f41c.png" alt=""></p><p>点击GitHub中的New repository创建新仓库</p><p><img src="http://i2.bvimg.com/647637/8cd2118322eeebb8.png" alt=""></p><p>仓库名应该为：用户名.<a href="http://github.io" target="_blank" rel="noopener">http://github.io</a> </p><p>这个用户名使用你的GitHub帐号名称代替，这是固定写法</p><p>如我的域名是<a href="http://github.com/paradoxallen" target="_blank" rel="noopener">github.com/paradoxallen</a>，就填入<a href="http://paradoxallen.github.io">paradoxallen.github.io</a></p><p>然后点击create repository创建仓库</p><p><img src="http://i2.bvimg.com/647637/7dee21bf61c6a269.png" alt=""></p><p>成功之后出现以下画面</p><p><img src="http://i4.bvimg.com/647637/9c9e7a4a292f769b.png" alt=""></p><h2 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h2><h3 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h3><p><a href="https://git-scm.com/download/win" target="_blank" rel="noopener">Git-Downloading Package</a>选择下载Windows版本的64位或32位的安装包（也有MacOSX版本和Linux/Unix版本的，按需求下载）</p><p><img src="http://i4.bvimg.com/647637/c8ab66c94a5b8923.png" alt=""></p><p>下载后安装，基本按默认安装就行，安装成功后，鼠标右键打开Git Bash</p><p><img src="http://i2.bvimg.com/647637/1a613567dfe1c628.png" alt=""></p><p>然后设置user.name和user.email配置信息<br><code>git config --global user.name &quot;你的GitHub用户名&quot;</code><br><code>git config --global user.email &quot;你的GitHub注册邮箱&quot;</code></p><p>生成ssh密钥文件：<br><code>ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;</code></p><p><img src="http://i2.bvimg.com/647637/d7a3ae0382cff29c.png" alt=""></p><p>然后直接三个回车，无需设置密码</p><p>在找到生成的.ssh的文件夹中的id-rsa.pub密钥，将内容全部复制</p><p><img src="http://i2.bvimg.com/647637/71af645c415b05d6.png" alt=""></p><p>打开<a href="https://github.com/settings/keys/new" target="_blank" rel="noopener">GitHub-Settings-SSHandGPGkeys-newSHHkeys</a>新建</p><p><img src="http://i4.bvimg.com/647637/410f443eedb161d1.png" alt=""></p><p>Title随意，Key粘贴id-rsa.pub内容，最后点击Add SHH key</p><p>在Git Bash中检测GitHub公钥是否设置成功，输入<code>ssh git@github.com</code>如下则说明成功</p><p><img src="http://i4.bvimg.com/647637/2e82b66bd44b0528.png" alt=""></p><h3 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h3><p><a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Download|Node.js</a>选择下载安装包，也是默认设置安装就好</p><p><img src="http://i4.bvimg.com/647637/c7552174b3bafe3b.png" alt=""></p><h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><p>这里需要在自己电脑中新建文件夹，如命名为blog</p><p>进入文件夹，按住shift键，右击鼠标点击在此处打开Powershell窗口</p><p>（有些教程是打开命令行，但好像是win10才有的powershell)</p><p><img src="http://i2.bvimg.com/647637/035c259ae9e63ed0.png" alt=""></p><p>然后依次输入：</p><p><code>npm install -g hexo-cli</code>安装Hexo</p><p><code>hexo init blog</code>初始化Hexo</p><p>成功提示<code>INFO  Start blogging with Hexo!</code></p><p>（因为我已经设置好就不重新初始化啦）</p><p>因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令<br><code>hexo g</code> </p><p><code>hexo s</code>启动本地服务器</p><p>成功提示<br><code>INFO  Start processing</code><br><code>INFO  Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.</code></p><p><img src="http://i4.bvimg.com/647637/e262c409d50dc6b2.png" alt=""></p><p>在浏览器输入<code>http://localhost:4000/</code>就可以看见网页和模板了（因为我修改过主题可能有点出入）</p><p><img src="http://i4.bvimg.com/647637/1a5c5f97074e6f7d.png" alt=""></p><h2 id="网站推送"><a href="#网站推送" class="headerlink" title="网站推送"></a>网站推送</h2><p>打开blog根目录_config.yml文件，将Hexo与GitHub关联起来</p><p><img src="http://i4.bvimg.com/647637/f4980b87d2c9f2ff.png" alt=""></p><p><code>deploy:</code></p><p><code>type: git</code></p><p><code>repo: GitHub上创建仓库的完整路径，加上 .git</code></p><p><code>branch: master</code></p><p>参考如下：</p><p><img src="http://i4.bvimg.com/647637/c150e9cde0adb7b3.png" alt=""></p><p>然后保存并执行命令：<br><code>npm install hexo-deployer-git --save</code></p><p>再依次输入三条命令:</p><p><code>hexo clean</code> </p><p><code>hexo g</code></p><p><code>hexo d</code></p><p>打开浏览器，在地址栏输入你的放置个人网站的仓库路径，即 <a href="http://xxxx.github.io，如[paradoxallen.github.io](https://paradoxallen.github.io/)即可访问" target="_blank" rel="noopener">http://xxxx.github.io，如[paradoxallen.github.io](https://paradoxallen.github.io/)即可访问</a></p><p>此外，也可以打开_config.yml文件修改参数信息，如排版格式等等</p><h2 id="文章发布"><a href="#文章发布" class="headerlink" title="文章发布"></a>文章发布</h2><p>输入：<code>hexo new &quot;testing&quot;</code>打开文件使用markdown语法输入文字</p><p>保存，执行：</p><p><code>hexo clean</code></p><p><code>hexo g</code></p><p><code>hexo server</code></p><p><code>hexo deploy</code></p><p><img src="http://i2.bvimg.com/647637/408049f3884510e4.png" alt=""></p><p>就可以看到文章发布了~</p><p><img src="http://i2.bvimg.com/647637/bdb5ddb3bea1f960.png" alt=""></p><h2 id="总结陈词"><a href="#总结陈词" class="headerlink" title="总结陈词"></a>总结陈词</h2><p>搭建博客的步骤：</p><p>1、GitHub配置</p><p>2、环境安装</p><p>3、网站推送</p><p>4、文章发布</p><p>发布文章的步骤：</p><p>1、hexo new 创建文章</p><p>2、Markdown语法编辑文章</p><p>3、部署（所有打开CMD都是在blog目录下）</p><p>到这里已经完成了博客的搭建以及文章的发布，但是还有很多需要设置和调整的。</p><p>我也是刚刚搭建好博客，还有待博客界面的优化以及内容的丰富!!!</p><p>今天先到这里啦~</p><p>##参考资料<br>1.<a href="https://zhangslob.github.io/2017/02/28/%E6%95%99%E4%BD%A0%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%8CHexo-Github/" target="_blank" rel="noopener">教你免费搭建个人博客，Hexo&amp;Github</a></p><p>2.<a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">GitHub+Hexo 搭建个人网站详细教程</a></p>]]></content>
      
      <categories>
          
          <category> 博客开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 博客 </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ASCII、Unicode和UTF-8编码的区别</title>
      <link href="/61074/"/>
      <url>/61074/</url>
      <content type="html"><![CDATA[<h3 id="归纳"><a href="#归纳" class="headerlink" title="归纳"></a>归纳</h3><table><thead><tr><th>编码</th><th style="text-align:center">大小</th><th style="text-align:right">支持语言</th></tr></thead><tbody><tr><td>ASCII</td><td style="text-align:center">1个字节</td><td style="text-align:right">英文</td></tr><tr><td>Unicode</td><td style="text-align:center">2个字节（生僻字4个）</td><td style="text-align:right">所有语言</td></tr><tr><td>UTF-8</td><td style="text-align:center">1-6个字节，英文字母1个字节，汉字3个字节，生僻字4-6个字节</td><td style="text-align:right">所有语言</td></tr></tbody></table><h3 id="具体解释："><a href="#具体解释：" class="headerlink" title="具体解释："></a>具体解释：</h3><p>最早只有127个字母被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码，比如大写字母A的编码是65，小写字母z的编码是122。</p><p>但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。</p><p>你可以想得到的是，全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。</p><p>因此，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。</p><p>Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。</p><p>新的问题又出现了：如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。</p><p>所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间。</p><p>UTF-8编码有一个额外的好处，就是ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BC%96%E7%A0%81/9127611?fr=aladdin" target="_blank" rel="noopener">计算机编码_百度百科</a></p>]]></content>
      
      <categories>
          
          <category> 计算机原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编码 </tag>
            
        </tags>
      
    </entry>
    
  
  
    
    <entry>
      <title>about</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<p>Hello~I’m paradoxallen.</p>]]></content>
    </entry>
    
  
</search>
