<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习预测房价代码 | RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  <meta name="description" content="123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="机器学习预测房价代码"/>
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-24T16:00:00.000Z"><a href="/40260/">2017-12-25</a></time>
        
  
    <h1 class="title">机器学习预测房价代码</h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br></pre></td><td class="code"><pre><span class="line">&apos;&apos;&apos;</span><br><span class="line">analysis</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#scaning data</span><br><span class="line">#train data:1460*81 </span><br><span class="line">#test data: 14559*80</span><br><span class="line"></span><br><span class="line">#transtype</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">#missing data processing</span><br><span class="line">#large in amount depose</span><br><span class="line">#little in amount avarage</span><br><span class="line">#middle of the missing data treat as one-hot</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line"></span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">types = all_df[missing.index].dtypes</span><br><span class="line"></span><br><span class="line">percent = (all_df[missing.index].isnull().sum()/all_df[missing.index].isnull().count()).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">missing_data = pd.concat([missing, percent,types], axis=1, keys=[&apos;Total&apos;, &apos;Percent&apos;,&apos;Types&apos;])</span><br><span class="line">missing_data.sort_values(&apos;Total&apos;,ascending=False,inplace=True)</span><br><span class="line">missing_data</span><br><span class="line"></span><br><span class="line">missing.plot.bar()</span><br><span class="line"></span><br><span class="line">#analysis</span><br><span class="line">#single var</span><br><span class="line">train_df.describe()[&apos;SalePrice&apos;]</span><br><span class="line"></span><br><span class="line">#skewness and kurtosis</span><br><span class="line">print(&quot;Skewness: %f&quot; % train_df[&apos;SalePrice&apos;].skew())</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % train_df[&apos;SalePrice&apos;].kurt())</span><br><span class="line"></span><br><span class="line">#conrver</span><br><span class="line">corrmat = train_df.corr()</span><br><span class="line"></span><br><span class="line">#saleprice correlation matrix</span><br><span class="line">k = 10 #number of variables for heatmap</span><br><span class="line">cols = corrmat.nlargest(k, &apos;SalePrice&apos;)[&apos;SalePrice&apos;].index</span><br><span class="line">cm = np.corrcoef(train_df[cols].values.T)</span><br><span class="line">sns.set(font_scale=1.25)</span><br><span class="line">hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&apos;.2f&apos;, annot_kws=&#123;&apos;size&apos;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">## both corr and missing</span><br><span class="line">missing_data.index.intersection(cols)</span><br><span class="line"></span><br><span class="line">missing_data.loc[missing_data.index.intersection(cols)]</span><br><span class="line"></span><br><span class="line">#dealing with missing data</span><br><span class="line">all_df = all_df.drop((missing_data[missing_data[&apos;Total&apos;] &gt; 1]).index,1)</span><br><span class="line"># df_train = df_train.drop(df_train.loc[df_train[&apos;Electrical&apos;].isnull()].index)</span><br><span class="line">all_df.isnull().sum().max() #just checking that there&apos;s no missing data missing...</span><br><span class="line"># missing 1 replace with average</span><br><span class="line"></span><br><span class="line">#normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#log</span><br><span class="line">train_df[&apos;SalePrice&apos;] = np.log(train_df[&apos;SalePrice&apos;])</span><br><span class="line"></span><br><span class="line">#histogram and normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#observe every var</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">f = pd.melt(all_df, value_vars=quantitative)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False)</span><br><span class="line">g = g.map(sns.distplot, &quot;value&quot;)</span><br><span class="line"></span><br><span class="line">#LotArea,BsmtUnfSF,1stFlrSF,TotalBsmtSF,KitchenAbvGr can be improved by log</span><br><span class="line">#skewness</span><br><span class="line">all_df[quantitative].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">#quantity charctive analysis</span><br><span class="line">#Analysis of variance</span><br><span class="line">train = all_df.loc[train_df.index]</span><br><span class="line">train[&apos;SalePrice&apos;] = train_df.SalePrice</span><br><span class="line"></span><br><span class="line">def anova(frame):</span><br><span class="line">    anv = pd.DataFrame()</span><br><span class="line">    anv[&apos;feature&apos;] = qualitative</span><br><span class="line">    pvals = []</span><br><span class="line">    for c in qualitative:</span><br><span class="line">        samples = []</span><br><span class="line">        for cls in frame[c].unique():</span><br><span class="line">            s = frame[frame[c] == cls][&apos;SalePrice&apos;].values</span><br><span class="line">            samples.append(s)</span><br><span class="line">        pval = stats.f_oneway(*samples)[1]</span><br><span class="line">        pvals.append(pval)</span><br><span class="line">    anv[&apos;pval&apos;] = pvals</span><br><span class="line">    return anv.sort_values(&apos;pval&apos;)</span><br><span class="line"></span><br><span class="line">a = anova(train)</span><br><span class="line">a[&apos;disparity&apos;] = np.log(1./a[&apos;pval&apos;].values)</span><br><span class="line">sns.barplot(data=a, x=&apos;feature&apos;, y=&apos;disparity&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#quality charctive analysis</span><br><span class="line">def encode(frame, feature):</span><br><span class="line">    ordering = pd.DataFrame()</span><br><span class="line">    ordering[&apos;val&apos;] = frame[feature].unique()</span><br><span class="line">    ordering.index = ordering.val</span><br><span class="line">    ordering[&apos;spmean&apos;] = frame[[feature, &apos;SalePrice&apos;]].groupby(feature).mean()[&apos;SalePrice&apos;]</span><br><span class="line">    ordering = ordering.sort_values(&apos;spmean&apos;)</span><br><span class="line">    ordering[&apos;ordering&apos;] = range(1, ordering.shape[0]+1)</span><br><span class="line">    ordering = ordering[&apos;ordering&apos;].to_dict()</span><br><span class="line">    </span><br><span class="line">    for cat, o in ordering.items():</span><br><span class="line">        frame.loc[frame[feature] == cat, feature+&apos;_E&apos;] = o</span><br><span class="line">    </span><br><span class="line">qual_encoded = []</span><br><span class="line">for q in qualitative:  </span><br><span class="line">    encode(train, q)</span><br><span class="line">    qual_encoded.append(q+&apos;_E&apos;)</span><br><span class="line">print(qual_encoded)</span><br><span class="line"></span><br><span class="line"># choose raws of having missing data</span><br><span class="line">missing_data = all_df.isnull().sum()</span><br><span class="line">missing_data = missing_data[missing_data&gt;0]</span><br><span class="line">ids = all_df[missing_data.index].isnull()</span><br><span class="line"># index (0), columns (1)</span><br><span class="line">all_df.loc[ids[ids.any(axis=1)].index][missing_data.index]</span><br><span class="line"></span><br><span class="line"># nan still nan</span><br><span class="line">train.loc[1379,&apos;Electrical_E&apos;]</span><br><span class="line"></span><br><span class="line">#corr computing</span><br><span class="line">def spearman(frame, features):</span><br><span class="line">    spr = pd.DataFrame()</span><br><span class="line">    spr[&apos;feature&apos;] = features</span><br><span class="line">    #Signature: a.corr(other, method=&apos;pearson&apos;, min_periods=None)</span><br><span class="line">    #Docstring:</span><br><span class="line">    #Compute correlation with `other` Series, excluding missing values</span><br><span class="line">    # 计算特征和 SalePrice的 斯皮尔曼 相关系数</span><br><span class="line">    spr[&apos;spearman&apos;] = [frame[f].corr(frame[&apos;SalePrice&apos;], &apos;spearman&apos;) for f in features]</span><br><span class="line">    spr = spr.sort_values(&apos;spearman&apos;)</span><br><span class="line">    plt.figure(figsize=(6, 0.25*len(features))) # width, height</span><br><span class="line">    sns.barplot(data=spr, y=&apos;feature&apos;, x=&apos;spearman&apos;, orient=&apos;h&apos;)</span><br><span class="line">    </span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">spearman(train, features)</span><br><span class="line"># OverallQual Neighborhood GrLiveArea have bing influence on price</span><br><span class="line"></span><br><span class="line">#corr between vars</span><br><span class="line">plt.figure(1)</span><br><span class="line">corr = train[quantitative+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(2)</span><br><span class="line">corr = train[qual_encoded+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(3)</span><br><span class="line"># [31,27]</span><br><span class="line">corr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded)+1]), index=quantitative+[&apos;SalePrice&apos;], columns=qual_encoded+[&apos;SalePrice&apos;])</span><br><span class="line">for q1 in quantitative+[&apos;SalePrice&apos;]:</span><br><span class="line">    for q2 in qual_encoded+[&apos;SalePrice&apos;]:</span><br><span class="line">        corr.loc[q1, q2] = train[q1].corr(train[q2])</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line"></span><br><span class="line">#Pairplots</span><br><span class="line">def pairplot(x, y, **kwargs):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ts = pd.DataFrame(&#123;&apos;time&apos;: x, &apos;val&apos;: y&#125;)</span><br><span class="line">    ts = ts.groupby(&apos;time&apos;).mean()</span><br><span class="line">    ts.plot(ax=ax)</span><br><span class="line">    plt.xticks(rotation=90)</span><br><span class="line">    </span><br><span class="line">f = pd.melt(train, id_vars=[&apos;SalePrice&apos;], value_vars=quantitative+qual_encoded)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False, size=5)</span><br><span class="line">g = g.map(pairplot, &quot;value&quot;, &quot;SalePrice&quot;)</span><br><span class="line"></span><br><span class="line">#price departing</span><br><span class="line">a = train[&apos;SalePrice&apos;]</span><br><span class="line">a.plot.hist()</span><br><span class="line"></span><br><span class="line">features = quantitative</span><br><span class="line"></span><br><span class="line">standard = train[train[&apos;SalePrice&apos;] &lt; np.log(200000)]</span><br><span class="line">pricey = train[train[&apos;SalePrice&apos;] &gt;= np.log(200000)]</span><br><span class="line"></span><br><span class="line">diff = pd.DataFrame()</span><br><span class="line">diff[&apos;feature&apos;] = features</span><br><span class="line">diff[&apos;difference&apos;] = [(pricey[f].fillna(0.).mean() - standard[f].fillna(0.).mean())/(standard[f].fillna(0.).mean())</span><br><span class="line">                      for f in features]</span><br><span class="line"></span><br><span class="line">sns.barplot(data=diff, x=&apos;feature&apos;, y=&apos;difference&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#classfing</span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">model = TSNE(n_components=2, random_state=0, perplexity=50)</span><br><span class="line">X = train[features].fillna(0.).values</span><br><span class="line">tsne = model.fit_transform(X)</span><br><span class="line"></span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line">pca = PCA(n_components=30)</span><br><span class="line">pca.fit(s)</span><br><span class="line">pc = pca.transform(s)</span><br><span class="line">kmeans = KMeans(n_clusters=5)</span><br><span class="line">kmeans.fit(pc)</span><br><span class="line"></span><br><span class="line">fr = pd.DataFrame(&#123;&apos;tsne1&apos;: tsne[:,0], &apos;tsne2&apos;: tsne[:, 1], &apos;cluster&apos;: kmeans.labels_&#125;)</span><br><span class="line">sns.lmplot(data=fr, x=&apos;tsne1&apos;, y=&apos;tsne2&apos;, hue=&apos;cluster&apos;, fit_reg=False)</span><br><span class="line">print(np.sum(pca.explained_variance_ratio_))</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">model</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#feature engineering</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#dealing missing data</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">#missing 1 replaced with average</span><br><span class="line">all_df = all_df.drop(missing[missing&gt;1].index,1)</span><br><span class="line"></span><br><span class="line">all_df.isnull().sum()[all_df.isnull().sum()&gt;0]</span><br><span class="line"></span><br><span class="line">#dealing log(GrLivArea、1stFlrSF、2ndFlrSF、TotalBsmtSF、LotArea、KitchenAbvGr、GarageArea )</span><br><span class="line">logfeatures = [&apos;GrLivArea&apos;,&apos;1stFlrSF&apos;,&apos;2ndFlrSF&apos;,&apos;TotalBsmtSF&apos;,&apos;LotArea&apos;,&apos;KitchenAbvGr&apos;,&apos;GarageArea&apos;]</span><br><span class="line"></span><br><span class="line">for logfeature in logfeatures:</span><br><span class="line">    all_df[logfeature] = np.log1p(all_df[logfeature].values)</span><br><span class="line"></span><br><span class="line">#dealing boolean var</span><br><span class="line">all_df[&apos;HasBasement&apos;] = all_df[&apos;TotalBsmtSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasGarage&apos;] = all_df[&apos;GarageArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;Has2ndFloor&apos;] = all_df[&apos;2ndFlrSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasWoodDeck&apos;] = all_df[&apos;WoodDeckSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPorch&apos;] = all_df[&apos;OpenPorchSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPool&apos;] = all_df[&apos;PoolArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;IsNew&apos;] = all_df[&apos;YearBuilt&apos;].apply(lambda x: 1 if x &gt; 2000 else 0)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#encode quanlity</span><br><span class="line">all_dummy_df = pd.get_dummies(all_df)</span><br><span class="line"></span><br><span class="line">#standize var</span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">mean_cols = all_dummy_df.mean()</span><br><span class="line">all_dummy_df = all_dummy_df.fillna(mean_cols)</span><br><span class="line"></span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">X = all_dummy_df[quantitative]</span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line"></span><br><span class="line">all_dummy_df[quantitative] = s</span><br><span class="line"></span><br><span class="line">dummy_train_df = all_dummy_df.loc[train_df.index]</span><br><span class="line">dummy_test_df = all_dummy_df.loc[test_df.index]</span><br><span class="line"></span><br><span class="line">y_train = np.log(train_df.SalePrice)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#model predicting</span><br><span class="line">#ridge regression</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">y_train.values</span><br><span class="line"></span><br><span class="line">def rmse_cv(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, dummy_train_df, y_train.values, scoring=&quot;neg_mean_squared_error&quot;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line">alphas = np.logspace(-3, 2, 50)</span><br><span class="line">cv_ridge = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Ridge(alpha = alpha)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_ridge.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">cv_ridge = pd.Series(cv_ridge, index = alphas)</span><br><span class="line">cv_ridge.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;)</span><br><span class="line"></span><br><span class="line">#ridge trace picture</span><br><span class="line"># matplotlib.rcParams[&apos;figure.figsize&apos;] = (12.0, 12.0)</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line"># ax.set_color_cycle([&apos;b&apos;, &apos;r&apos;, &apos;g&apos;, &apos;c&apos;, &apos;k&apos;, &apos;y&apos;, &apos;m&apos;])</span><br><span class="line"></span><br><span class="line">ax.plot(alphas, coefs)</span><br><span class="line">ax.set_xscale(&apos;log&apos;)</span><br><span class="line">ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span><br><span class="line">plt.xlabel(&apos;alpha&apos;)</span><br><span class="line">plt.ylabel(&apos;weights&apos;)</span><br><span class="line">plt.title(&apos;Ridge coefficients as a function of the regularization&apos;)</span><br><span class="line">plt.axis(&apos;tight&apos;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#lesso :can choose some of feature</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line"></span><br><span class="line"># alphas = np.logspace(-3, 2, 50)</span><br><span class="line"># alphas = [1, 0.1, 0.001, 0.0005]</span><br><span class="line">alphas = np.logspace(-4, -2, 100)</span><br><span class="line">cv_lasso = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Lasso(alpha = alpha,max_iter=5000)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_lasso.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line"></span><br><span class="line">cv_lasso = pd.Series(cv_lasso, index = alphas)</span><br><span class="line">cv_lasso.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;</span><br><span class="line"></span><br><span class="line">print(cv_lasso.min(), cv_lasso.argmin())</span><br><span class="line"></span><br><span class="line">model = Lasso(alpha = 0.00058,max_iter=5000)</span><br><span class="line">model.fit(dummy_train_df,y_train)</span><br><span class="line">Lasso(alpha=0.00058, copy_X=True, fit_intercept=True, max_iter=5000,</span><br><span class="line">   normalize=False, positive=False, precompute=False, random_state=None,</span><br><span class="line">   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</span><br><span class="line">coef = pd.Series(model.coef_, index = dummy_train_df.columns)</span><br><span class="line">print(&quot;Lasso picked &quot; + str(sum(coef != 0)) + &quot; variables and eliminated the other &quot; +  str(sum(coef == 0)) + &quot; variables&quot;)</span><br><span class="line"></span><br><span class="line">imp_coef = pd.concat([coef.sort_values().head(10),</span><br><span class="line">                     coef.sort_values().tail(10)])</span><br><span class="line">matplotlib.rcParams[&apos;figure.figsize&apos;] = (8.0, 10.0)</span><br><span class="line">imp_coef.plot(kind = &quot;barh&quot;)</span><br><span class="line">plt.title(&quot;Coefficients in the Lasso Model&quot;)</span><br><span class="line"></span><br><span class="line">#Elastic Net :connect with lasso and ridge</span><br><span class="line"></span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=5000)</span><br><span class="line">elastic.fit(dummy_train_df, y_train)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=5000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line">rmse_cv(elastic).mean()</span><br><span class="line"></span><br><span class="line">#feature engineering 2 (another methon)</span><br><span class="line">import utils</span><br><span class="line">train_df_munged,label_df,test_df_munged = utils.feature_engineering()</span><br><span class="line"></span><br><span class="line">test_df = pd.read_csv(&apos;../input/test.csv&apos;)</span><br><span class="line">from sklearn.metrics import mean_squared_error,make_scorer</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"># 定义自己的score函数</span><br><span class="line">def my_custom_loss_func(ground_truth, predictions):</span><br><span class="line">    return np.sqrt(mean_squared_error(np.exp(ground_truth), np.exp(predictions)))</span><br><span class="line"></span><br><span class="line">my_loss_func  = make_scorer(my_custom_loss_func, greater_is_better=False)</span><br><span class="line">def rmse_cv2(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, train_df_munged, label_df.SalePrice, scoring=&apos;neg_mean_squared_error&apos;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line"></span><br><span class="line">#ridge2</span><br><span class="line">from sklearn.linear_model import RidgeCV,Ridge</span><br><span class="line">alphas = np.logspace(-3, 2, 100)</span><br><span class="line">model_ridge = RidgeCV(alphas=alphas).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_ridge = model_ridge.predict(train_df_munged)</span><br><span class="line">print(&quot;Ridge score on training set: &quot;, model_ridge.score(train_df_munged,label_df.SalePrice))</span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_ridge).mean())</span><br><span class="line"></span><br><span class="line">#lasso2</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line">model_lasso = LassoCV(eps=0.0001,max_iter=20000).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_lasso = model_lasso.predict(train_df_munged)</span><br><span class="line">print(&quot;Lasso score on training set: &quot;, model_lasso.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_lasso).mean())</span><br><span class="line"></span><br><span class="line">#Elastic Net</span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">model_elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=10000)</span><br><span class="line">model_elastic.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=10000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_elastic = model_elastic.predict(train_df_munged)</span><br><span class="line">print(&quot;Elastic score on training set: &quot;, model_elastic.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_elastic).mean())</span><br><span class="line"></span><br><span class="line">#XGBoost</span><br><span class="line"># XGBoost -- I did some &quot;manual&quot; cross-validation here but should really find</span><br><span class="line"># these hyperparameters using CV. ;-)</span><br><span class="line"></span><br><span class="line">import xgboost as xgb</span><br><span class="line"></span><br><span class="line">model_xgb = xgb.XGBRegressor(</span><br><span class="line">                 colsample_bytree=0.2,</span><br><span class="line">                 gamma=0.0,</span><br><span class="line">                 learning_rate=0.05,</span><br><span class="line">                 max_depth=6,</span><br><span class="line">                 min_child_weight=1.5,</span><br><span class="line">                 n_estimators=7200,                                                                  </span><br><span class="line">                 reg_alpha=0.9,</span><br><span class="line">                 reg_lambda=0.6,</span><br><span class="line">                 subsample=0.2,</span><br><span class="line">                 seed=42,</span><br><span class="line">                 silent=1)</span><br><span class="line"></span><br><span class="line">model_xgb.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"></span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_xgb = model_xgb.predict(train_df_munged)</span><br><span class="line">print(&quot;XGBoost score on training set: &quot;, model_xgb.score(train_df_munged,label_df.SalePrice)) # 过拟合</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_xgb).mean())</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(model_xgb.predict(train_df_munged),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#Ensemble</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"># Create linear regression object</span><br><span class="line">regr = LinearRegression()</span><br><span class="line">train_x = np.concatenate(</span><br><span class="line">    (pred_Y_lasso[np.newaxis, :].T,pred_Y_ridge[np.newaxis, :].T,</span><br><span class="line">     pred_Y_elastic[np.newaxis, :].T,pred_Y_xgb[np.newaxis, :].T), axis=1)</span><br><span class="line">regr.fit(train_x,label_df.SalePrice)</span><br><span class="line">LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</span><br><span class="line">regr.coef_</span><br><span class="line"></span><br><span class="line">print(&quot;Ensemble score on training set: &quot;, regr.score(train_x,label_df.SalePrice)) # overfitting</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(regr.predict(train_x),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#submit</span><br><span class="line">model_lasso.predict(test_df_munged)[np.newaxis, :].T</span><br><span class="line"></span><br><span class="line">test_x = np.concatenate(</span><br><span class="line">(model_lasso.predict(test_df_munged)[np.newaxis, :].T,model_ridge.predict(test_df_munged)[np.newaxis, :].T,</span><br><span class="line">                           model_elastic.predict(test_df_munged)[np.newaxis, :].T, model_xgb.predict(test_df_munged)[np.newaxis, :].T)</span><br><span class="line">        ,axis=1)</span><br><span class="line">y_final = regr.predict(test_x)</span><br><span class="line">y_final</span><br><span class="line"></span><br><span class="line">submission_df = pd.DataFrame(data= &#123;&apos;Id&apos; : test_df.Id, &apos;SalePrice&apos;: np.exp(y_final)&#125;)</span><br><span class="line">submission_df.to_csv(&quot;bag-4.csv&quot;,index=False) # conceal index</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/机器学习/">机器学习</a>
  </div>

        
  <div class="tags">
    <a href="/tags/机器学习/">机器学习</a>
  </div>

        
  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a><a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a></div>
  <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div></div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据挖掘/">数据挖掘</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">26</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 12.5px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.75px;">Machine Learning 课程笔记</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/SQL/" style="font-size: 13.75px;">SQL</a> <a href="/tags/hexo/" style="font-size: 11.25px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.25px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/提问/" style="font-size: 10px;">提问</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.25px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 12.5px;">模型</a> <a href="/tags/爬虫/" style="font-size: 17.5px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.25px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2020 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>