<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第 2 页 | RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper">
    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-24T16:00:00.000Z"><a href="/40260/">2017-12-25</a></time>
        
  
    <h1 class="title"><a href="/40260/">机器学习预测房价代码</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br></pre></td><td class="code"><pre><span class="line">&apos;&apos;&apos;</span><br><span class="line">analysis</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#scaning data</span><br><span class="line">#train data:1460*81 </span><br><span class="line">#test data: 14559*80</span><br><span class="line"></span><br><span class="line">#transtype</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">#missing data processing</span><br><span class="line">#large in amount depose</span><br><span class="line">#little in amount avarage</span><br><span class="line">#middle of the missing data treat as one-hot</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line"></span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">types = all_df[missing.index].dtypes</span><br><span class="line"></span><br><span class="line">percent = (all_df[missing.index].isnull().sum()/all_df[missing.index].isnull().count()).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">missing_data = pd.concat([missing, percent,types], axis=1, keys=[&apos;Total&apos;, &apos;Percent&apos;,&apos;Types&apos;])</span><br><span class="line">missing_data.sort_values(&apos;Total&apos;,ascending=False,inplace=True)</span><br><span class="line">missing_data</span><br><span class="line"></span><br><span class="line">missing.plot.bar()</span><br><span class="line"></span><br><span class="line">#analysis</span><br><span class="line">#single var</span><br><span class="line">train_df.describe()[&apos;SalePrice&apos;]</span><br><span class="line"></span><br><span class="line">#skewness and kurtosis</span><br><span class="line">print(&quot;Skewness: %f&quot; % train_df[&apos;SalePrice&apos;].skew())</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % train_df[&apos;SalePrice&apos;].kurt())</span><br><span class="line"></span><br><span class="line">#conrver</span><br><span class="line">corrmat = train_df.corr()</span><br><span class="line"></span><br><span class="line">#saleprice correlation matrix</span><br><span class="line">k = 10 #number of variables for heatmap</span><br><span class="line">cols = corrmat.nlargest(k, &apos;SalePrice&apos;)[&apos;SalePrice&apos;].index</span><br><span class="line">cm = np.corrcoef(train_df[cols].values.T)</span><br><span class="line">sns.set(font_scale=1.25)</span><br><span class="line">hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&apos;.2f&apos;, annot_kws=&#123;&apos;size&apos;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">## both corr and missing</span><br><span class="line">missing_data.index.intersection(cols)</span><br><span class="line"></span><br><span class="line">missing_data.loc[missing_data.index.intersection(cols)]</span><br><span class="line"></span><br><span class="line">#dealing with missing data</span><br><span class="line">all_df = all_df.drop((missing_data[missing_data[&apos;Total&apos;] &gt; 1]).index,1)</span><br><span class="line"># df_train = df_train.drop(df_train.loc[df_train[&apos;Electrical&apos;].isnull()].index)</span><br><span class="line">all_df.isnull().sum().max() #just checking that there&apos;s no missing data missing...</span><br><span class="line"># missing 1 replace with average</span><br><span class="line"></span><br><span class="line">#normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#log</span><br><span class="line">train_df[&apos;SalePrice&apos;] = np.log(train_df[&apos;SalePrice&apos;])</span><br><span class="line"></span><br><span class="line">#histogram and normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#observe every var</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">f = pd.melt(all_df, value_vars=quantitative)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False)</span><br><span class="line">g = g.map(sns.distplot, &quot;value&quot;)</span><br><span class="line"></span><br><span class="line">#LotArea,BsmtUnfSF,1stFlrSF,TotalBsmtSF,KitchenAbvGr can be improved by log</span><br><span class="line">#skewness</span><br><span class="line">all_df[quantitative].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">#quantity charctive analysis</span><br><span class="line">#Analysis of variance</span><br><span class="line">train = all_df.loc[train_df.index]</span><br><span class="line">train[&apos;SalePrice&apos;] = train_df.SalePrice</span><br><span class="line"></span><br><span class="line">def anova(frame):</span><br><span class="line">    anv = pd.DataFrame()</span><br><span class="line">    anv[&apos;feature&apos;] = qualitative</span><br><span class="line">    pvals = []</span><br><span class="line">    for c in qualitative:</span><br><span class="line">        samples = []</span><br><span class="line">        for cls in frame[c].unique():</span><br><span class="line">            s = frame[frame[c] == cls][&apos;SalePrice&apos;].values</span><br><span class="line">            samples.append(s)</span><br><span class="line">        pval = stats.f_oneway(*samples)[1]</span><br><span class="line">        pvals.append(pval)</span><br><span class="line">    anv[&apos;pval&apos;] = pvals</span><br><span class="line">    return anv.sort_values(&apos;pval&apos;)</span><br><span class="line"></span><br><span class="line">a = anova(train)</span><br><span class="line">a[&apos;disparity&apos;] = np.log(1./a[&apos;pval&apos;].values)</span><br><span class="line">sns.barplot(data=a, x=&apos;feature&apos;, y=&apos;disparity&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#quality charctive analysis</span><br><span class="line">def encode(frame, feature):</span><br><span class="line">    ordering = pd.DataFrame()</span><br><span class="line">    ordering[&apos;val&apos;] = frame[feature].unique()</span><br><span class="line">    ordering.index = ordering.val</span><br><span class="line">    ordering[&apos;spmean&apos;] = frame[[feature, &apos;SalePrice&apos;]].groupby(feature).mean()[&apos;SalePrice&apos;]</span><br><span class="line">    ordering = ordering.sort_values(&apos;spmean&apos;)</span><br><span class="line">    ordering[&apos;ordering&apos;] = range(1, ordering.shape[0]+1)</span><br><span class="line">    ordering = ordering[&apos;ordering&apos;].to_dict()</span><br><span class="line">    </span><br><span class="line">    for cat, o in ordering.items():</span><br><span class="line">        frame.loc[frame[feature] == cat, feature+&apos;_E&apos;] = o</span><br><span class="line">    </span><br><span class="line">qual_encoded = []</span><br><span class="line">for q in qualitative:  </span><br><span class="line">    encode(train, q)</span><br><span class="line">    qual_encoded.append(q+&apos;_E&apos;)</span><br><span class="line">print(qual_encoded)</span><br><span class="line"></span><br><span class="line"># choose raws of having missing data</span><br><span class="line">missing_data = all_df.isnull().sum()</span><br><span class="line">missing_data = missing_data[missing_data&gt;0]</span><br><span class="line">ids = all_df[missing_data.index].isnull()</span><br><span class="line"># index (0), columns (1)</span><br><span class="line">all_df.loc[ids[ids.any(axis=1)].index][missing_data.index]</span><br><span class="line"></span><br><span class="line"># nan still nan</span><br><span class="line">train.loc[1379,&apos;Electrical_E&apos;]</span><br><span class="line"></span><br><span class="line">#corr computing</span><br><span class="line">def spearman(frame, features):</span><br><span class="line">    spr = pd.DataFrame()</span><br><span class="line">    spr[&apos;feature&apos;] = features</span><br><span class="line">    #Signature: a.corr(other, method=&apos;pearson&apos;, min_periods=None)</span><br><span class="line">    #Docstring:</span><br><span class="line">    #Compute correlation with `other` Series, excluding missing values</span><br><span class="line">    # 计算特征和 SalePrice的 斯皮尔曼 相关系数</span><br><span class="line">    spr[&apos;spearman&apos;] = [frame[f].corr(frame[&apos;SalePrice&apos;], &apos;spearman&apos;) for f in features]</span><br><span class="line">    spr = spr.sort_values(&apos;spearman&apos;)</span><br><span class="line">    plt.figure(figsize=(6, 0.25*len(features))) # width, height</span><br><span class="line">    sns.barplot(data=spr, y=&apos;feature&apos;, x=&apos;spearman&apos;, orient=&apos;h&apos;)</span><br><span class="line">    </span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">spearman(train, features)</span><br><span class="line"># OverallQual Neighborhood GrLiveArea have bing influence on price</span><br><span class="line"></span><br><span class="line">#corr between vars</span><br><span class="line">plt.figure(1)</span><br><span class="line">corr = train[quantitative+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(2)</span><br><span class="line">corr = train[qual_encoded+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(3)</span><br><span class="line"># [31,27]</span><br><span class="line">corr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded)+1]), index=quantitative+[&apos;SalePrice&apos;], columns=qual_encoded+[&apos;SalePrice&apos;])</span><br><span class="line">for q1 in quantitative+[&apos;SalePrice&apos;]:</span><br><span class="line">    for q2 in qual_encoded+[&apos;SalePrice&apos;]:</span><br><span class="line">        corr.loc[q1, q2] = train[q1].corr(train[q2])</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line"></span><br><span class="line">#Pairplots</span><br><span class="line">def pairplot(x, y, **kwargs):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ts = pd.DataFrame(&#123;&apos;time&apos;: x, &apos;val&apos;: y&#125;)</span><br><span class="line">    ts = ts.groupby(&apos;time&apos;).mean()</span><br><span class="line">    ts.plot(ax=ax)</span><br><span class="line">    plt.xticks(rotation=90)</span><br><span class="line">    </span><br><span class="line">f = pd.melt(train, id_vars=[&apos;SalePrice&apos;], value_vars=quantitative+qual_encoded)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False, size=5)</span><br><span class="line">g = g.map(pairplot, &quot;value&quot;, &quot;SalePrice&quot;)</span><br><span class="line"></span><br><span class="line">#price departing</span><br><span class="line">a = train[&apos;SalePrice&apos;]</span><br><span class="line">a.plot.hist()</span><br><span class="line"></span><br><span class="line">features = quantitative</span><br><span class="line"></span><br><span class="line">standard = train[train[&apos;SalePrice&apos;] &lt; np.log(200000)]</span><br><span class="line">pricey = train[train[&apos;SalePrice&apos;] &gt;= np.log(200000)]</span><br><span class="line"></span><br><span class="line">diff = pd.DataFrame()</span><br><span class="line">diff[&apos;feature&apos;] = features</span><br><span class="line">diff[&apos;difference&apos;] = [(pricey[f].fillna(0.).mean() - standard[f].fillna(0.).mean())/(standard[f].fillna(0.).mean())</span><br><span class="line">                      for f in features]</span><br><span class="line"></span><br><span class="line">sns.barplot(data=diff, x=&apos;feature&apos;, y=&apos;difference&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#classfing</span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">model = TSNE(n_components=2, random_state=0, perplexity=50)</span><br><span class="line">X = train[features].fillna(0.).values</span><br><span class="line">tsne = model.fit_transform(X)</span><br><span class="line"></span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line">pca = PCA(n_components=30)</span><br><span class="line">pca.fit(s)</span><br><span class="line">pc = pca.transform(s)</span><br><span class="line">kmeans = KMeans(n_clusters=5)</span><br><span class="line">kmeans.fit(pc)</span><br><span class="line"></span><br><span class="line">fr = pd.DataFrame(&#123;&apos;tsne1&apos;: tsne[:,0], &apos;tsne2&apos;: tsne[:, 1], &apos;cluster&apos;: kmeans.labels_&#125;)</span><br><span class="line">sns.lmplot(data=fr, x=&apos;tsne1&apos;, y=&apos;tsne2&apos;, hue=&apos;cluster&apos;, fit_reg=False)</span><br><span class="line">print(np.sum(pca.explained_variance_ratio_))</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">model</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#feature engineering</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#dealing missing data</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">#missing 1 replaced with average</span><br><span class="line">all_df = all_df.drop(missing[missing&gt;1].index,1)</span><br><span class="line"></span><br><span class="line">all_df.isnull().sum()[all_df.isnull().sum()&gt;0]</span><br><span class="line"></span><br><span class="line">#dealing log(GrLivArea、1stFlrSF、2ndFlrSF、TotalBsmtSF、LotArea、KitchenAbvGr、GarageArea )</span><br><span class="line">logfeatures = [&apos;GrLivArea&apos;,&apos;1stFlrSF&apos;,&apos;2ndFlrSF&apos;,&apos;TotalBsmtSF&apos;,&apos;LotArea&apos;,&apos;KitchenAbvGr&apos;,&apos;GarageArea&apos;]</span><br><span class="line"></span><br><span class="line">for logfeature in logfeatures:</span><br><span class="line">    all_df[logfeature] = np.log1p(all_df[logfeature].values)</span><br><span class="line"></span><br><span class="line">#dealing boolean var</span><br><span class="line">all_df[&apos;HasBasement&apos;] = all_df[&apos;TotalBsmtSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasGarage&apos;] = all_df[&apos;GarageArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;Has2ndFloor&apos;] = all_df[&apos;2ndFlrSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasWoodDeck&apos;] = all_df[&apos;WoodDeckSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPorch&apos;] = all_df[&apos;OpenPorchSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPool&apos;] = all_df[&apos;PoolArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;IsNew&apos;] = all_df[&apos;YearBuilt&apos;].apply(lambda x: 1 if x &gt; 2000 else 0)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#encode quanlity</span><br><span class="line">all_dummy_df = pd.get_dummies(all_df)</span><br><span class="line"></span><br><span class="line">#standize var</span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">mean_cols = all_dummy_df.mean()</span><br><span class="line">all_dummy_df = all_dummy_df.fillna(mean_cols)</span><br><span class="line"></span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">X = all_dummy_df[quantitative]</span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line"></span><br><span class="line">all_dummy_df[quantitative] = s</span><br><span class="line"></span><br><span class="line">dummy_train_df = all_dummy_df.loc[train_df.index]</span><br><span class="line">dummy_test_df = all_dummy_df.loc[test_df.index]</span><br><span class="line"></span><br><span class="line">y_train = np.log(train_df.SalePrice)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#model predicting</span><br><span class="line">#ridge regression</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">y_train.values</span><br><span class="line"></span><br><span class="line">def rmse_cv(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, dummy_train_df, y_train.values, scoring=&quot;neg_mean_squared_error&quot;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line">alphas = np.logspace(-3, 2, 50)</span><br><span class="line">cv_ridge = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Ridge(alpha = alpha)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_ridge.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">cv_ridge = pd.Series(cv_ridge, index = alphas)</span><br><span class="line">cv_ridge.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;)</span><br><span class="line"></span><br><span class="line">#ridge trace picture</span><br><span class="line"># matplotlib.rcParams[&apos;figure.figsize&apos;] = (12.0, 12.0)</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line"># ax.set_color_cycle([&apos;b&apos;, &apos;r&apos;, &apos;g&apos;, &apos;c&apos;, &apos;k&apos;, &apos;y&apos;, &apos;m&apos;])</span><br><span class="line"></span><br><span class="line">ax.plot(alphas, coefs)</span><br><span class="line">ax.set_xscale(&apos;log&apos;)</span><br><span class="line">ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span><br><span class="line">plt.xlabel(&apos;alpha&apos;)</span><br><span class="line">plt.ylabel(&apos;weights&apos;)</span><br><span class="line">plt.title(&apos;Ridge coefficients as a function of the regularization&apos;)</span><br><span class="line">plt.axis(&apos;tight&apos;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#lesso :can choose some of feature</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line"></span><br><span class="line"># alphas = np.logspace(-3, 2, 50)</span><br><span class="line"># alphas = [1, 0.1, 0.001, 0.0005]</span><br><span class="line">alphas = np.logspace(-4, -2, 100)</span><br><span class="line">cv_lasso = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Lasso(alpha = alpha,max_iter=5000)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_lasso.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line"></span><br><span class="line">cv_lasso = pd.Series(cv_lasso, index = alphas)</span><br><span class="line">cv_lasso.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;</span><br><span class="line"></span><br><span class="line">print(cv_lasso.min(), cv_lasso.argmin())</span><br><span class="line"></span><br><span class="line">model = Lasso(alpha = 0.00058,max_iter=5000)</span><br><span class="line">model.fit(dummy_train_df,y_train)</span><br><span class="line">Lasso(alpha=0.00058, copy_X=True, fit_intercept=True, max_iter=5000,</span><br><span class="line">   normalize=False, positive=False, precompute=False, random_state=None,</span><br><span class="line">   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</span><br><span class="line">coef = pd.Series(model.coef_, index = dummy_train_df.columns)</span><br><span class="line">print(&quot;Lasso picked &quot; + str(sum(coef != 0)) + &quot; variables and eliminated the other &quot; +  str(sum(coef == 0)) + &quot; variables&quot;)</span><br><span class="line"></span><br><span class="line">imp_coef = pd.concat([coef.sort_values().head(10),</span><br><span class="line">                     coef.sort_values().tail(10)])</span><br><span class="line">matplotlib.rcParams[&apos;figure.figsize&apos;] = (8.0, 10.0)</span><br><span class="line">imp_coef.plot(kind = &quot;barh&quot;)</span><br><span class="line">plt.title(&quot;Coefficients in the Lasso Model&quot;)</span><br><span class="line"></span><br><span class="line">#Elastic Net :connect with lasso and ridge</span><br><span class="line"></span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=5000)</span><br><span class="line">elastic.fit(dummy_train_df, y_train)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=5000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line">rmse_cv(elastic).mean()</span><br><span class="line"></span><br><span class="line">#feature engineering 2 (another methon)</span><br><span class="line">import utils</span><br><span class="line">train_df_munged,label_df,test_df_munged = utils.feature_engineering()</span><br><span class="line"></span><br><span class="line">test_df = pd.read_csv(&apos;../input/test.csv&apos;)</span><br><span class="line">from sklearn.metrics import mean_squared_error,make_scorer</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"># 定义自己的score函数</span><br><span class="line">def my_custom_loss_func(ground_truth, predictions):</span><br><span class="line">    return np.sqrt(mean_squared_error(np.exp(ground_truth), np.exp(predictions)))</span><br><span class="line"></span><br><span class="line">my_loss_func  = make_scorer(my_custom_loss_func, greater_is_better=False)</span><br><span class="line">def rmse_cv2(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, train_df_munged, label_df.SalePrice, scoring=&apos;neg_mean_squared_error&apos;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line"></span><br><span class="line">#ridge2</span><br><span class="line">from sklearn.linear_model import RidgeCV,Ridge</span><br><span class="line">alphas = np.logspace(-3, 2, 100)</span><br><span class="line">model_ridge = RidgeCV(alphas=alphas).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_ridge = model_ridge.predict(train_df_munged)</span><br><span class="line">print(&quot;Ridge score on training set: &quot;, model_ridge.score(train_df_munged,label_df.SalePrice))</span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_ridge).mean())</span><br><span class="line"></span><br><span class="line">#lasso2</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line">model_lasso = LassoCV(eps=0.0001,max_iter=20000).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_lasso = model_lasso.predict(train_df_munged)</span><br><span class="line">print(&quot;Lasso score on training set: &quot;, model_lasso.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_lasso).mean())</span><br><span class="line"></span><br><span class="line">#Elastic Net</span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">model_elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=10000)</span><br><span class="line">model_elastic.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=10000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_elastic = model_elastic.predict(train_df_munged)</span><br><span class="line">print(&quot;Elastic score on training set: &quot;, model_elastic.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_elastic).mean())</span><br><span class="line"></span><br><span class="line">#XGBoost</span><br><span class="line"># XGBoost -- I did some &quot;manual&quot; cross-validation here but should really find</span><br><span class="line"># these hyperparameters using CV. ;-)</span><br><span class="line"></span><br><span class="line">import xgboost as xgb</span><br><span class="line"></span><br><span class="line">model_xgb = xgb.XGBRegressor(</span><br><span class="line">                 colsample_bytree=0.2,</span><br><span class="line">                 gamma=0.0,</span><br><span class="line">                 learning_rate=0.05,</span><br><span class="line">                 max_depth=6,</span><br><span class="line">                 min_child_weight=1.5,</span><br><span class="line">                 n_estimators=7200,                                                                  </span><br><span class="line">                 reg_alpha=0.9,</span><br><span class="line">                 reg_lambda=0.6,</span><br><span class="line">                 subsample=0.2,</span><br><span class="line">                 seed=42,</span><br><span class="line">                 silent=1)</span><br><span class="line"></span><br><span class="line">model_xgb.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"></span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_xgb = model_xgb.predict(train_df_munged)</span><br><span class="line">print(&quot;XGBoost score on training set: &quot;, model_xgb.score(train_df_munged,label_df.SalePrice)) # 过拟合</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_xgb).mean())</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(model_xgb.predict(train_df_munged),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#Ensemble</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"># Create linear regression object</span><br><span class="line">regr = LinearRegression()</span><br><span class="line">train_x = np.concatenate(</span><br><span class="line">    (pred_Y_lasso[np.newaxis, :].T,pred_Y_ridge[np.newaxis, :].T,</span><br><span class="line">     pred_Y_elastic[np.newaxis, :].T,pred_Y_xgb[np.newaxis, :].T), axis=1)</span><br><span class="line">regr.fit(train_x,label_df.SalePrice)</span><br><span class="line">LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</span><br><span class="line">regr.coef_</span><br><span class="line"></span><br><span class="line">print(&quot;Ensemble score on training set: &quot;, regr.score(train_x,label_df.SalePrice)) # overfitting</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(regr.predict(train_x),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#submit</span><br><span class="line">model_lasso.predict(test_df_munged)[np.newaxis, :].T</span><br><span class="line"></span><br><span class="line">test_x = np.concatenate(</span><br><span class="line">(model_lasso.predict(test_df_munged)[np.newaxis, :].T,model_ridge.predict(test_df_munged)[np.newaxis, :].T,</span><br><span class="line">                           model_elastic.predict(test_df_munged)[np.newaxis, :].T, model_xgb.predict(test_df_munged)[np.newaxis, :].T)</span><br><span class="line">        ,axis=1)</span><br><span class="line">y_final = regr.predict(test_x)</span><br><span class="line">y_final</span><br><span class="line"></span><br><span class="line">submission_df = pd.DataFrame(data= &#123;&apos;Id&apos; : test_df.Id, &apos;SalePrice&apos;: np.exp(y_final)&#125;)</span><br><span class="line">submission_df.to_csv(&quot;bag-4.csv&quot;,index=False) # conceal index</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-09T16:00:00.000Z"><a href="/41954/">2017-12-10</a></time>
        
  
    <h1 class="title"><a href="/41954/">异步IO</a></h1>
  

    </header>

    <div class="entry">
      
        <p>在IO编程一节中，我们已经知道，CPU的速度远远快于磁盘、网络等IO。在一个线程中，CPU执行代码的速度极快，然而，一旦遇到IO操作，如读写文件、发送网络数据时，就需要等待IO操作完成，才能继续进行下一步操作。这种情况称为同步IO。</p>
<p>在IO操作的过程中，当前线程被挂起，而其他需要CPU执行的代码就无法被当前线程执行了。</p>
<p>因为一个IO操作就阻塞了当前线程，导致其他代码无法执行，所以我们必须使用多线程或者多进程来并发执行代码，为多个用户服务。每个用户都会分配一个线程，如果遇到IO导致线程被挂起，其他用户的线程不受影响。</p>
<p>多线程和多进程的模型虽然解决了并发问题，但是系统不能无上限地增加线程。由于系统切换线程的开销也很大，所以，一旦线程数量过多，CPU的时间就花在线程切换上了，真正运行代码的时间就少了，结果导致性能严重下降。</p>
<p>由于我们要解决的问题是CPU高速执行能力和IO设备的龟速严重不匹配，多线程和多进程只是解决这一问题的一种方法。</p>
<p>另一种解决IO问题的方法是异步IO。当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。</p>
<p>可以想象如果按普通顺序写出的代码实际上是没法完成异步IO的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">do_some_code()</span><br><span class="line">f = open(&apos;/path/to/file&apos;, &apos;r&apos;)</span><br><span class="line">r = f.read() # &lt;== 线程停在此处等待IO操作结果</span><br><span class="line"># IO操作完成后线程才能继续执行:</span><br><span class="line">do_some_code(r)</span><br></pre></td></tr></table></figure></p>
<p>所以，同步IO模型的代码是无法实现异步IO模型的。</p>
<p>异步IO模型需要一个消息循环，在消息循环中，主线程不断地重复“读取消息-处理消息”这一过程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loop = get_event_loop()</span><br><span class="line">while True:</span><br><span class="line">    event = loop.get_event()</span><br><span class="line">    process_event(event)</span><br></pre></td></tr></table></figure></p>
<p>消息模型其实早在应用在桌面应用程序中了。一个GUI程序的主线程就负责不停地读取消息并处理消息。所有的键盘、鼠标等消息都被发送到GUI程序的消息队列中，然后由GUI程序的主线程处理。</p>
<p>由于GUI线程处理键盘、鼠标等消息的速度非常快，所以用户感觉不到延迟。某些时候，GUI线程在一个消息处理的过程中遇到问题导致一次消息处理时间过长，此时，用户会感觉到整个GUI程序停止响应了，敲键盘、点鼠标都没有反应。这种情况说明在消息模型中，处理一个消息必须非常迅速，否则，主线程将无法及时处理消息队列中的其他消息，导致程序看上去停止响应。</p>
<p>消息模型是如何解决同步IO必须等待IO操作这一问题的呢？当遇到IO操作时，代码只负责发出IO请求，不等待IO结果，然后直接结束本轮消息处理，进入下一轮消息处理过程。当IO操作完成后，将收到一条“IO完成”的消息，处理该消息时就可以直接获取IO操作结果。</p>
<p>在“发出IO请求”到收到“IO完成”的这段时间里，同步IO模型下，主线程只能挂起，但异步IO模型下，主线程并没有休息，而是在消息循环中继续处理其他消息。这样，在异步IO模型下，一个线程就可以同时处理多个IO请求，并且没有切换线程的操作。对于大多数IO密集型的应用程序，使用异步IO将大大提升系统的多任务处理能力。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/41954/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-01T16:00:00.000Z"><a href="/55836/">2017-12-02</a></time>
        
  
    <h1 class="title"><a href="/55836/">Python访问数据库</a></h1>
  

    </header>

    <div class="entry">
      
        <p>程序运行的时候，数据都是在内存中的。当程序终止的时候，通常都需要将数据保存到磁盘上，无论是保存到本地磁盘，还是通过网络保存到服务器上，最终都会将数据写入磁盘文件。</p>
<p>而如何定义数据的存储格式就是一个大问题。如果我们自己来定义存储格式，比如保存一个班级所有学生的成绩单：</p>
<p>名字    成绩<br>Michael    99<br>Bob        85<br>Bart    59<br>Lisa    87<br>你可以用一个文本文件保存，一行保存一个学生，用,隔开：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Michael,99</span><br><span class="line">Bob,85</span><br><span class="line">Bart,59</span><br><span class="line">Lisa,87</span><br></pre></td></tr></table></figure></p>
<p>你还可以用JSON格式保存，也是文本文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Michael&quot;,&quot;score&quot;:99&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Bob&quot;,&quot;score&quot;:85&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Bart&quot;,&quot;score&quot;:59&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Lisa&quot;,&quot;score&quot;:87&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<p>你还可以定义各种保存格式，但是问题来了：</p>
<p>存储和读取需要自己实现，JSON还是标准，自己定义的格式就各式各样了；</p>
<p>不能做快速查询，只有把数据全部读到内存中才能自己遍历，但有时候数据的大小远远超过了内存（比如蓝光电影，40GB的数据），根本无法全部读入内存。</p>
<p>为了便于程序保存和读取数据，而且，能直接通过条件快速查询到指定的数据，就出现了数据库（Database）这种专门用于集中存储和查询的软件。</p>
<p>数据库软件诞生的历史非常久远，早在1950年数据库就诞生了。经历了网状数据库，层次数据库，我们现在广泛使用的关系数据库是20世纪70年代基于关系模型的基础上诞生的。</p>
<p>关系模型有一套复杂的数学理论，但是从概念上是十分容易理解的。举个学校的例子：</p>
<p>假设某个XX省YY市ZZ县第一实验小学有3个年级，要表示出这3个年级，可以在Excel中用一个表格画出来</p>
<p>每个年级又有若干个班级，要把所有班级表示出来，可以在Excel中再画一个表格</p>
<p>这两个表格有个映射关系，就是根据Grade_ID可以在班级表中查找到对应的所有班级</p>
<p>也就是Grade表的每一行对应Class表的多行，在关系数据库中，这种基于表（Table）的一对多的关系就是关系数据库的基础。</p>
<p>根据某个年级的ID就可以查找所有班级的行，这种查询语句在关系数据库中称为SQL语句，可以写成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM classes WHERE grade_id = &apos;1&apos;;</span><br></pre></td></tr></table></figure></p>
<p>结果也是一个表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">grade_id | class_id | name</span><br><span class="line"></span><br><span class="line">1        | 11       | 一年级一班</span><br><span class="line"></span><br><span class="line">1        | 12       | 一年级二班</span><br><span class="line"></span><br><span class="line">1        | 13       | 一年级三班</span><br></pre></td></tr></table></figure>
<p>类似的，Class表的一行记录又可以关联到Student表的多行记录</p>
<h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><p>也许还听说过NoSQL数据库，很多NoSQL宣传其速度和规模远远超过关系数据库，所以很多同学觉得有了NoSQL是否就不需要SQL了呢？千万不要被忽悠了，连SQL都不明白怎么可能搞明白NoSQL呢？</p>
<h3 id="数据库类别"><a href="#数据库类别" class="headerlink" title="数据库类别"></a>数据库类别</h3><p>既然我们要使用关系数据库，就必须选择一个关系数据库。目前广泛使用的关系数据库也就这么几种：</p>
<p>付费的商用数据库：</p>
<p>Oracle，典型的高富帅；</p>
<p>SQL Server，微软自家产品，Windows定制专款；</p>
<p>DB2，IBM的产品，听起来挺高端；</p>
<p>Sybase，曾经跟微软是好基友，后来关系破裂，现在家境惨淡。</p>
<p>这些数据库都是不开源而且付费的，最大的好处是花了钱出了问题可以找厂家解决，不过在Web的世界里，常常需要部署成千上万的数据库服务器，当然不能把大把大把的银子扔给厂家，所以，无论是Google、Facebook，还是国内的BAT，无一例外都选择了免费的开源数据库：</p>
<p>MySQL，大家都在用，一般错不了；</p>
<p>PostgreSQL，学术气息有点重，其实挺不错，但知名度没有MySQL高；</p>
<p>sqlite，嵌入式数据库，适合桌面和移动应用。</p>
<p>作为Python开发工程师，选择哪个免费数据库呢？当然是MySQL。因为MySQL普及率最高，出了错，可以很容易找到解决方法。而且，围绕MySQL有一大堆监控和运维的工具，安装和使用很方便。</p>
<p>从MySQL官方网站下载并安装MySQL Community Server 5.6，这个版本是免费的，其他高级版本是要收钱的。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/55836/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-27T16:00:00.000Z"><a href="/53901/">2017-11-28</a></time>
        
  
    <h1 class="title"><a href="/53901/">Python电子邮件</a></h1>
  

    </header>

    <div class="entry">
      
        <p>Email的历史比Web还要久远，直到现在，Email也是互联网上应用非常广泛的服务。</p>
<p>几乎所有的编程语言都支持发送和接收电子邮件，但是，先等等，在我们开始编写代码之前，有必要搞清楚电子邮件是如何在互联网上运作的。</p>
<p>我们来看看传统邮件是如何运作的。假设你现在在北京，要给一个香港的朋友发一封信，怎么做呢？</p>
<p>首先你得写好信，装进信封，写上地址，贴上邮票，然后就近找个邮局，把信仍进去。</p>
<p>信件会从就近的小邮局转运到大邮局，再从大邮局往别的城市发，比如先发到天津，再走海运到达香港，也可能走京九线到香港，但是你不用关心具体路线，你只需要知道一件事，就是信件走得很慢，至少要几天时间。</p>
<p>信件到达香港的某个邮局，也不会直接送到朋友的家里，因为邮局的叔叔是很聪明的，他怕你的朋友不在家，一趟一趟地白跑，所以，信件会投递到你的朋友的邮箱里，邮箱可能在公寓的一层，或者家门口，直到你的朋友回家的时候检查邮箱，发现信件后，就可以取到邮件了。</p>
<p>电子邮件的流程基本上也是按上面的方式运作的，只不过速度不是按天算，而是按秒算。</p>
<p>现在我们回到电子邮件，假设我们自己的电子邮件地址是<a href="mailto:me@163.com" target="_blank" rel="noopener">me@163.com</a>，对方的电子邮件地址是<a href="mailto:friend@sina.com" target="_blank" rel="noopener">friend@sina.com</a>（注意地址都是虚构的哈），现在我们用Outlook或者Foxmail之类的软件写好邮件，填上对方的Email地址，点“发送”，电子邮件就发出去了。这些电子邮件软件被称为MUA：Mail User Agent——邮件用户代理。</p>
<p>Email从MUA发出去，不是直接到达对方电脑，而是发到MTA：Mail Transfer Agent——邮件传输代理，就是那些Email服务提供商，比如网易、新浪等等。由于我们自己的电子邮件是163.com，所以，Email首先被投递到网易提供的MTA，再由网易的MTA发到对方服务商，也就是新浪的MTA。这个过程中间可能还会经过别的MTA，但是我们不关心具体路线，我们只关心速度。</p>
<p>Email到达新浪的MTA后，由于对方使用的是@sina.com的邮箱，因此，新浪的MTA会把Email投递到邮件的最终目的地MDA：Mail Delivery Agent——邮件投递代理。Email到达MDA后，就静静地躺在新浪的某个服务器上，存放在某个文件或特殊的数据库里，我们将这个长期保存邮件的地方称之为电子邮箱。</p>
<p>同普通邮件类似，Email不会直接到达对方的电脑，因为对方电脑不一定开机，开机也不一定联网。对方要取到邮件，必须通过MUA从MDA上把邮件取到自己的电脑上。</p>
<p>所以，一封电子邮件的旅程就是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">发件人 -&gt; MUA -&gt; MTA -&gt; MTA -&gt; 若干个MTA -&gt; MDA &lt;- MUA &lt;- 收件人</span><br></pre></td></tr></table></figure></p>
<p>有了上述基本概念，要编写程序来发送和接收邮件，本质上就是：</p>
<ol>
<li><p>编写MUA把邮件发到MTA；</p>
</li>
<li><p>编写MUA从MDA上收邮件。</p>
</li>
</ol>
<p>发邮件时，MUA和MTA使用的协议就是<strong>SMTP</strong>：Simple Mail Transfer Protocol，后面的MTA到另一个MTA也是用SMTP协议。</p>
<p>收邮件时，MUA和MDA使用的协议有两种：<strong>POP</strong>：Post Office Protocol，目前版本是3，俗称POP3；<strong>IMAP</strong>：Internet Message Access Protocol，目前版本是4，优点是不但能取邮件，还可以直接操作MDA上存储的邮件，比如从收件箱移到垃圾箱，等等。</p>
<p>邮件客户端软件在发邮件时，会让你先配置SMTP服务器，也就是你要发到哪个MTA上。假设你正在使用163的邮箱，你就不能直接发到新浪的MTA上，因为它只服务新浪的用户，所以，你得填163提供的SMTP服务器地址：smtp.163.com，为了证明你是163的用户，SMTP服务器还要求你填写邮箱地址和邮箱口令，这样，MUA才能正常地把Email通过SMTP协议发送到MTA。</p>
<p>类似的，从MDA收邮件时，MDA服务器也要求验证你的邮箱口令，确保不会有人冒充你收取你的邮件，所以，Outlook之类的邮件客户端会要求你填写POP3或IMAP服务器地址、邮箱地址和口令，这样，MUA才能顺利地通过POP或IMAP协议从MDA取到邮件。</p>
<p>在使用Python收发邮件前，请先准备好至少两个电子邮件，如<a href="mailto:xxx@163.com" target="_blank" rel="noopener">xxx@163.com</a>，<a href="mailto:xxx@sina.com" target="_blank" rel="noopener">xxx@sina.com</a>，<a href="mailto:xxx@qq.com" target="_blank" rel="noopener">xxx@qq.com</a>等，注意两个邮箱不要用同一家邮件服务商。</p>
<p>最后特别注意，目前大多数邮件服务商都需要手动打开SMTP发信和POP收信的功能，否则只允许在网页登录</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/53901/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-23T16:00:00.000Z"><a href="/7429/">2017-11-24</a></time>
        
  
    <h1 class="title"><a href="/7429/">Python网络编程</a></h1>
  

    </header>

    <div class="entry">
      
        <p>自从互联网诞生以来，现在基本上所有的程序都是网络程序，很少有单机版的程序了。</p>
<p>计算机网络就是把各个计算机连接到一起，让网络中的计算机可以互相通信。网络编程就是如何在程序中实现两台计算机的通信。</p>
<p>举个例子，当你使用浏览器访问新浪网时，你的计算机就和新浪的某台服务器通过互联网连接起来了，然后，新浪的服务器把网页内容作为数据通过互联网传输到你的电脑上。</p>
<p>由于你的电脑上可能不止浏览器，还有QQ、Skype、Dropbox、邮件客户端等，不同的程序连接的别的计算机也会不同，所以，更确切地说，网络通信是两台计算机上的两个进程之间的通信。比如，浏览器进程和新浪服务器上的某个Web服务进程在通信，而QQ进程是和腾讯的某个服务器上的某个进程在通信。</p>
<p>网络通信就是两个进程在通信。</p>
<p>网络编程对所有开发语言都是一样的，Python也不例外。用Python进行网络编程，就是在Python程序本身这个进程内，连接别的服务器进程的通信端口进行通信。</p>
<p>这里将详细介绍Python网络编程的概念和最主要的两种网络类型的编程。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/7429/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-19T16:00:00.000Z"><a href="/53971/">2017-11-20</a></time>
        
  
    <h1 class="title"><a href="/53971/">Python图形界面</a></h1>
  

    </header>

    <div class="entry">
      
        <p>Python支持多种图形界面的第三方库，包括：</p>
<ul>
<li><p>Tk</p>
</li>
<li><p>wxWidgets</p>
</li>
<li><p>Qt</p>
</li>
<li><p>GTK</p>
</li>
</ul>
<p>等等。</p>
<p>但是Python自带的库是支持Tk的Tkinter，使用Tkinter，无需安装任何包，就可以直接使用。本章简单介绍如何使用Tkinter进行GUI编程。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/53971/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-18T16:00:00.000Z"><a href="/60484/">2017-11-19</a></time>
        
  
    <h1 class="title"><a href="/60484/">Python vertualenv</a></h1>
  

    </header>

    <div class="entry">
      
        <p>在开发Python应用程序的时候，系统安装的Python3只有一个版本：3.4。所有第三方的包都会被pip安装到Python3的site-packages目录下。</p>
<p>如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要jinja 2.7，而应用B需要jinja 2.6怎么办？</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/60484/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-17T16:00:00.000Z"><a href="/6897/">2017-11-18</a></time>
        
  
    <h1 class="title"><a href="/6897/">Python爬虫代码———新浪新闻</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">res = requests.get(&apos;http://news.sina.com.cn/china/&apos;)</span><br><span class="line">res.encoding = &apos;utf-8&apos;</span><br><span class="line">print(type(res))</span><br><span class="line">#print(res.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#使用示例</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">html_sample = &apos; \</span><br><span class="line">&lt;html&gt; \</span><br><span class="line"> &lt;body&gt; \</span><br><span class="line"> &lt;h1 id=&quot;title&quot;&gt;Hello World&lt;/h1&gt; \</span><br><span class="line"> &lt;a href=&quot;#&quot; class=&quot;link&quot;&gt;This is link1&lt;/a&gt; \</span><br><span class="line"> &lt;a href=&quot;# link2&quot; class=&quot;link&quot;&gt;This is link2&lt;/a&gt; \</span><br><span class="line"> &lt;/body&gt; \</span><br><span class="line"> &lt;/html&gt;&apos;</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html_sample, &apos;html.parser&apos;)</span><br><span class="line">print(type(soup))</span><br><span class="line">print(soup.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有含h1的元素</span><br><span class="line">soup = BeautifulSoup(html_sample, &apos;html.parser&apos;)</span><br><span class="line">alink = soup.select(&apos;h1&apos;)</span><br><span class="line">print(alink)</span><br><span class="line">print(alink[0])</span><br><span class="line">print(alink[0].text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有含a的元素</span><br><span class="line">soup = BeautifulSoup(html_sample, &apos;html.parser&apos;)</span><br><span class="line">alink = soup.select(&apos;a&apos;)</span><br><span class="line">print(alink)</span><br><span class="line">for link in alink:</span><br><span class="line">    print(link)</span><br><span class="line">    print(link.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有id为title的元素</span><br><span class="line">alink = soup.select(&apos;#title&apos;)</span><br><span class="line">print(alink)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有class为link的元素</span><br><span class="line">alink = soup.select(&apos;.link&apos;)</span><br><span class="line">for link in alink:</span><br><span class="line">    print(link)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有a tag 的href的连结</span><br><span class="line">alink = soup.select(&apos;a&apos;)</span><br><span class="line">for link in alink:</span><br><span class="line">    print(link[&apos;href&apos;])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">res = requests.get(&apos;http://news.sina.com.cn/china/&apos;)</span><br><span class="line">res.encoding = &apos;utf-8&apos;</span><br><span class="line">#print(type(res))</span><br><span class="line">soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for news in soup.select(&apos;.news-item&apos;):</span><br><span class="line">    #print(news)</span><br><span class="line">    if len(news.select(&apos;h2&apos;)) &gt; 0:</span><br><span class="line">        h2 = news.select(&apos;h2&apos;)[0].text</span><br><span class="line">        time = news.select(&apos;.time&apos;)[0].text</span><br><span class="line">        a = news.select(&apos;a&apos;)[0][&apos;href&apos;]</span><br><span class="line">        #print(time, h2, a)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">res = requests.get(&apos;http://news.sina.com.cn/c/2018-07-31/doc-ihhacrcc9897484.shtml&apos;)</span><br><span class="line">res.encoding = &apos;utf-8&apos;</span><br><span class="line">print(type(res))</span><br><span class="line">#print(res.text)</span><br><span class="line">soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#标题</span><br><span class="line">title = soup.select(&apos;.main-title&apos;)[0].text</span><br><span class="line">print(title)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#时间与来源</span><br><span class="line">datesource = soup.select(&apos;.date-source&apos;)[0]</span><br><span class="line">print(datesource)</span><br><span class="line">date = datesource.span.text</span><br><span class="line">print(date)</span><br><span class="line">source = datesource.a.text</span><br><span class="line">print(source)</span><br><span class="line">#或者</span><br><span class="line">#date = soup.select(&apos;.date-source&apos;)[0].contents[0].strip()</span><br><span class="line">#date</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#时间</span><br><span class="line">from datetime import datetime</span><br><span class="line">dt = datetime.strptime(date, &apos;%Y年%m月%d日 %H:%M&apos;) #str转time</span><br><span class="line">print(dt)</span><br><span class="line">dt.strftime(&apos;%Y-%M-%d&apos;)#time转str</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#文章内容</span><br><span class="line">article = []</span><br><span class="line">for p in soup.select(&apos;#article p&apos;)[:-1]:</span><br><span class="line">    article.append(p.text.strip())</span><br><span class="line">#print(article)</span><br><span class="line">&apos; &apos;.join(article)</span><br><span class="line">#或者&apos; &apos;.join[p.text.strip() for p in soup.select(&apos;#article p&apos;)[:-1]]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#编辑</span><br><span class="line">editor = soup.select(&apos;.show_author&apos;)[0].text.lstrip(&apos;责任编辑：&apos;)</span><br><span class="line">print(editor)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#评论</span><br><span class="line">import requests</span><br><span class="line">comments = requests.get(&apos;http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;\</span><br><span class="line">channel=gn&amp;newsid=comos-hhacrcc9897484&amp;group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;\</span><br><span class="line">page_size=3&apos;)</span><br><span class="line">#comments.text</span><br><span class="line">import json</span><br><span class="line">jd = json.loads(comments.text)</span><br><span class="line">#print(jd)</span><br><span class="line">commentnum = jd[&apos;result&apos;][&apos;count&apos;][&apos;total&apos;]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">newsurl = &apos;http://news.sina.com.cn/c/2018-07-31/doc-ihhacrcc9897484.shtml&apos;</span><br><span class="line">newsurl.split(&apos;/&apos;)[-1].rstrip(&apos;.shtml&apos;).lstrip(&apos;doc-i&apos;)</span><br><span class="line">#或正则式</span><br><span class="line">re.search(&apos;doc-i(.*).shtml&apos;, newsurl).group(1)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#整理评论</span><br><span class="line">commentURL = &apos;http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;\</span><br><span class="line">channel=gn&amp;newsid=comos-&#123;&#125;&amp;group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;\</span><br><span class="line">page_size=3&apos;</span><br><span class="line">import re</span><br><span class="line">import json</span><br><span class="line">def getCommentCount(newsurl):</span><br><span class="line">    newsid = re.search(&apos;doc-i(.*).shtml&apos;, newsurl).group(1)</span><br><span class="line">    comments = requests.get(commentURL.format(newsid))</span><br><span class="line">    jd = json.loads(comments.text)</span><br><span class="line">    return jd[&apos;result&apos;][&apos;count&apos;][&apos;total&apos;]</span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">news = &apos;http://news.sina.com.cn/c/2018-07-31/doc-ihhacrcc9897484.shtml&apos;</span><br><span class="line">getCommentCount(news)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#单个新闻信息</span><br><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">def getNewsDetail(newsurl):</span><br><span class="line">    result = &#123;&#125;</span><br><span class="line">    res = requests.get(newsurl)</span><br><span class="line">    res.encoding = &apos;utf-8&apos;</span><br><span class="line">    soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</span><br><span class="line">    result[&apos;title&apos;] = soup.select(&apos;.main-title&apos;)[0].text</span><br><span class="line">    result[&apos;newssource&apos;] = soup.select(&apos;.date-source&apos;)[0].a.text</span><br><span class="line">    date = soup.select(&apos;.date-source&apos;)[0].span.text</span><br><span class="line">    result[&apos;dt&apos;] = datetime.strptime(date, &apos;%Y年%m月%d日 %H:%M&apos;) #str转time</span><br><span class="line">    result[&apos;article&apos;] = &apos; &apos;.join([p.text.strip() for p in soup.select(&apos;#article p&apos;)[:-1]])</span><br><span class="line">    result[&apos;editor&apos;] = soup.select(&apos;.show_author&apos;)[0].text.lstrip(&apos;责任编辑：&apos;)</span><br><span class="line">    result[&apos;comments&apos;] = getCommentCount(newsurl)</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line">#test</span><br><span class="line">news = &apos;http://news.sina.com.cn/c/nd/2018-07-24/doc-ihftenhz7547208.shtml&apos;</span><br><span class="line">getNewsDetail(news)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#剖析分页信息</span><br><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">res = requests.get(&apos;http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;\</span><br><span class="line">cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&amp;level==1||=2&amp;show_ext=1&amp;show_all=1&amp;show_num=22&amp;tag=1&amp;\</span><br><span class="line">format=json&amp;page=6&amp;callback=newsloadercallback&amp;_=1533026268219&apos;)</span><br><span class="line">jd = json.loads(res.text.lstrip(&apos;  newsloadercallback(&apos;).rstrip(&apos;);&apos;))</span><br><span class="line">#jd</span><br><span class="line">for ent in jd[&apos;result&apos;][&apos;data&apos;]:</span><br><span class="line">    print(ent[&apos;url&apos;])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#建立剖析清单链接函式</span><br><span class="line">def parseListLinks(url):</span><br><span class="line">    newsdetails = []</span><br><span class="line">    res = requests.get(url)</span><br><span class="line">    jd = json.loads(res.text.lstrip(&apos;  newsloadercallback(&apos;).rstrip(&apos;);&apos;))</span><br><span class="line">    for ent in jd[&apos;result&apos;][&apos;data&apos;]:</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            print(ent[&apos;url&apos;])</span><br><span class="line">            newsdetails.append(getNewsDetail(ent[&apos;url&apos;]))</span><br><span class="line">        except AttributeError:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">    return newsdetails</span><br><span class="line"></span><br><span class="line">#test </span><br><span class="line">url = &apos;http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;\</span><br><span class="line">cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&amp;level==1||=2&amp;show_ext=1&amp;show_all=1&amp;show_num=22&amp;tag=1&amp;\</span><br><span class="line">format=json&amp;page=6&amp;callback=newsloadercallback&amp;_=1533026268219&apos;</span><br><span class="line">parseListLinks(url)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#使用for循环产生多页连结&amp;批次抓取每页新闻内文</span><br><span class="line">def createUrl(num):</span><br><span class="line">    url = &apos;http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;\</span><br><span class="line">cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&amp;level==1||=2&amp;show_ext=1&amp;show_all=1&amp;show_num=22&amp;tag=1&amp;\</span><br><span class="line">format=json&amp;page=&#123;&#125;&apos;#使用&#123;&#125;代替</span><br><span class="line">    news_total = []</span><br><span class="line">    for i in range(1, num):</span><br><span class="line">        newsurl = url.format(i)</span><br><span class="line">        print(newsurl)</span><br><span class="line">        newsary = parseListLinks(newsurl)</span><br><span class="line">        news_total.extend(newsary)</span><br><span class="line">    return news_total</span><br><span class="line">#test</span><br><span class="line">news_total = createUrl(3)</span><br><span class="line">#print(news_total)</span><br><span class="line">len(news_total)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#pandas 整理资料</span><br><span class="line">import pandas</span><br><span class="line">df = pandas.DataFrame(news_total)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#保存数据</span><br><span class="line">df.to_csv(&apos;news.csv&apos;)#到csv</span><br><span class="line">import sqlite3 #到sql</span><br><span class="line">with sqlite3.connect(&apos;news.sqlite&apos;) as db:</span><br><span class="line">    df.to_sql(&apos;news&apos;, con = db)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#操作sql</span><br><span class="line">import sqlite3</span><br><span class="line">with sqlite3.connect(&apos;news.sqlite&apos;) as db:</span><br><span class="line">    df2 = pandas.read_sql_query(&apos;SELECT * FROM news&apos;, con = db)</span><br><span class="line">df2.head()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-17T16:00:00.000Z"><a href="/57576/">2017-11-18</a></time>
        
  
    <h1 class="title"><a href="/57576/">Python常用第三方模块</a></h1>
  

    </header>

    <div class="entry">
      
        <p>除了内建的模块外，Python还有大量的第三方模块。</p>
<p>基本上，所有的第三方模块都会在PyPI - the Python Package Index上注册，只要找到对应的模块名字，即可用pip安装。</p>
<p>此外，在安装第三方模块一节中，我们强烈推荐安装Anaconda，安装后，数十个常用的第三方模块就已经就绪，不用pip手动安装。</p>
<p>这里将介绍常用的第三方模块。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/57576/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-15T16:00:00.000Z"><a href="/32546/">2017-11-16</a></time>
        
  
    <h1 class="title"><a href="/32546/">Python常用内建模块</a></h1>
  

    </header>

    <div class="entry">
      
        <p>Python之所以自称“batteries included”，就是因为内置了许多非常有用的模块，无需额外安装和配置，即可直接使用。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/32546/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>
 
<nav id="pagination">
  
    <a href="/" class="alignleft prev">上一页</a>
  
  
    <a href="/page/3/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav>
</div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据挖掘/">数据挖掘</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">26</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 12.5px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.75px;">Machine Learning 课程笔记</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/SQL/" style="font-size: 13.75px;">SQL</a> <a href="/tags/hexo/" style="font-size: 11.25px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.25px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/提问/" style="font-size: 10px;">提问</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.25px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 12.5px;">模型</a> <a href="/tags/爬虫/" style="font-size: 17.5px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.25px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2020 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>