<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python爬虫学习———urllib进阶 | RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  <meta name="description" content="前情回顾，urllib的基本用法
urllib库的基本组成

利用最简单的urlopen方法爬取网页html
利用Request方法构建headers模拟浏览器操作
error的异常操作

具体内容参见Python从零学爬虫。urllib库除了以上基础的用法外，还有很多高级的功能，可以更加灵活的适用在爬虫应用中，比如：

使用HTTP的POST请求方法向服务器提交数据实现用户登录
使用代理IP解决防止反爬
设置超时提高爬虫效率
解析URL的方法

本次将会对这些内容进行详细的分析和讲解。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Python爬虫学习———urllib进阶"/>
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-07-31T16:00:00.000Z"><a href="/24182/">2017-08-01</a></time>
        
  
    <h1 class="title">Python爬虫学习———urllib进阶</h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#POST请求"><span class="toc-text">POST请求</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#POST请求的准备工作"><span class="toc-text">POST请求的准备工作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-浏览器F12"><span class="toc-text">1. 浏览器F12</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-通过fiddler抓包工具"><span class="toc-text">2. 通过fiddler抓包工具</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#POST请求的使用"><span class="toc-text">POST请求的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#POST请求代码分析"><span class="toc-text">POST请求代码分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代理IP"><span class="toc-text">代理IP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#代理IP的使用"><span class="toc-text">代理IP的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#代理IP代码分析"><span class="toc-text">代理IP代码分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#超时"><span class="toc-text">超时</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#urllib库parse解析"><span class="toc-text">urllib库parse解析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
    </div>

        <p>前情回顾，urllib的基本用法</p>
<p>urllib库的基本组成</p>
<ul>
<li>利用最简单的urlopen方法爬取网页html</li>
<li>利用Request方法构建headers模拟浏览器操作</li>
<li>error的异常操作</li>
</ul>
<p>具体内容参见Python从零学爬虫。urllib库除了以上基础的用法外，还有很多高级的功能，可以更加灵活的适用在爬虫应用中，比如：</p>
<ul>
<li>使用HTTP的POST请求方法向服务器提交数据实现用户登录</li>
<li>使用代理IP解决防止反爬</li>
<li>设置超时提高爬虫效率</li>
<li>解析URL的方法</li>
</ul>
<p>本次将会对这些内容进行详细的分析和讲解。</p>
<a id="more"></a>
<hr>
<h2 id="POST请求"><a href="#POST请求" class="headerlink" title="POST请求"></a>POST请求</h2><p>POST是HTTP协议的请求方法之一，也是比较常用到的一种方法，用于向服务器提交数据。先介绍进行post请求的一些准备工作，然后举一个例子，对其使用以及更深层概念进行详细的的剖析。</p>
<h3 id="POST请求的准备工作"><a href="#POST请求的准备工作" class="headerlink" title="POST请求的准备工作"></a>POST请求的准备工作</h3><p>既然要提交信息给服务器，我们就需要知道信息往哪填，填什么，填写格式是什么？带这些问题，我们往下看。</p>
<p>同样提交用户登录信息（用户名和密码），不同网站可能需要的东西不一样，比如淘宝反爬机制较复杂，会有其它一大串的额外信息。这里，我们以豆瓣为例（相对简单），目标是弄清楚POST是如何使用的，复杂内容会在后续实战部分与大家继续分享。</p>
<p>抛开上面像淘宝一样需要的复杂信息，如果仅考虑用户名和密码的话，我们的准备工作其实就是要弄明白用户名和密码标签的属性name是什么，以下两种方法可以实现。</p>
<p>浏览器F12查看element获取<br>也可以通过抓包工具Fiddler获取，fiddler的下载地址<br><a href="https://www.telerik.com/" target="_blank" rel="noopener">https://www.telerik.com/</a><br>废话不多说了，让我们看看到底如何找到name？</p>
<h4 id="1-浏览器F12"><a href="#1-浏览器F12" class="headerlink" title="1. 浏览器F12"></a>1. 浏览器F12</h4><p>通过浏览器F12元素逐层查看到（我是用的Chrome），邮箱/手机号标签的name=”form_email”, 密码的标签name=”form_email”</p>
<p>但要说明的是，两个标签的name名称并不是固定的，上面查看的name名称只是豆瓣网站定义的，不代表所有。其它的网站可能有会有不同的名称，比如name=”username”, name=”password”之类的。因此，针对不同网站的登录，需要每次查看name是什么。</p>
<h4 id="2-通过fiddler抓包工具"><a href="#2-通过fiddler抓包工具" class="headerlink" title="2. 通过fiddler抓包工具"></a>2. 通过fiddler抓包工具</h4><p>推荐使用fiddler工具，非常好用。爬虫本身就是模拟浏览器工作，我们只需要知道浏览器是怎么工作的就可以了。</p>
<p>fiddler会帮助我们抓取浏览器POST请求的所有内容，这样我们得到了浏览器POST的信息，把它填到爬虫程序里模拟浏览器操作就OK了。另外，也可以通过fiddler抓到浏览器请求的headers，非常方便。</p>
<p>安装fiddler的小伙伴们注意：fiddler证书问题的坑（无法抓取HTTPs包），可以通过Tools —&gt; Options —&gt;HTTPS里面打勾Decrypt HTTPS traffic修改证书来解决。否则会一直显示抓取 Tunnel 信息包…</p>
<p>好了，完成了准备工作，我们直接上一段代码理解下。</p>
<h3 id="POST请求的使用"><a href="#POST请求的使用" class="headerlink" title="POST请求的使用"></a>POST请求的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.error</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line"># headers 信息，从fiddler上或你的浏览器上可复制下来</span><br><span class="line">headers = &#123;&apos;Accept&apos;: &apos;text/html,application/xhtml+xml,</span><br><span class="line">        application/xml;q=0.9,image/webp,image/apng,</span><br><span class="line">        */*;q=0.8&apos;,</span><br><span class="line">       &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;,</span><br><span class="line">       &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.3; </span><br><span class="line">                      Win64; x64) AppleWebKit/537.36 </span><br><span class="line">                      (KHTML, like Gecko)Chrome/48.0</span><br><span class="line">                      .2564.48 Safari/537.36&apos;</span><br><span class="line">       &#125;</span><br><span class="line"># POST请求的信息，填写你的用户名和密码</span><br><span class="line">value = &#123;&apos;source&apos;: &apos;index_nav&apos;,</span><br><span class="line">     &apos;form_password&apos;: &apos;your password&apos;,</span><br><span class="line">     &apos;form_email&apos;: &apos;your username&apos;</span><br><span class="line">     &#125;</span><br><span class="line">try:</span><br><span class="line">data = urllib.parse.urlencode(value).encode(&apos;utf8&apos;)</span><br><span class="line">response = urllib.request.Request(</span><br><span class="line">&apos;https://www.douban.com/login&apos;, data=data, headers=headers)</span><br><span class="line">html = urllib.request.urlopen(response)</span><br><span class="line">result = html.read().decode(&apos;utf8&apos;)</span><br><span class="line">print(result)</span><br><span class="line">except urllib.error.URLError as e:</span><br><span class="line">if hasattr(e, &apos;reason&apos;):</span><br><span class="line">    print(&apos;错误原因是&apos; + str(e.reason))</span><br><span class="line">except urllib.error.HTTPError as e:</span><br><span class="line">if hasattr(e, &apos;code&apos;):</span><br><span class="line">    print(&apos;错误编码是&apos; + str(e.code))</span><br><span class="line">else:</span><br><span class="line">print(&apos;请求成功通过。&apos;)</span><br></pre></td></tr></table></figure>
<p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE HTML&gt;</span><br><span class="line">&lt;html lang=&quot;zh-cmn-Hans&quot; class=&quot;ua-windows ua-webkit&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">&lt;meta name=&quot;description&quot; content=&quot;提供图书、电影、音乐唱片的</span><br><span class="line">推荐、评论和价格比较，以及城市独特的文化生活。&quot;&gt;</span><br><span class="line">.....</span><br><span class="line">window.attachEvent(&apos;onload&apos;, _ga_init);</span><br><span class="line">&#125;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<p>注意：复制header的时候请去掉 这一项’Accept-Encoding’:’ gzip, deflate， 否则会提示decode的错误。</p>
<h3 id="POST请求代码分析"><a href="#POST请求代码分析" class="headerlink" title="POST请求代码分析"></a>POST请求代码分析</h3><p>我们来分析一下上面的代码，与urllib库request的使用基本一致，urllib库request的基本用法可参考上篇文章，这里多出了post的data参数和一些解析的内容，着重讲解一下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = urllib.parse.urlencode(value).encode(&apos;utf8&apos;)</span><br></pre></td></tr></table></figure></p>
<p>这句的意思是利用了urllib库的parse来对post内容解析，为什么要解析呢？</p>
<p>这是因为post内容需要进行一定的编码格式处理后才能发送，而编码的规则需要遵从RFC标准，百度了一下RFC定义，供大家参考：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Request ForComments（RFC），是一系列以编号排定的文件。文件收集了有关互联网相关信息，以及UNIX和互联网社区的软件文件。目前RFC文件是由InternetSociety（ISOC）赞助发行。基本的互联网通信协议都有在RFC文件内详细说明。RFC文件还额外加入许多的论题在标准内，例如对于互联网新开发的协议及发展中所有的记录。因此几乎所有的互联网标准都有收录在RFC文件之中。</span><br></pre></td></tr></table></figure></p>
<p>而parse的urlencode方法是将一个字典或者有顺序的二元素元组转换成为URL的查询字符串（说白了就是按照RFC标准转换了一下格式）。然后再将转换好的字符串按UTF-8的编码转换成为二进制格式才能使用。</p>
<p>注：以上是在Python3.x环境下完成，Python3.x中编码解码规则为 byte—&gt;string—&gt;byte的模式，其中byte—&gt;string为解码，string—&gt;byte为编码</p>
<h2 id="代理IP"><a href="#代理IP" class="headerlink" title="代理IP"></a>代理IP</h2><h3 id="代理IP的使用"><a href="#代理IP的使用" class="headerlink" title="代理IP的使用"></a>代理IP的使用</h3><p>为什么要使用代理IP？因为各种反爬机制会检测同一IP爬取网页的频率速度，如果速度过快，就会被认定为机器人封掉你的IP。但是速度过慢又会影响爬取的速度，因此，我们将使用代理IP取代我们自己的IP，这样不断更换新的IP地址就可以达到快速爬取网页而降低被检测为机器人的目的了。</p>
<p>同样利用urllib的request就可以完成代理IP的使用，但是与之前用到的urlopen不同，我们需要自己创建订制化的opener。什么意思呢？</p>
<p>urlopen就好像是opener的通用版本，当我们需要特殊功能（例如代理IP）的时候，urlopen满足不了我们的需求，我们就不得不自己定义并创建特殊的opener了。</p>
<p>request里面正好有处理各种功能的处理器方法，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ProxyHandler, UnknownHandler, HTTPHandler,</span><br><span class="line">HTTPDefaultErrorHandler, HTTPRedirectHandler,</span><br><span class="line">FTPHandler, FileHandler, HTTPErrorProcessor, DataHandler</span><br></pre></td></tr></table></figure></p>
<p>我们要用的是第一个ProxyHandler来处理代理问题。</p>
<p>让我们看一段代码如何使用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import urllib.error</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line"># headers信息，从fiddler上或浏览器上可复制下来</span><br><span class="line">headers = &#123;&apos;Accept&apos;: &apos;text/html,application/xhtml+xml,</span><br><span class="line">        application/xml;q=0.9,image/webp,image/apng,</span><br><span class="line">        */*;q=0.8&apos;,</span><br><span class="line">       &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;,</span><br><span class="line">       &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.3;</span><br><span class="line">                      Win64;</span><br><span class="line">                      x64) AppleWebKit/537.36 (KHTML, </span><br><span class="line">                      like Gecko)Chrome/48.0.2564.48 </span><br><span class="line">                      Safari/537.36&apos;</span><br><span class="line">       &#125;</span><br><span class="line"># POST请求的信息</span><br><span class="line">value = &#123;&apos;source&apos;: &apos;index_nav&apos;,</span><br><span class="line">     &apos;form_password&apos;: &apos;your password&apos;,</span><br><span class="line">     &apos;form_email&apos;: &apos;your username&apos;</span><br><span class="line">     &#125;</span><br><span class="line"># 代理IP信息为字典格式，key为&apos;http&apos;，value为&apos;代理ip：端口号&apos;</span><br><span class="line">proxy = &#123;&apos;http&apos;: &apos;115.193.101.21:61234&apos;&#125;</span><br><span class="line">try:</span><br><span class="line">data = urllib.parse.urlencode(value).encode(&apos;utf8&apos;)</span><br><span class="line">response = urllib.request.Request(</span><br><span class="line">&apos;https://www.douban.com/login&apos;, data=data, headers=headers)</span><br><span class="line"># 使用ProxyHandler方法生成处理器对象</span><br><span class="line">proxy_handler = urllib.request.ProxyHandler(proxy)</span><br><span class="line"># 创建代理IP的opener实例</span><br><span class="line">opener = urllib.request.build_opener(proxy_handler)</span><br><span class="line"># 将设置好的post信息和headers的response作为参数</span><br><span class="line">html = opener.open(response)</span><br><span class="line">result = html.read().decode(&apos;utf8&apos;)</span><br><span class="line">print(result)</span><br><span class="line">except urllib.error.URLError as e:</span><br><span class="line">if hasattr(e, &apos;reason&apos;):</span><br><span class="line">    print(&apos;错误原因是&apos; + str(e.reason))</span><br><span class="line">except urllib.error.HTTPError as e:</span><br><span class="line">if hasattr(e, &apos;code&apos;):</span><br><span class="line">    print(&apos;错误编码是&apos; + str(e.code))</span><br><span class="line">else:</span><br><span class="line">print(&apos;请求成功通过。&apos;)</span><br></pre></td></tr></table></figure></p>
<p>在上面post请求代码的基础上，用自己创建的opener替换urlopen即可完成代理IP的操作，代理ip可以到一些免费的代理IP网站上查找，整理出几个，如：</p>
<p><a href="http://www.xicidaili.com/" target="_blank" rel="noopener">http://www.xicidaili.com/</a><br><a href="http://www.66ip.cn/" target="_blank" rel="noopener">http://www.66ip.cn/</a><br><a href="http://www.mimiip.com/gngao/" target="_blank" rel="noopener">http://www.mimiip.com/gngao/</a><br><a href="http://www.kuaidaili.com/" target="_blank" rel="noopener">http://www.kuaidaili.com/</a><br>运行得到的结果与使用本机IP一样。</p>
<h3 id="代理IP代码分析"><a href="#代理IP代码分析" class="headerlink" title="代理IP代码分析"></a>代理IP代码分析</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 这个代理IP数据类型为字典，如果是http协议，key值就为**&quot;http&quot;**，value值应为**&quot;代理IP：端口号&quot;的格式**。</span><br><span class="line">proxy = &#123;&apos;http&apos;: &apos;115.193.101.21:61234&apos;&#125;</span><br><span class="line"></span><br><span class="line"># 使用ProxyHandler方法创建proxy处理器对象</span><br><span class="line">proxy_handler = urllib.request.ProxyHandler(proxy)</span><br><span class="line"></span><br><span class="line"># 创建代理IP的opener实例，参数为proxy处理器对象</span><br><span class="line">opener = urllib.request.build_opener(proxy_handler)</span><br><span class="line"></span><br><span class="line"># 用代理IP的opener打开指定状态的URL信息</span><br><span class="line">html = opener.open(response)</span><br></pre></td></tr></table></figure>
<h2 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h2><p>设置超时的目的是为了防止爬取网站的时候，等待时间过长而导致效率的降低。有效的超时设置可以强制结束等待而进行下一次的爬取，下面来一段代码看如何使用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line">import urllib.request</span><br><span class="line">import urllib.error</span><br><span class="line">import urllib.parse</span><br><span class="line">import socket</span><br><span class="line"></span><br><span class="line"># headers信息，从fiddler上或浏览器上可复制下来</span><br><span class="line">headers = &#123;&apos;Accept&apos;: &apos;text/html,application/xhtml+xml,</span><br><span class="line">        application/xml;q=0.9,image/webp,image/apng,</span><br><span class="line">        */*;q=0.8&apos;,</span><br><span class="line">       &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;,</span><br><span class="line">       &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.3; </span><br><span class="line">                      Win64;</span><br><span class="line">                      x64) AppleWebKit/537.36</span><br><span class="line">                      (KHTML, like Gecko)Chrome/48.0</span><br><span class="line">                      .2564.48 Safari/537.36&apos;</span><br><span class="line">       &#125;</span><br><span class="line"># POST请求的信息</span><br><span class="line">value = &#123;&apos;source&apos;: &apos;index_nav&apos;,</span><br><span class="line">     &apos;form_password&apos;: &apos;your password&apos;,</span><br><span class="line">     &apos;form_email&apos;: &apos;your username&apos;</span><br><span class="line">     &#125;</span><br><span class="line"># 代理IP为字典格式，key为&apos;http&apos;，value为&apos;代理ip：端口号&apos;</span><br><span class="line">proxy = &#123;&apos;http&apos;: &apos;115.193.101.21:61234&apos;&#125;</span><br><span class="line"># 设置超时为2秒，单位为秒</span><br><span class="line">timeout = 2</span><br><span class="line">try:</span><br><span class="line"># 设置socket超时</span><br><span class="line">socket.setdefaulttimeout(timeout)</span><br><span class="line"></span><br><span class="line">data = urllib.parse.urlencode(value).encode(&apos;utf8&apos;)</span><br><span class="line">response = urllib.request.Request(</span><br><span class="line">&apos;https://www.douban.com/login&apos;, data=data, headers=headers)</span><br><span class="line"></span><br><span class="line"># 使用ProxyHandler方法生成处理器对象</span><br><span class="line">proxy_handler = urllib.request.ProxyHandler(proxy)</span><br><span class="line"># 创建代理IP的opener实例</span><br><span class="line">opener = urllib.request.build_opener(proxy_handler)</span><br><span class="line"># 将设置好的post信息和headers的response作为参数</span><br><span class="line">html = opener.open(response)</span><br><span class="line">result = html.read().decode(&apos;utf8&apos;)</span><br><span class="line">print(result)</span><br><span class="line">except urllib.error.URLError as e:</span><br><span class="line">if hasattr(e, &apos;reason&apos;):</span><br><span class="line">    print(&apos;错误原因是&apos; + str(e.reason))</span><br><span class="line">except urllib.error.HTTPError as e:</span><br><span class="line">if hasattr(e, &apos;code&apos;):</span><br><span class="line">    print(&apos;错误编码是&apos; + str(e.code))</span><br><span class="line">except socket.timeout:</span><br><span class="line">print(&apos;socket超时&apos;)</span><br><span class="line">else:</span><br><span class="line">print(&apos;请求成功通过。&apos;)</span><br></pre></td></tr></table></figure></p>
<p>在post和代理IP使用的基础上又增加了超时的使用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 设置超时为2秒，单位为秒</span><br><span class="line">timeout = 2</span><br><span class="line">#设置socket超时时间，如果不设置，则会使用默认时间。</span><br><span class="line">socket.setdefaulttimeout(timeout)</span><br><span class="line"></span><br><span class="line"># 同时对socket超时timeout的错误设置了异常，timeout错误属于OSerror的子类,时间超出指定timeout就会提示socket超时。</span><br><span class="line">except socket.timeout:</span><br><span class="line">print(&apos;socket超时&apos;)</span><br></pre></td></tr></table></figure></p>
<h2 id="urllib库parse解析"><a href="#urllib库parse解析" class="headerlink" title="urllib库parse解析"></a>urllib库parse解析</h2><p>除了上面提到的urlencode方法，urllib库的parse中还有很多其它的方法可以使用，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#urlparse：把URL解析成6个部分</span><br><span class="line">&lt;scheme&gt;://&lt;netloc&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;fragment&gt;</span><br><span class="line"></span><br><span class="line">#urlsplit：把URL解析成5个部分</span><br><span class="line">&lt;scheme&gt;://&lt;netloc&gt;/&lt;path&gt;?&lt;query&gt;#&lt;fragment&gt;</span><br><span class="line"></span><br><span class="line"># urlunsplit，urlunparse：进行URL的重组</span><br><span class="line"># 还有urljoin，urldefrag等。</span><br></pre></td></tr></table></figure></p>
<p>更多用法可以查找官方request源码，也会在后续实战例子中陆续使用介绍。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>主要介绍了urllib库的一些高级使用用法：</p>
<ul>
<li>POST请求的准备和使用方法</li>
<li>代理IP的使用</li>
<li>超时的使用</li>
<li>parse解析</li>
</ul>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/数据挖掘/">数据挖掘</a>
  </div>

        
  <div class="tags">
    <a href="/tags/python/">python</a>, <a href="/tags/爬虫/">爬虫</a>
  </div>

        
  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a><a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a></div>
  <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div></div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据挖掘/">数据挖掘</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">25</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 12.5px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.75px;">Machine Learning 课程笔记</a> <a href="/tags/SQL/" style="font-size: 13.75px;">SQL</a> <a href="/tags/hexo/" style="font-size: 11.25px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.25px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/提问/" style="font-size: 10px;">提问</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.25px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 12.5px;">模型</a> <a href="/tags/爬虫/" style="font-size: 17.5px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.25px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2018 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>