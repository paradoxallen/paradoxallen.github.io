<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python爬虫代码———新浪新闻 | RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  <meta name="description" content="12345import requestsres = requests.get(&amp;apos;http://news.sina.com.cn/china/&amp;apos;)res.encoding = &amp;apos;utf-8&amp;apos;print(type(res))#print(res.text)
123">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Python爬虫代码———新浪新闻"/>
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-17T16:00:00.000Z"><a href="/6897/">2017-11-18</a></time>
        
  
    <h1 class="title">Python爬虫代码———新浪新闻</h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">res = requests.get(&apos;http://news.sina.com.cn/china/&apos;)</span><br><span class="line">res.encoding = &apos;utf-8&apos;</span><br><span class="line">print(type(res))</span><br><span class="line">#print(res.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#使用示例</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">html_sample = &apos; \</span><br><span class="line">&lt;html&gt; \</span><br><span class="line"> &lt;body&gt; \</span><br><span class="line"> &lt;h1 id=&quot;title&quot;&gt;Hello World&lt;/h1&gt; \</span><br><span class="line"> &lt;a href=&quot;#&quot; class=&quot;link&quot;&gt;This is link1&lt;/a&gt; \</span><br><span class="line"> &lt;a href=&quot;# link2&quot; class=&quot;link&quot;&gt;This is link2&lt;/a&gt; \</span><br><span class="line"> &lt;/body&gt; \</span><br><span class="line"> &lt;/html&gt;&apos;</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html_sample, &apos;html.parser&apos;)</span><br><span class="line">print(type(soup))</span><br><span class="line">print(soup.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有含h1的元素</span><br><span class="line">soup = BeautifulSoup(html_sample, &apos;html.parser&apos;)</span><br><span class="line">alink = soup.select(&apos;h1&apos;)</span><br><span class="line">print(alink)</span><br><span class="line">print(alink[0])</span><br><span class="line">print(alink[0].text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有含a的元素</span><br><span class="line">soup = BeautifulSoup(html_sample, &apos;html.parser&apos;)</span><br><span class="line">alink = soup.select(&apos;a&apos;)</span><br><span class="line">print(alink)</span><br><span class="line">for link in alink:</span><br><span class="line">    print(link)</span><br><span class="line">    print(link.text)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有id为title的元素</span><br><span class="line">alink = soup.select(&apos;#title&apos;)</span><br><span class="line">print(alink)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有class为link的元素</span><br><span class="line">alink = soup.select(&apos;.link&apos;)</span><br><span class="line">for link in alink:</span><br><span class="line">    print(link)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#使用select 找出所有a tag 的href的连结</span><br><span class="line">alink = soup.select(&apos;a&apos;)</span><br><span class="line">for link in alink:</span><br><span class="line">    print(link[&apos;href&apos;])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">res = requests.get(&apos;http://news.sina.com.cn/china/&apos;)</span><br><span class="line">res.encoding = &apos;utf-8&apos;</span><br><span class="line">#print(type(res))</span><br><span class="line">soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for news in soup.select(&apos;.news-item&apos;):</span><br><span class="line">    #print(news)</span><br><span class="line">    if len(news.select(&apos;h2&apos;)) &gt; 0:</span><br><span class="line">        h2 = news.select(&apos;h2&apos;)[0].text</span><br><span class="line">        time = news.select(&apos;.time&apos;)[0].text</span><br><span class="line">        a = news.select(&apos;a&apos;)[0][&apos;href&apos;]</span><br><span class="line">        #print(time, h2, a)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">res = requests.get(&apos;http://news.sina.com.cn/c/2018-07-31/doc-ihhacrcc9897484.shtml&apos;)</span><br><span class="line">res.encoding = &apos;utf-8&apos;</span><br><span class="line">print(type(res))</span><br><span class="line">#print(res.text)</span><br><span class="line">soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#标题</span><br><span class="line">title = soup.select(&apos;.main-title&apos;)[0].text</span><br><span class="line">print(title)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#时间与来源</span><br><span class="line">datesource = soup.select(&apos;.date-source&apos;)[0]</span><br><span class="line">print(datesource)</span><br><span class="line">date = datesource.span.text</span><br><span class="line">print(date)</span><br><span class="line">source = datesource.a.text</span><br><span class="line">print(source)</span><br><span class="line">#或者</span><br><span class="line">#date = soup.select(&apos;.date-source&apos;)[0].contents[0].strip()</span><br><span class="line">#date</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#时间</span><br><span class="line">from datetime import datetime</span><br><span class="line">dt = datetime.strptime(date, &apos;%Y年%m月%d日 %H:%M&apos;) #str转time</span><br><span class="line">print(dt)</span><br><span class="line">dt.strftime(&apos;%Y-%M-%d&apos;)#time转str</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#文章内容</span><br><span class="line">article = []</span><br><span class="line">for p in soup.select(&apos;#article p&apos;)[:-1]:</span><br><span class="line">    article.append(p.text.strip())</span><br><span class="line">#print(article)</span><br><span class="line">&apos; &apos;.join(article)</span><br><span class="line">#或者&apos; &apos;.join[p.text.strip() for p in soup.select(&apos;#article p&apos;)[:-1]]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#编辑</span><br><span class="line">editor = soup.select(&apos;.show_author&apos;)[0].text.lstrip(&apos;责任编辑：&apos;)</span><br><span class="line">print(editor)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#评论</span><br><span class="line">import requests</span><br><span class="line">comments = requests.get(&apos;http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;\</span><br><span class="line">channel=gn&amp;newsid=comos-hhacrcc9897484&amp;group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;\</span><br><span class="line">page_size=3&apos;)</span><br><span class="line">#comments.text</span><br><span class="line">import json</span><br><span class="line">jd = json.loads(comments.text)</span><br><span class="line">#print(jd)</span><br><span class="line">commentnum = jd[&apos;result&apos;][&apos;count&apos;][&apos;total&apos;]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">newsurl = &apos;http://news.sina.com.cn/c/2018-07-31/doc-ihhacrcc9897484.shtml&apos;</span><br><span class="line">newsurl.split(&apos;/&apos;)[-1].rstrip(&apos;.shtml&apos;).lstrip(&apos;doc-i&apos;)</span><br><span class="line">#或正则式</span><br><span class="line">re.search(&apos;doc-i(.*).shtml&apos;, newsurl).group(1)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#整理评论</span><br><span class="line">commentURL = &apos;http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;\</span><br><span class="line">channel=gn&amp;newsid=comos-&#123;&#125;&amp;group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;\</span><br><span class="line">page_size=3&apos;</span><br><span class="line">import re</span><br><span class="line">import json</span><br><span class="line">def getCommentCount(newsurl):</span><br><span class="line">    newsid = re.search(&apos;doc-i(.*).shtml&apos;, newsurl).group(1)</span><br><span class="line">    comments = requests.get(commentURL.format(newsid))</span><br><span class="line">    jd = json.loads(comments.text)</span><br><span class="line">    return jd[&apos;result&apos;][&apos;count&apos;][&apos;total&apos;]</span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">news = &apos;http://news.sina.com.cn/c/2018-07-31/doc-ihhacrcc9897484.shtml&apos;</span><br><span class="line">getCommentCount(news)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#单个新闻信息</span><br><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">def getNewsDetail(newsurl):</span><br><span class="line">    result = &#123;&#125;</span><br><span class="line">    res = requests.get(newsurl)</span><br><span class="line">    res.encoding = &apos;utf-8&apos;</span><br><span class="line">    soup = BeautifulSoup(res.text, &apos;html.parser&apos;)</span><br><span class="line">    result[&apos;title&apos;] = soup.select(&apos;.main-title&apos;)[0].text</span><br><span class="line">    result[&apos;newssource&apos;] = soup.select(&apos;.date-source&apos;)[0].a.text</span><br><span class="line">    date = soup.select(&apos;.date-source&apos;)[0].span.text</span><br><span class="line">    result[&apos;dt&apos;] = datetime.strptime(date, &apos;%Y年%m月%d日 %H:%M&apos;) #str转time</span><br><span class="line">    result[&apos;article&apos;] = &apos; &apos;.join([p.text.strip() for p in soup.select(&apos;#article p&apos;)[:-1]])</span><br><span class="line">    result[&apos;editor&apos;] = soup.select(&apos;.show_author&apos;)[0].text.lstrip(&apos;责任编辑：&apos;)</span><br><span class="line">    result[&apos;comments&apos;] = getCommentCount(newsurl)</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line">#test</span><br><span class="line">news = &apos;http://news.sina.com.cn/c/nd/2018-07-24/doc-ihftenhz7547208.shtml&apos;</span><br><span class="line">getNewsDetail(news)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#剖析分页信息</span><br><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">res = requests.get(&apos;http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;\</span><br><span class="line">cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&amp;level==1||=2&amp;show_ext=1&amp;show_all=1&amp;show_num=22&amp;tag=1&amp;\</span><br><span class="line">format=json&amp;page=6&amp;callback=newsloadercallback&amp;_=1533026268219&apos;)</span><br><span class="line">jd = json.loads(res.text.lstrip(&apos;  newsloadercallback(&apos;).rstrip(&apos;);&apos;))</span><br><span class="line">#jd</span><br><span class="line">for ent in jd[&apos;result&apos;][&apos;data&apos;]:</span><br><span class="line">    print(ent[&apos;url&apos;])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#建立剖析清单链接函式</span><br><span class="line">def parseListLinks(url):</span><br><span class="line">    newsdetails = []</span><br><span class="line">    res = requests.get(url)</span><br><span class="line">    jd = json.loads(res.text.lstrip(&apos;  newsloadercallback(&apos;).rstrip(&apos;);&apos;))</span><br><span class="line">    for ent in jd[&apos;result&apos;][&apos;data&apos;]:</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            print(ent[&apos;url&apos;])</span><br><span class="line">            newsdetails.append(getNewsDetail(ent[&apos;url&apos;]))</span><br><span class="line">        except AttributeError:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">    return newsdetails</span><br><span class="line"></span><br><span class="line">#test </span><br><span class="line">url = &apos;http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;\</span><br><span class="line">cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&amp;level==1||=2&amp;show_ext=1&amp;show_all=1&amp;show_num=22&amp;tag=1&amp;\</span><br><span class="line">format=json&amp;page=6&amp;callback=newsloadercallback&amp;_=1533026268219&apos;</span><br><span class="line">parseListLinks(url)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#使用for循环产生多页连结&amp;批次抓取每页新闻内文</span><br><span class="line">def createUrl(num):</span><br><span class="line">    url = &apos;http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;\</span><br><span class="line">cat_2==gdxw1||=gatxw||=zs-pl||=mtjj&amp;level==1||=2&amp;show_ext=1&amp;show_all=1&amp;show_num=22&amp;tag=1&amp;\</span><br><span class="line">format=json&amp;page=&#123;&#125;&apos;#使用&#123;&#125;代替</span><br><span class="line">    news_total = []</span><br><span class="line">    for i in range(1, num):</span><br><span class="line">        newsurl = url.format(i)</span><br><span class="line">        print(newsurl)</span><br><span class="line">        newsary = parseListLinks(newsurl)</span><br><span class="line">        news_total.extend(newsary)</span><br><span class="line">    return news_total</span><br><span class="line">#test</span><br><span class="line">news_total = createUrl(3)</span><br><span class="line">#print(news_total)</span><br><span class="line">len(news_total)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#pandas 整理资料</span><br><span class="line">import pandas</span><br><span class="line">df = pandas.DataFrame(news_total)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#保存数据</span><br><span class="line">df.to_csv(&apos;news.csv&apos;)#到csv</span><br><span class="line">import sqlite3 #到sql</span><br><span class="line">with sqlite3.connect(&apos;news.sqlite&apos;) as db:</span><br><span class="line">    df.to_sql(&apos;news&apos;, con = db)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#操作sql</span><br><span class="line">import sqlite3</span><br><span class="line">with sqlite3.connect(&apos;news.sqlite&apos;) as db:</span><br><span class="line">    df2 = pandas.read_sql_query(&apos;SELECT * FROM news&apos;, con = db)</span><br><span class="line">df2.head()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/数据分析/">数据分析</a>
  </div>

        
  <div class="tags">
    <a href="/tags/python/">python</a>, <a href="/tags/爬虫/">爬虫</a>
  </div>

        
  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a><a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a></div>
  <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div></div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">25</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 13.33px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.33px;">Machine Learning 课程笔记</a> <a href="/tags/hexo/" style="font-size: 11.67px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.67px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.67px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 13.33px;">模型</a> <a href="/tags/爬虫/" style="font-size: 11.67px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.67px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2018 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>