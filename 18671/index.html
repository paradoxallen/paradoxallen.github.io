<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>预测北京和伦敦两个城市的空气质量 | RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  <meta name="description" content="源代码分享">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="预测北京和伦敦两个城市的空气质量"/>
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-17T16:00:00.000Z"><a href="/18671/">2018-06-18</a></time>
        
  
    <h1 class="title">预测北京和伦敦两个城市的空气质量</h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p>源代码分享<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import pickle</span><br><span class="line">import hashlib</span><br><span class="line">import requests</span><br><span class="line">import datetime</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from tqdm import tqdm</span><br><span class="line">import lightgbm as lgb</span><br><span class="line">from io import StringIO</span><br><span class="line">from dateutil.parser import parse</span><br><span class="line">from datetime import date, timedelta</span><br><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line"></span><br><span class="line">inplace = False</span><br><span class="line">cache_path = &apos;../cache/&apos;</span><br><span class="line">data_path = &apos;../data/&apos;</span><br><span class="line">station_dict = pd.read_csv(&apos;../data/station_dict.csv&apos;)</span><br><span class="line"></span><br><span class="line">##########################################基础工具包#######################################</span><br><span class="line"># 日期的加减</span><br><span class="line">def date_add_days(start_date, days):</span><br><span class="line">    end_date = parse(start_date[:10]) + timedelta(days=days)</span><br><span class="line">    end_date = end_date.strftime(&apos;%Y-%m-%d&apos;)</span><br><span class="line">    return end_date</span><br><span class="line"># 日期的加减</span><br><span class="line">def date_add_hours(start_date, hours):</span><br><span class="line">    end_date = parse(start_date) + timedelta(hours=hours)</span><br><span class="line">    end_date = end_date.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;)</span><br><span class="line">    return end_date</span><br><span class="line"># 压缩数据降低精度</span><br><span class="line">def convert_dtypes(data,predictors,slient=False):</span><br><span class="line">    for c in predictors:</span><br><span class="line">        if data[c].dtypes == &apos;O&apos;:</span><br><span class="line">            try:</span><br><span class="line">                data[c] = data[c].astype(&apos;float32&apos;)</span><br><span class="line">            except:</span><br><span class="line">                if not slient:</span><br><span class="line">                    print(&apos;特征&#123;&#125;格式无法转换&apos;.format(c))</span><br><span class="line">        if data[c].dtypes == &apos;float64&apos;:</span><br><span class="line">            data[c] = data[c].astype(&apos;float32&apos;)</span><br><span class="line">    return data</span><br><span class="line"></span><br><span class="line">##########################################aq数据更新#######################################</span><br><span class="line">def up_date():</span><br><span class="line"></span><br><span class="line">    # 北京aq数据（起始时间2018-03-31-16）</span><br><span class="line">    url = &apos;https://biendata.com/competition/airquality/bj/2018-03-31-16/2018-06-11-23/2k0d1d8&apos;</span><br><span class="line">    # url = &apos;http://kdd.caiyunapp.com/competition/2k0d1d8/bj/2018-03-31-16/2018-06-11-23/airquality&apos;</span><br><span class="line">    respones= requests.get(url)</span><br><span class="line">    with open (data_path + &quot;bj_aq+.csv&quot;,&apos;w&apos;) as f:</span><br><span class="line">        f.write(respones.text)</span><br><span class="line"></span><br><span class="line">    # 伦敦aq数据（起始时间2018-03-31-16）</span><br><span class="line">    url = &apos;https://biendata.com/competition/airquality/ld/2018-03-31-16/2018-06-11-23/2k0d1d8&apos;</span><br><span class="line">    # url = &apos;http://kdd.caiyunapp.com/competition/2k0d1d8/ld/2018-03-31-16/2018-06-11-23/airquality&apos;</span><br><span class="line">    respones= requests.get(url)</span><br><span class="line">    with open (data_path + &quot;ld_aq+.csv&quot;,&apos;w&apos;) as f:</span><br><span class="line">        f.write(respones.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    bj_aq_more = pd.read_csv(data_path + &apos;bj_aq_more.csv&apos;)</span><br><span class="line">    bj_aq_1718 = pd.read_csv(data_path + &apos;beijing_17_18_aq.csv&apos;)</span><br><span class="line">    bj_aq_0203 = pd.read_csv(data_path + &apos;beijing_201802_201803_aq.csv&apos;)</span><br><span class="line"></span><br><span class="line">    ld_aq = pd.read_csv(data_path + &apos;London_historical_aqi_forecast_stations_20180331.csv&apos;,index_col=0)</span><br><span class="line">    ld_other = pd.read_csv(data_path + &apos;London_historical_aqi_other_stations_20180331.csv&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    bj_aq = bj_aq_1718.append(bj_aq_0203).append(bj_aq_more)</span><br><span class="line">    del bj_aq_1718,bj_aq_0203,bj_aq_more</span><br><span class="line">    bj_aq.rename(columns=&#123;&apos;stationId&apos;:&apos;station_id&apos;,&apos;utc_time&apos;:&apos;time&apos;&#125;,inplace=True)</span><br><span class="line">    ld_aq.rename(columns=&#123;&apos;MeasurementDateGMT&apos;:&apos;time&apos;,&apos;PM2.5 (ug/m3)&apos;:&apos;PM2.5&apos;,&apos;PM10 (ug/m3)&apos;:&apos;PM10&apos;,&apos;NO2 (ug/m3)&apos;:&apos;NO2&apos;&#125;,inplace=True)</span><br><span class="line">    ld_aq[&apos;time&apos;] = pd.to_datetime(ld_aq[&apos;time&apos;]).astype(str)</span><br><span class="line">    ld_aq_more = pd.read_csv(data_path+&apos;ld_aq_more.csv&apos;)</span><br><span class="line">    ld_aq_more[&apos;time&apos;] = pd.to_datetime(ld_aq_more[&apos;time&apos;]).astype(str)</span><br><span class="line">    ld_other.rename(columns=&#123;&apos;MeasurementDateGMT&apos;:&apos;time&apos;,&apos;PM2.5 (ug/m3)&apos;:&apos;PM2.5&apos;,&apos;PM10 (ug/m3)&apos;:&apos;PM10&apos;,&apos;NO2 (ug/m3)&apos;:&apos;NO2&apos;,&apos;Station_ID&apos;:&apos;station_id&apos;&#125;,inplace=True)</span><br><span class="line">    ld_other.drop([&apos;Unnamed: 5&apos;,&apos;Unnamed: 6&apos;],axis=1,inplace=True)</span><br><span class="line">    ld_other[&apos;time&apos;] = pd.to_datetime(ld_other[&apos;time&apos;]).astype(str)</span><br><span class="line">    ld_aq = ld_aq.append(ld_other).append(ld_aq_more)</span><br><span class="line"></span><br><span class="line">    bj_aq1 = pd.read_csv(data_path + &apos;bj_aq+.csv&apos;)</span><br><span class="line">    ld_aq1 = pd.read_csv(data_path + &apos;ld_aq+.csv&apos;)</span><br><span class="line"></span><br><span class="line">    del bj_aq1[&apos;id&apos;]</span><br><span class="line">    bj_aq1.rename(columns=&#123;&apos;PM25_Concentration&apos;:&apos;PM2.5&apos;,&apos;PM10_Concentration&apos;:&apos;PM10&apos;,&apos;NO2_Concentration&apos;:&apos;NO2&apos;,</span><br><span class="line">                           &apos;CO_Concentration&apos;:&apos;CO&apos;,&apos;O3_Concentration&apos;:&apos;O3&apos;,&apos;SO2_Concentration&apos;:&apos;SO2&apos;&#125;,inplace=True)</span><br><span class="line">    bj_aq = bj_aq.append(bj_aq1)</span><br><span class="line">    bj_aq[&apos;station_id&apos;] = bj_aq[&apos;station_id&apos;].str[:-3]</span><br><span class="line">    del bj_aq1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ld_aq1.drop([&apos;id&apos;,&apos;CO_Concentration&apos;,&apos;O3_Concentration&apos;,&apos;SO2_Concentration&apos;],axis=1,inplace=True)</span><br><span class="line">    ld_aq1.rename(columns=&#123;&apos;NO2_Concentration&apos;:&apos;NO2&apos;,&apos;PM25_Concentration&apos;:&apos;PM2.5&apos;,&apos;PM10_Concentration&apos;:&apos;PM10&apos;&#125;,inplace=True)</span><br><span class="line">    ld_aq = ld_aq.append(ld_aq1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    aq = bj_aq.append(ld_aq).drop_duplicates([&apos;station_id&apos;,&apos;time&apos;])</span><br><span class="line">    aq = aq[~aq[&apos;station_id&apos;].isnull()]</span><br><span class="line">    aq.to_hdf(data_path+&apos;aq.hdf&apos;,&apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(&apos;更新完毕....&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##########################################grid数据更新（更新天气预报）#######################################</span><br><span class="line"># 更新api grid数据</span><br><span class="line">def update_meo_grid():</span><br><span class="line"></span><br><span class="line">    dates = [str(date)[:10] for date in pd.date_range(&apos;2018-04-07&apos;,&apos;2018-06-05&apos;)]</span><br><span class="line">    for date in dates:</span><br><span class="line">        if date &gt; time.strftime(&quot;%Y-%m-%d&quot;, time.gmtime()):</span><br><span class="line">            continue</span><br><span class="line">        result_path = data_path + &quot;meo_grid_&#123;&#125;.csv&quot;.format(date)</span><br><span class="line">        if not os.path.exists(result_path):</span><br><span class="line">            # 北京meo_grid数据（起始时间2018-04-09-22）</span><br><span class="line">            url = &apos;http://kdd.caiyunapp.com/competition/forecast/bj/&#123;&#125;-22/2k0d1d8&apos;.format(date)</span><br><span class="line">            respones = requests.get(url)</span><br><span class="line">            if respones.text == &apos;None&apos;:</span><br><span class="line">                print(&apos;北京&#123;&#125;的数据api不存在&apos;.format(date))</span><br><span class="line">            else:</span><br><span class="line">                bj_result = pd.read_csv(StringIO(respones.text))</span><br><span class="line">                bj_result.drop([&apos;id&apos;, &apos;weather&apos;], axis=1, inplace=True)</span><br><span class="line">                bj_result.rename(columns=&#123;&apos;station_id&apos;: &apos;station_name&apos;, &apos;forecast_time&apos;: &apos;time&apos;&#125;, inplace=True)</span><br><span class="line">                bj_result = station_dict.merge(bj_result, on=&apos;station_name&apos;, how=&apos;inner&apos;)</span><br><span class="line">                del bj_result[&apos;station_name&apos;]</span><br><span class="line">                # result.to_csv(result_path, index=False)</span><br><span class="line">                print(&apos;正在更新北京&#123;&#125;的数据...&apos;.format(date))</span><br><span class="line"></span><br><span class="line">            # 伦敦meo_grid数据（起始时间2018-04-09-22）</span><br><span class="line">            url = &apos;http://kdd.caiyunapp.com/competition/forecast/ld/&#123;&#125;-22/2k0d1d8&apos;.format(date)</span><br><span class="line">            respones = requests.get(url)</span><br><span class="line">            if respones.text == &apos;None&apos;:</span><br><span class="line">                print(&apos;伦敦&#123;&#125;的数据api不存在&apos;.format(date))</span><br><span class="line">            else:</span><br><span class="line">                ld_result = pd.read_csv(StringIO(respones.text))</span><br><span class="line">                ld_result.drop([&apos;id&apos;, &apos;weather&apos;], axis=1, inplace=True)</span><br><span class="line">                ld_result.rename(columns=&#123;&apos;station_id&apos;: &apos;station_name&apos;, &apos;forecast_time&apos;: &apos;time&apos;&#125;, inplace=True)</span><br><span class="line">                ld_result = station_dict.merge(ld_result, on=&apos;station_name&apos;, how=&apos;inner&apos;)</span><br><span class="line">                del ld_result[&apos;station_name&apos;]</span><br><span class="line">                # result.to_csv(result_path,index=False)</span><br><span class="line">                print(&apos;正在更新伦敦&#123;&#125;的数据...&apos;.format(date))</span><br><span class="line">                result = pd.concat([bj_result, ld_result])</span><br><span class="line">                if (date &gt; &apos;2018-04-07&apos;) &amp; (date &lt; &apos;2018-04-23&apos;):</span><br><span class="line">                    temp = result[&apos;wind_direction&apos;]</span><br><span class="line">                    result[&apos;wind_direction&apos;] = result[&apos;wind_speed&apos;]</span><br><span class="line">                    result[&apos;wind_speed&apos;] = temp</span><br><span class="line">                result.to_csv(result_path, index=False)</span><br><span class="line">        else:</span><br><span class="line">            print(&apos;&#123;&#125;的数据已存在&apos;.format(date))</span><br><span class="line"></span><br><span class="line"># 更新历史grid数据</span><br><span class="line">def update_meo_grid2():</span><br><span class="line">    bj_meo_grid = pd.read_hdf(data_path + &apos;bj_meo_grid.hdf&apos;)</span><br><span class="line">    ld_meo_grid = pd.read_hdf(data_path + &apos;ld_meo_grid.hdf&apos;)</span><br><span class="line"></span><br><span class="line">    bj_meo_grid.drop([&apos;latitude&apos;, &apos;longitude&apos;, &apos;weather&apos;], axis=1, inplace=True)</span><br><span class="line">    ld_meo_grid.drop([&apos;latitude&apos;, &apos;longitude&apos;, &apos;weather&apos;], axis=1, inplace=True)</span><br><span class="line">    dates = [str(date)[:10] for date in pd.date_range(&apos;2017-01-01&apos;,&apos;2018-04-01&apos;)]</span><br><span class="line">    for date in dates:</span><br><span class="line">        start_time = date_add_hours(date, 0)[:10] + &apos; 23:00:00&apos;</span><br><span class="line">        end_time = date_add_hours(date, 48)[:10] + &apos; 23:00:00&apos;</span><br><span class="line">        result_path = data_path + &quot;meo_grid_&#123;&#125;.csv&quot;.format(date)</span><br><span class="line">        if not os.path.exists(result_path):</span><br><span class="line">            try:</span><br><span class="line">                bj_result = bj_meo_grid[(bj_meo_grid[&apos;time&apos;]&gt;=start_time) &amp; (bj_meo_grid[&apos;time&apos;]&lt;end_time)].copy()</span><br><span class="line">                bj_result = station_dict.merge(bj_result, on=&apos;station_name&apos;, how=&apos;inner&apos;)</span><br><span class="line">                del bj_result[&apos;station_name&apos;]</span><br><span class="line">                print(&apos;正在更新北京&#123;&#125;的数据...&apos;.format(date))</span><br><span class="line">            except:</span><br><span class="line">                print(&apos;北京&#123;&#125;的数据更新失败&apos;.format(date))</span><br><span class="line">            try:</span><br><span class="line">                ld_result = ld_meo_grid[(ld_meo_grid[&apos;time&apos;]&gt;=start_time) &amp; (ld_meo_grid[&apos;time&apos;]&lt;end_time)].copy()</span><br><span class="line">                ld_result = station_dict.merge(ld_result, on=&apos;station_name&apos;, how=&apos;inner&apos;)</span><br><span class="line">                del ld_result[&apos;station_name&apos;]</span><br><span class="line">                print(&apos;正在更新伦敦&#123;&#125;的数据...&apos;.format(date))</span><br><span class="line">            except:</span><br><span class="line">                print(&apos;伦敦&#123;&#125;的数据更新失败&apos;.format(date))</span><br><span class="line">            result = pd.concat([bj_result, ld_result])</span><br><span class="line">            result.to_csv(result_path, index=False)</span><br><span class="line">        else:</span><br><span class="line">            print(&apos;&#123;&#125;的数据已存在&apos;.format(date))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">aq = pd.read_hdf(data_path+&apos;aq.hdf&apos;)</span><br><span class="line">temp = aq[[&apos;CO&apos;, &apos;NO2&apos;, &apos;O3&apos;, &apos;PM10&apos;, &apos;PM2.5&apos;, &apos;SO2&apos;]].copy()</span><br><span class="line">temp[temp&lt;0] = np.nan</span><br><span class="line">aq[[&apos;CO&apos;, &apos;NO2&apos;, &apos;O3&apos;, &apos;PM10&apos;, &apos;PM2.5&apos;, &apos;SO2&apos;]] = temp</span><br><span class="line">aq2 = aq.copy()</span><br><span class="line">aq[[&apos;CO&apos;, &apos;NO2&apos;, &apos;O3&apos;, &apos;PM10&apos;, &apos;PM2.5&apos;, &apos;SO2&apos;]] = np.log(aq[[&apos;CO&apos;, &apos;NO2&apos;, &apos;O3&apos;, &apos;PM10&apos;, &apos;PM2.5&apos;, &apos;SO2&apos;]]+100)</span><br><span class="line"></span><br><span class="line">station_info = pd.read_csv(data_path+&apos;station_info.csv&apos;)</span><br><span class="line">station_info[&apos;sitetype&apos;] = LabelEncoder().fit_transform(station_info[&apos;sitetype&apos;])</span><br><span class="line">holidays = pd.read_csv(data_path + &apos;holidays.csv&apos;)</span><br><span class="line">aq = aq.merge(station_info[[&apos;station_id&apos;,&apos;sitetype&apos;,&apos;city&apos;]],on=&apos;station_id&apos;,how=&apos;left&apos;)</span><br><span class="line">aq[&apos;hour&apos;] = pd.to_datetime(aq[&apos;time&apos;]).dt.hour</span><br><span class="line">aq[&apos;date&apos;] = aq[&apos;time&apos;].str[:10]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bj_station_id = [&apos;aotizhongxin&apos;, &apos;badaling&apos;, &apos;beibuxinqu&apos;, &apos;daxing&apos;, &apos;dingling&apos;,</span><br><span class="line">       &apos;donggaocun&apos;, &apos;dongsi&apos;, &apos;dongsihuan&apos;, &apos;fangshan&apos;, &apos;fengtaihuayuan&apos;,</span><br><span class="line">       &apos;guanyuan&apos;, &apos;gucheng&apos;, &apos;huairou&apos;, &apos;liulihe&apos;, &apos;mentougou&apos;, &apos;miyun&apos;,</span><br><span class="line">       &apos;miyunshuiku&apos;, &apos;nansanhuan&apos;, &apos;nongzhanguan&apos;, &apos;pingchang&apos;, &apos;pinggu&apos;,</span><br><span class="line">       &apos;qianmen&apos;, &apos;shunyi&apos;, &apos;tiantan&apos;, &apos;tongzhou&apos;, &apos;wanliu&apos;,</span><br><span class="line">       &apos;wanshouxigong&apos;, &apos;xizhimenbei&apos;, &apos;yanqin&apos;, &apos;yizhuang&apos;,</span><br><span class="line">       &apos;yongdingmennei&apos;, &apos;yongledian&apos;, &apos;yufa&apos;, &apos;yungang&apos;, &apos;zhiwuyuan&apos;]</span><br><span class="line">ld_station_id = [&apos;CD1&apos;, &apos;BL0&apos;, &apos;GR4&apos;, &apos;MY7&apos;, &apos;HV1&apos;, &apos;GN3&apos;, &apos;GR9&apos;, &apos;LW2&apos;, &apos;GN0&apos;,</span><br><span class="line">       &apos;KF1&apos;, &apos;CD9&apos;, &apos;ST5&apos;, &apos;TH4&apos;, &apos;LH0&apos;, &apos;HR1&apos;, &apos;TD5&apos;, &apos;CT3&apos;, &apos;GB0&apos;,</span><br><span class="line">       &apos;CR8&apos;, &apos;RB7&apos;, &apos;BX1&apos;, &apos;BX9&apos;, &apos;KC1&apos;, &apos;CT2&apos;]</span><br><span class="line">station_id = [&apos;aotizhongxin&apos;, &apos;badaling&apos;, &apos;beibuxinqu&apos;, &apos;daxing&apos;, &apos;dingling&apos;,</span><br><span class="line">       &apos;donggaocun&apos;, &apos;dongsi&apos;, &apos;dongsihuan&apos;, &apos;fangshan&apos;, &apos;fengtaihuayuan&apos;,</span><br><span class="line">       &apos;guanyuan&apos;, &apos;gucheng&apos;, &apos;huairou&apos;, &apos;liulihe&apos;, &apos;mentougou&apos;, &apos;miyun&apos;,</span><br><span class="line">       &apos;miyunshuiku&apos;, &apos;nansanhuan&apos;, &apos;nongzhanguan&apos;, &apos;pingchang&apos;, &apos;pinggu&apos;,</span><br><span class="line">       &apos;qianmen&apos;, &apos;shunyi&apos;, &apos;tiantan&apos;, &apos;tongzhou&apos;, &apos;wanliu&apos;,</span><br><span class="line">       &apos;wanshouxigong&apos;, &apos;xizhimenbei&apos;, &apos;yanqin&apos;, &apos;yizhuang&apos;,</span><br><span class="line">       &apos;yongdingmennei&apos;, &apos;yongledian&apos;, &apos;yufa&apos;, &apos;yungang&apos;, &apos;zhiwuyuan&apos;,</span><br><span class="line">       &apos;CD1&apos;, &apos;BL0&apos;, &apos;GR4&apos;, &apos;MY7&apos;, &apos;HV1&apos;, &apos;GN3&apos;, &apos;GR9&apos;, &apos;LW2&apos;, &apos;GN0&apos;,</span><br><span class="line">       &apos;KF1&apos;, &apos;CD9&apos;, &apos;ST5&apos;, &apos;TH4&apos;, &apos;LH0&apos;, &apos;HR1&apos;, &apos;TD5&apos;, &apos;CT3&apos;, &apos;GB0&apos;,</span><br><span class="line">       &apos;CR8&apos;, &apos;RB7&apos;, &apos;BX1&apos;, &apos;BX9&apos;, &apos;KC1&apos;, &apos;CT2&apos;</span><br><span class="line">              ]</span><br><span class="line">stationName = [&apos;beijing_grid_303&apos;, &apos;beijing_grid_303&apos;, &apos;beijing_grid_282&apos;, &apos;beijing_grid_303&apos;, &apos;beijing_grid_304&apos;,</span><br><span class="line"> &apos;beijing_grid_324&apos;,  &apos;beijing_grid_283&apos;,  &apos;beijing_grid_263&apos;, &apos;beijing_grid_262&apos;,  &apos;beijing_grid_282&apos;, &apos;beijing_grid_239&apos;,</span><br><span class="line"> &apos;beijing_grid_261&apos;, &apos;beijing_grid_238&apos;,&apos;beijing_grid_301&apos;,&apos;beijing_grid_323&apos;,&apos;beijing_grid_366&apos;, &apos;beijing_grid_368&apos;,</span><br><span class="line"> &apos;beijing_grid_264&apos;, &apos;beijing_grid_240&apos;, &apos;beijing_grid_452&apos;, &apos;beijing_grid_349&apos;, &apos;beijing_grid_392&apos;, &apos;beijing_grid_225&apos;,</span><br><span class="line"> &apos;beijing_grid_265&apos;, &apos;beijing_grid_224&apos;, &apos;beijing_grid_414&apos;, &apos;beijing_grid_452&apos;, &apos;beijing_grid_385&apos;, &apos;beijing_grid_278&apos;,</span><br><span class="line"> &apos;beijing_grid_216&apos;, &apos;beijing_grid_303&apos;, &apos;beijing_grid_303&apos;, &apos;beijing_grid_283&apos;, &apos;beijing_grid_303&apos;, &apos;beijing_grid_324&apos;,</span><br><span class="line"> &apos;london_grid_472&apos;, &apos;london_grid_472&apos;, &apos;london_grid_409&apos;, &apos;london_grid_409&apos;, &apos;london_grid_388&apos;, &apos;london_grid_409&apos;,</span><br><span class="line"> &apos;london_grid_409&apos;, &apos;london_grid_408&apos;, &apos;london_grid_451&apos;, &apos;london_grid_451&apos;, &apos;london_grid_451&apos;, &apos;london_grid_430&apos;,</span><br><span class="line"> &apos;london_grid_451&apos;, &apos;london_grid_368&apos;, &apos;london_grid_472&apos;, &apos;london_grid_346&apos;, &apos;london_grid_388&apos;, &apos;london_grid_388&apos;,</span><br><span class="line"> &apos;london_grid_430&apos;, &apos;london_grid_452&apos;, &apos;london_grid_366&apos;, &apos;london_grid_408&apos;, &apos;london_grid_430&apos;, &apos;london_grid_388&apos;]</span><br><span class="line"></span><br><span class="line">############################### 工具函数 ###########################</span><br><span class="line"># 合并节约内存</span><br><span class="line">def concat(L):</span><br><span class="line">    result = None</span><br><span class="line">    for l in L:</span><br><span class="line">        if result is None:</span><br><span class="line">            result = l</span><br><span class="line">        else:</span><br><span class="line">            result[l.columns.tolist()] = l</span><br><span class="line">    return result</span><br><span class="line"># groupby 直接拼接</span><br><span class="line">def groupby(data,stat,key,value,func):</span><br><span class="line">    key = key if type(key)==list else [key]</span><br><span class="line">    data_temp = data[key].copy()</span><br><span class="line">    feat = stat.groupby(key,as_index=False)[value].agg(&#123;&apos;feat&apos;:func&#125;)</span><br><span class="line">    data_temp = data_temp.merge(feat,on=key,how=&apos;left&apos;)</span><br><span class="line">    return data_temp[&apos;feat&apos;].values</span><br><span class="line"># 相差的小时数</span><br><span class="line">def diff_of_hours(time1,time2):</span><br><span class="line">    hours = (parse(time1) - parse(time2)).total_seconds()//3600</span><br><span class="line">    return abs(hours)</span><br><span class="line">############################### 预处理函数 ###########################</span><br><span class="line">def pre_treatment(data_key):</span><br><span class="line">    result_path = cache_path + &apos;data_&#123;&#125;.hdf&apos;.format(data_key)</span><br><span class="line">    if os.path.exists(result_path) &amp; 1:</span><br><span class="line">        data = pd.read_hdf(result_path, &apos;w&apos;)</span><br><span class="line">    else:</span><br><span class="line">        times = pd.date_range(data_key,date_add_days(data_key,2),freq=&apos;H&apos;)[:-1]</span><br><span class="line">        data = pd.DataFrame(index=times,columns=station_id).unstack().reset_index().drop(0,axis=1)</span><br><span class="line">        data.columns = [&apos;station_id&apos;,&apos;time&apos;]</span><br><span class="line">        data = data.merge(station_info, on=&apos;station_id&apos;, how=&apos;left&apos;)</span><br><span class="line">        data[&apos;hour&apos;] = data[&apos;time&apos;].dt.hour</span><br><span class="line">        data[&apos;month&apos;] = data[&apos;time&apos;].dt.month</span><br><span class="line">        data[&apos;year&apos;] = data[&apos;time&apos;].dt.year</span><br><span class="line">        data[&apos;day_of_week&apos;] = data[&apos;time&apos;].dt.dayofweek</span><br><span class="line">        data[&apos;day_of_month&apos;] = data[&apos;time&apos;].dt.day</span><br><span class="line">        data[&apos;day_of_year&apos;] = data[&apos;time&apos;].dt.dayofyear</span><br><span class="line">        data[&apos;time&apos;] = data[&apos;time&apos;].astype(str)</span><br><span class="line">        data[&apos;date&apos;] = data[&apos;time&apos;].str[:10]</span><br><span class="line">        data[&apos;diff_of_hour&apos;] = (data[&apos;date&apos;]!=data_key).astype(int)*24+data[&apos;hour&apos;]</span><br><span class="line">        data = data.merge(holidays,on=&apos;date&apos;,how=&apos;left&apos;)</span><br><span class="line">        data.reset_index(drop=True, inplace=True)</span><br><span class="line">        data.to_hdf(result_path, &apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line">    return data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">############################### 预处理函数 ###########################</span><br><span class="line"># 24个小时前的数据</span><br><span class="line">def get_24hour_feat(data,data_key,replace):</span><br><span class="line">    result_path = cache_path + &apos;24hour_feat_&#123;&#125;_&#123;&#125;hours_ago.hdf&apos;.format(data_key,1)</span><br><span class="line">    if os.path.exists(result_path) &amp; (not replace):</span><br><span class="line">        feat = pd.read_hdf(result_path, &apos;w&apos;)</span><br><span class="line">    else:</span><br><span class="line">        start_time = date_add_hours(data_key, -25)</span><br><span class="line">        end_time1 = date_add_hours(data_key, -1)</span><br><span class="line">        end_time0 = date_add_hours(data_key, -2)</span><br><span class="line">        bj_aq = aq[(aq[&apos;city&apos;]==1) &amp; (aq[&apos;time&apos;] &lt; end_time1) &amp; (aq[&apos;time&apos;] &gt;= start_time)].copy()</span><br><span class="line">        ld_aq = aq[(aq[&apos;city&apos;] == 0) &amp; (aq[&apos;time&apos;] &lt; end_time0) &amp; (aq[&apos;time&apos;] &gt;= start_time)].copy()</span><br><span class="line">        data_temp = bj_aq.append(ld_aq)</span><br><span class="line">        feat = data[[&apos;station_id&apos;,&apos;city&apos;,&apos;sitetype&apos;]].copy()</span><br><span class="line">        for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">            result_temp = data_temp.set_index([&apos;station_id&apos;, &apos;time&apos;])[label].unstack()</span><br><span class="line">            result_temp.columns = [&apos;&#123;&#125;_&#123;&#125;hour_last&apos;.format(label,c[11:13]) for c in result_temp.columns]</span><br><span class="line">            feat = feat.merge(result_temp.reset_index(),on=&apos;station_id&apos;,how=&apos;left&apos;)</span><br><span class="line">        for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">            result_temp = data_temp.groupby([&apos;city&apos;, &apos;time&apos;])[label].mean().unstack()</span><br><span class="line">            result_temp.columns = [&apos;&#123;&#125;_&#123;&#125;hour_last_city&apos;.format(label,c[11:13]) for c in result_temp.columns]</span><br><span class="line">            feat = feat.merge(result_temp.reset_index(),on=&apos;city&apos;,how=&apos;left&apos;)</span><br><span class="line">        # for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">        #     result_temp = data_temp.groupby([&apos;sitetype&apos;, &apos;time&apos;])[label].mean().unstack()</span><br><span class="line">        #     result_temp.columns = [&apos;&#123;&#125;_&#123;&#125;hour_last_sitetype&apos;.format(label,c[11:13]) for c in result_temp.columns]</span><br><span class="line">        #     feat = feat.merge(result_temp.reset_index(),on=&apos;sitetype&apos;,how=&apos;left&apos;)</span><br><span class="line">        feat.to_hdf(result_path, &apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line">    return feat</span><br><span class="line"></span><br><span class="line"># 一个月内对应小时的值</span><br><span class="line">def get_nday_mean_feat(data,data_key,n,replace):</span><br><span class="line">    result_path = cache_path + &apos;&#123;&#125;day_mean_feat&#123;&#125;_&#123;&#125;hours_age.hdf&apos;.format(n,data_key,1)</span><br><span class="line">    if os.path.exists(result_path) &amp; (not replace):</span><br><span class="line">        feat = pd.read_hdf(result_path, &apos;w&apos;)</span><br><span class="line">    else:</span><br><span class="line">        start_time = date_add_hours(data_key, -1-24*n)</span><br><span class="line">        end_time = date_add_hours(data_key, -1)</span><br><span class="line">        data_temp = aq[(aq[&apos;time&apos;]&lt;end_time) &amp; (aq[&apos;time&apos;]&gt;=start_time)]</span><br><span class="line">        feat = data[[&apos;station_id&apos;,&apos;hour&apos;,&apos;date&apos;,&apos;city&apos;]].copy()</span><br><span class="line">        for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">            # feat[&apos;&#123;&#125;day_&#123;&#125;_mean&apos;.format(n,label)] = groupby(feat,data_temp,[&apos;station_id&apos;],label,np.mean)</span><br><span class="line">            # feat[&apos;&#123;&#125;day_&#123;&#125;_std&apos;.format(n,label)] = groupby(feat, data_temp, [&apos;station_id&apos;], label, np.std)</span><br><span class="line">            feat[&apos;&#123;&#125;day_hour_&#123;&#125;_mean&apos;.format(n,label)] = groupby(feat, data_temp, [&apos;station_id&apos;,&apos;hour&apos;], label, np.mean)</span><br><span class="line">        for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">            # feat[&apos;&#123;&#125;day_&#123;&#125;_mean_city&apos;.format(n,label)] = groupby(feat,data_temp,[&apos;station_id&apos;],label,np.mean)</span><br><span class="line">            # feat[&apos;&#123;&#125;day_&#123;&#125;_std_city&apos;.format(n,label)] = groupby(feat, data_temp, [&apos;station_id&apos;], label, np.std)</span><br><span class="line">            feat[&apos;&#123;&#125;day_&#123;&#125;_mean_city&apos;.format(n,label)] = groupby(feat, data_temp, [&apos;city&apos;,&apos;date&apos;], label, np.mean)</span><br><span class="line">        for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">            # feat[&apos;&#123;&#125;day_&#123;&#125;_mean_city&apos;.format(n,label)] = groupby(feat,data_temp,[&apos;station_id&apos;],label,np.mean)</span><br><span class="line">            # feat[&apos;&#123;&#125;day_&#123;&#125;_std_city&apos;.format(n,label)] = groupby(feat, data_temp, [&apos;station_id&apos;], label, np.std)</span><br><span class="line">            feat[&apos;&#123;&#125;day_hour_&#123;&#125;_mean_city&apos;.format(n,label)] = groupby(feat, data_temp, [&apos;city&apos;,&apos;hour&apos;], label, np.mean)</span><br><span class="line">        feat.to_hdf(result_path, &apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line">    return feat</span><br><span class="line"></span><br><span class="line"># 天气特征</span><br><span class="line">def get_weather_feat(data,data_key,replace):</span><br><span class="line">    result_path = cache_path + &apos;weather_feat&#123;&#125;.hdf&apos;.format(data_key)</span><br><span class="line">    if os.path.exists(result_path) &amp; (not replace):</span><br><span class="line">        feat = pd.read_hdf(result_path, &apos;w&apos;)</span><br><span class="line">    else:</span><br><span class="line">        data_temp = data[[&apos;station_id&apos;,&apos;time&apos;]].copy()</span><br><span class="line">        end_time = date_add_hours(data_key, -2)</span><br><span class="line">        try:</span><br><span class="line">            weather = pd.read_csv(r&apos;C:\Users\csw\Desktop\python\kdd\data\meo_grid_api\meo_grid_&#123;&#125;.csv&apos;.format(end_time[:10]))</span><br><span class="line">            date_time = data_temp[&apos;time&apos;].copy()</span><br><span class="line">            feat_columns = weather.columns.copy()</span><br><span class="line">            for i in [-18,-12,-6,-4,-3,-2,-1,0,1,2,3]:</span><br><span class="line">                weather.columns = [c+&apos;_ahead&#123;&#125;&apos;.format(i) if c not in [&apos;station_id&apos;,&apos;time&apos;] else c for c in feat_columns]</span><br><span class="line">                data_temp[&apos;time&apos;] = date_time.apply(lambda x: date_add_hours(x,i))</span><br><span class="line">                data_temp = data_temp.merge(weather,on=[&apos;station_id&apos;,&apos;time&apos;],how=&apos;left&apos;)</span><br><span class="line">            data_temp[&apos;temperature_diff_1&apos;] = data_temp[&apos;temperature_ahead0&apos;] - data_temp[&apos;temperature_ahead-1&apos;]</span><br><span class="line">            data_temp[&apos;temperature_diff_2&apos;] = data_temp[&apos;temperature_ahead0&apos;] - data_temp[&apos;temperature_ahead-2&apos;]</span><br><span class="line">            data_temp[&apos;temperature_diff_21&apos;] = data_temp[&apos;temperature_ahead-1&apos;] - data_temp[&apos;temperature_ahead-2&apos;]</span><br><span class="line">            data_temp[&apos;temperature_diff_3&apos;] = data_temp[&apos;temperature_ahead0&apos;] - data_temp[&apos;temperature_ahead-3&apos;]</span><br><span class="line">            data_temp[&apos;temperature_diff_31&apos;] = data_temp[&apos;temperature_ahead-2&apos;] - data_temp[&apos;temperature_ahead-3&apos;]</span><br><span class="line">            data_temp[&apos;humidity_diff_1&apos;] = (data_temp[&apos;humidity_ahead0&apos;] - data_temp[&apos;humidity_ahead-1&apos;])/data_temp[&apos;humidity_ahead0&apos;]</span><br><span class="line">            feat = data_temp.drop([&apos;station_id&apos;,&apos;time&apos;],axis=1)</span><br><span class="line">        except:</span><br><span class="line">            feat = pd.DataFrame()</span><br><span class="line">            print(&apos;&#123;&#125;的天气数据为空。&apos;.format(end_time[:10]))</span><br><span class="line">        feat.to_hdf(result_path, &apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line">    return feat</span><br><span class="line"></span><br><span class="line"># 添加标签</span><br><span class="line">def get_label(result):</span><br><span class="line">    return result.merge(aq2[[&apos;station_id&apos;,&apos;time&apos;,&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]],on=[&apos;station_id&apos;,&apos;time&apos;],how=&apos;left&apos;)</span><br><span class="line"></span><br><span class="line"># 二次处理特征</span><br><span class="line">def second_feat(result):</span><br><span class="line">    try:</span><br><span class="line">        result[&apos;PM2.5_22hour_last_city/PM2.5_21hour_last_city_rate&apos;] = result[&apos;PM2.5_22hour_last_city&apos;] / result[&apos;PM2.5_21hour_last_city&apos;]</span><br><span class="line">        result[&apos;PM10_22hour_last_city/PM10_21hour_last_city_rate&apos;] = result[&apos;PM10_22hour_last&apos;] / result[&apos;PM10_21hour_last_city&apos;]</span><br><span class="line">        result[&apos;O3_22hour_last/O3_21hour_last_rate&apos;] = result[&apos;O3_22hour_last_city&apos;] / result[&apos;O3_21hour_last_city&apos;]</span><br><span class="line">        result[&apos;PM2.5_21hour_last/PM2.5_20hour_last_rate&apos;] = result[&apos;PM2.5_21hour_last&apos;]/result[&apos;PM2.5_20hour_last&apos;]</span><br><span class="line">        result[&apos;PM10_21hour_last/PM10_20hour_last_rate&apos;] = result[&apos;PM10_21hour_last&apos;] / result[&apos;PM10_20hour_last&apos;]</span><br><span class="line">        result[&apos;O3_21hour_last/O3_20hour_last_rate&apos;] = result[&apos;O3_21hour_last&apos;] / result[&apos;O3_20hour_last&apos;]</span><br><span class="line">        result[&apos;30day_PM2.5_mean/60day_PM2.5_mean_rate&apos;] = result[&apos;30day_PM2.5_mean_city&apos;] / result[&apos;60day_PM2.5_mean_city&apos;]</span><br><span class="line">        result[&apos;30day_PM10_mean/60day_PM10_mean_rate&apos;] = result[&apos;30day_PM10_mean_city&apos;] / result[&apos;60day_PM10_mean_city&apos;]</span><br><span class="line">        result[&apos;30day_O3_mean/60day_O3_mean_rate&apos;] = result[&apos;30day_O3_mean_city&apos;] / result[&apos;60day_O3_mean_city&apos;]</span><br><span class="line">        result[&apos;3day_PM2.5_mean/7day_PM2.5_mean_rate&apos;] = result[&apos;3day_PM2.5_mean_city&apos;] / result[&apos;7day_PM2.5_mean_city&apos;]</span><br><span class="line">        result[&apos;3day_PM10_mean/7day_PM10_mean_rate&apos;] = result[&apos;3day_PM10_mean_city&apos;] / result[&apos;7day_PM10_mean_city&apos;]</span><br><span class="line">        result[&apos;3day_O3_mean/7day_O3_mean_rate&apos;] = result[&apos;3day_O3_mean_city&apos;] / result[&apos;7day_O3_mean_city&apos;]</span><br><span class="line">        result[&apos;1day_PM2.5_mean_city/2day_PM2.5_mean_city_rate&apos;] = result[&apos;1day_PM2.5_mean_city&apos;] / result[&apos;2day_PM2.5_mean_city&apos;]</span><br><span class="line">        result[&apos;1day_PM10_mean_city/2day_PM10_mean_city_rate&apos;] = result[&apos;1day_PM10_mean_city&apos;] / result[&apos;2day_PM10_mean_city&apos;]</span><br><span class="line">        result[&apos;1day_O3_mean_city/2day_O3_mean_city_rate&apos;] = result[&apos;1day_O3_mean_city&apos;] / result[&apos;2day_O3_mean_city&apos;]</span><br><span class="line">    except:</span><br><span class="line">        pass</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line">def make_feat(data_key,silent=0,replace=False):</span><br><span class="line">    # data_key = hashlib.md5(data.to_string().encode()).hexdigest()</span><br><span class="line">    print(end=&apos;&apos;) if silent else print(&apos;数据key为：&#123;&#125;&apos;.format(data_key))</span><br><span class="line">    result_path = cache_path + &apos;feat_set_&#123;&#125;_&#123;&#125;hour_ago.hdf&apos;.format(data_key,1)</span><br><span class="line">    if os.path.exists(result_path) &amp; (not replace):</span><br><span class="line">        result = pd.read_hdf(result_path, &apos;w&apos;)</span><br><span class="line">    else:</span><br><span class="line">        data = pre_treatment(data_key)</span><br><span class="line"></span><br><span class="line">        result = [data]</span><br><span class="line">        # print(&apos;开始构造特征...&apos;)</span><br><span class="line">        result.append(get_24hour_feat(data,data_key,replace))               # 24个小时前的数据</span><br><span class="line">        for i in [1,2,3,7,15,30,60,360]:</span><br><span class="line">            result.append(get_nday_mean_feat(data,data_key,i,replace))      # 一个月内对应小时的值</span><br><span class="line">        result.append(get_weather_feat(data, data_key,replace))             # 天气特征</span><br><span class="line"></span><br><span class="line">        # print(&apos;开始合并特征...&apos;)</span><br><span class="line">        result = concat(result)</span><br><span class="line"></span><br><span class="line">        result = second_feat(result)</span><br><span class="line">        # print(&apos;添加label&apos;)</span><br><span class="line">        result = get_label(result)</span><br><span class="line">        # print(&apos;存储数据...&apos;)</span><br><span class="line">        result = convert_dtypes(result, result.columns, slient=True)</span><br><span class="line">        result.to_hdf(result_path, &apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line">    print(end=&apos;&apos;) if silent else print(&apos;特征矩阵大小：&#123;&#125;&apos;.format(result.shape))</span><br><span class="line">    # print(&apos;生成特征一共用时&#123;&#125;秒&apos;.format(time.time() - t0))</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">up_date()</span><br><span class="line">update_meo_grid()</span><br><span class="line">update_meo_grid2()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hours = 1</span><br><span class="line">data_feat = []</span><br><span class="line">start_date = &apos;2018-05-05&apos;</span><br><span class="line">days = 400</span><br><span class="line">data_feat_url = cache_path + &apos;data_feat_&#123;&#125;_&#123;&#125;days.hdf&apos;.format(start_date,days)</span><br><span class="line">if os.path.exists(data_feat_url):</span><br><span class="line">    data_feat = pd.read_hdf(data_feat_url, &apos;w&apos;)</span><br><span class="line">else:</span><br><span class="line">    for i in tqdm(range(days)):</span><br><span class="line">        data_feat.append(make_feat(date_add_days(start_date, i*(-1))))</span><br><span class="line">    data_feat = pd.concat(data_feat,axis=0)</span><br><span class="line">    data_feat.to_hdf(data_feat_url, &apos;w&apos;, complib=&apos;blosc&apos;, complevel=5)</span><br><span class="line"></span><br><span class="line">train_feat = data_feat[data_feat[&apos;time&apos;]&lt;&apos;2018-04-10 00:00:00&apos;]</span><br><span class="line">eval_feat = data_feat[data_feat[&apos;time&apos;]&gt;=&apos;2018-04-10 00:00:00&apos;]</span><br><span class="line"></span><br><span class="line"># weather_columns = []</span><br><span class="line"># for i in [&apos;&apos;,&apos;&apos;,&apos;&apos;,&apos;&apos;,&apos;&apos;,&apos;&apos;]:</span><br><span class="line"></span><br><span class="line">predictors = [c for c in train_feat.columns if c not in ([&apos;station_id&apos;, &apos;time&apos;,&apos;date&apos;, &apos;PM2.5&apos;, &apos;PM10&apos;, &apos;O3&apos;,&apos;city&apos;,&apos;duoyun&apos;, &apos;yangsha&apos;, &apos;qing&apos;, &apos;fuchen&apos;, &apos;yin&apos;, &apos;zhenyu&apos;, &apos;zhenxue&apos;,</span><br><span class="line">       &apos;yujiaxue&apos;, &apos;wu&apos;, &apos;mai&apos;])]</span><br><span class="line">params = &#123;</span><br><span class="line">    &apos;learning_rate&apos;: 0.01,</span><br><span class="line">    &apos;boosting_type&apos;: &apos;gbdt&apos;,</span><br><span class="line">    # &apos;objective&apos;: &apos;regression&apos;,</span><br><span class="line">    &apos;application&apos;: &apos;mape&apos;,</span><br><span class="line">    &apos;metric&apos;: &apos;map&apos;,</span><br><span class="line">    &apos;sub_feature&apos;: 0.7,</span><br><span class="line">    &apos;num_leaves&apos;: 60,</span><br><span class="line">    &apos;min_data&apos;: 100,</span><br><span class="line">    &apos;min_hessian&apos;: 1,</span><br><span class="line">    &apos;verbose&apos;: -1,</span><br><span class="line">&#125;</span><br><span class="line">model_dict = &#123;&#125;</span><br><span class="line">def f1(x): return np.log(x+1)</span><br><span class="line">def f2(x): return np.log(x+1)</span><br><span class="line">def f3(x): return np.log(x+100)</span><br><span class="line">def f4(x): return np.exp(x)-1</span><br><span class="line">def f5(x): return np.exp(x)-1</span><br><span class="line">def f6(x): return np.exp(x)-100</span><br><span class="line">encode = &#123;&apos;PM2.5&apos;:f1,&apos;PM10&apos;:f2,&apos;O3&apos;:f3&#125;</span><br><span class="line">decode = &#123;&apos;PM2.5&apos;:f4,&apos;PM10&apos;:f5,&apos;O3&apos;:f6&#125;</span><br><span class="line">for label in [&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]:</span><br><span class="line">    lgb_train = lgb.Dataset(train_feat[train_feat[label] &gt; 0][predictors],encode[label](train_feat[train_feat[label] &gt; 0][label]))</span><br><span class="line">    lgb_eval = lgb.Dataset(eval_feat[eval_feat[label] &gt; 0][predictors], encode[label](eval_feat[eval_feat[label] &gt; 0][label]))</span><br><span class="line"></span><br><span class="line">    gbm = lgb.train(params,</span><br><span class="line">                    lgb_train,</span><br><span class="line">                    num_boost_round=5000,</span><br><span class="line">                    valid_sets=lgb_eval,</span><br><span class="line">                    verbose_eval = 100,</span><br><span class="line">                    early_stopping_rounds = 100)</span><br><span class="line">    feat_imp = pd.Series(gbm.feature_importance(), index=predictors).sort_values(ascending=False)</span><br><span class="line">    model_dict[label] = gbm</span><br><span class="line"></span><br><span class="line">pickle.dump((model_dict,predictors),open(data_path+&apos;lightgbm_weather_best_eval.model&apos;,&apos;wb+&apos;))</span><br><span class="line">model_dict,predictors = pickle.load(open(data_path+&apos;lightgbm_weather_best_eval.model&apos;, &apos;rb+&apos;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(&apos;生成测试集&apos;)</span><br><span class="line">def get_test_feat(date):</span><br><span class="line">    test_feat = make_feat(date_add_days(date[:10],1),replace=True)</span><br><span class="line">    test_feat = pd.concat([train_feat[:0],test_feat])</span><br><span class="line">    return test_feat</span><br><span class="line"></span><br><span class="line">print(&apos;生成预测结果&apos;)</span><br><span class="line">def get_submission(test_feat,model_dict,decode):</span><br><span class="line">    for label in [&apos;PM2.5&apos;, &apos;PM10&apos;, &apos;O3&apos;]:</span><br><span class="line">        pred = model_dict[label].predict(test_feat[predictors])</span><br><span class="line">        test_feat[label] = decode[label](pred)</span><br><span class="line">    test_feat[&apos;test_id&apos;] = test_feat[&apos;station_id&apos;].apply(lambda x: x if len(x)&lt;11 else x[:10])</span><br><span class="line">    test_feat[&apos;test_id&apos;] = list(map(lambda x,y: y if x==0 else y+&apos;_aq&apos;, test_feat[&apos;city&apos;],test_feat[&apos;test_id&apos;]))</span><br><span class="line">    test_feat[&apos;test_id&apos;] = test_feat[&apos;test_id&apos;] + &apos;#&apos; + test_feat[&apos;diff_of_hour&apos;].astype(int).astype(str)</span><br><span class="line">    submission = pd.read_csv(data_path + &apos;sample_submissioin.csv&apos;)</span><br><span class="line">    submission = submission[[&apos;test_id&apos;]].merge(test_feat[[&apos;test_id&apos;,&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]],on=&apos;test_id&apos;,how=&apos;left&apos;)</span><br><span class="line">    if (submission[[&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]]&lt;0).sum().sum()&gt;0:</span><br><span class="line">        print(&apos;存在负数，请检查！！！&apos;)</span><br><span class="line">    return submission</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hours = 1</span><br><span class="line">utc_date = date_add_hours(datetime.datetime.now().strftime(&apos;%Y-%m-%d %H:%M:%S&apos;),-8)</span><br><span class="line">print(&apos;现在是UTC时间：&#123;&#125;&apos;.format(utc_date))</span><br><span class="line">print(&apos;距离待预测时间还有&#123;&#125;个小时&apos;.format(diff_of_hours(date_add_days(utc_date,1),utc_date)+1))</span><br><span class="line"></span><br><span class="line">test_feat = get_test_feat(utc_date)</span><br><span class="line">submission = get_submission(test_feat,model_dict, decode)</span><br><span class="line"></span><br><span class="line">sub_url = r&apos;../submission/sub&#123;&#125;.csv&apos;.format(datetime.datetime.now().strftime(&apos;%Y%m%d_%H%M%S&apos;))</span><br><span class="line">submission.to_csv(sub_url,index=False,  float_format=&apos;%.4f&apos;)</span><br><span class="line">print(submission[[&apos;PM2.5&apos;,&apos;PM10&apos;,&apos;O3&apos;]].mean())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import requests</span><br><span class="line">files=&#123;&apos;files&apos;: open(sub_url,&apos;rb&apos;)&#125;</span><br><span class="line">data = &#123;</span><br><span class="line">    &quot;user_id&quot;: &quot;piupiu&quot;,</span><br><span class="line">    &quot;team_token&quot;: &quot;739a5c2029a031c0d0709ba0b7d438968a458b783420c4179f1ee1b8e7380d08&quot;,</span><br><span class="line">    &quot;description&quot;: &apos;log1&apos;,</span><br><span class="line">    &quot;filename&quot;: sub_url.split(&apos;\\&apos;)[-1],</span><br><span class="line">&#125;</span><br><span class="line">url = &apos;https://biendata.com/competition/kdd_2018_submit/&apos;</span><br><span class="line">response = requests.post(url, files=files, data=data)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/机器学习/">机器学习</a>
  </div>

        
  <div class="tags">
    <a href="/tags/python/">python</a>
  </div>

        
  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a><a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a></div>
  <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div></div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据挖掘/">数据挖掘</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">25</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 12.5px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.75px;">Machine Learning 课程笔记</a> <a href="/tags/SQL/" style="font-size: 13.75px;">SQL</a> <a href="/tags/hexo/" style="font-size: 11.25px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.25px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.25px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 12.5px;">模型</a> <a href="/tags/爬虫/" style="font-size: 17.5px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.25px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2018 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>