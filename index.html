<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper">
    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-08-19T16:00:00.000Z"><a href="/34680/">2018-08-20</a></time>
        
  
    <h1 class="title"><a href="/34680/">提问的智慧</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#提问之前"><span class="toc-text">======== 提问之前 ========</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#怎样提问"><span class="toc-text">======== 怎样提问 ========</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#三思而后问"><span class="toc-text">======== 三思而后问 ========</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#好问题，坏问题"><span class="toc-text">======== 好问题，坏问题 ========</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#找不到答案怎么办"><span class="toc-text">======== 找不到答案怎么办 ========</span></a></li></ol>
    </div>

        <p>这里有一篇文章是关于“提问的智慧”（How To Ask Questions in The Smart Way），虽然文章的假设对象是黑客，但觉得帮助作用甚大，所以就从论坛搬过来了。。。在这里仅代表问题帮向热心为我们答疑解惑的各位致以最崇高的敬意，你们辛苦啦！</p>
<p><img src="https://i.imgur.com/Z2ttQsd.png" alt=""></p>
<p>内容如下：<br>   在黑客世界里，当提出一个技术问题时，你能得到怎样的回答？这取决于挖出答案的难度，同样取决于你提问的方法。本指南旨在帮助你提高发问技巧，以获取你最想要的答案。</p>
<p>   首先你必须明白，黑客们只偏爱艰巨的任务，或者能激发他们思维的好问题。如若不然，我们还来干吗？如果你有值得我们反复咀嚼玩味的好问题，我们自会对你感激不尽。好问题是激励，是厚礼，可以提高我们的理解力，而且通常会暴露我们以前从没意识到或者思考过的问题。对黑客而言，“问得好！”是发自内心的大力称赞。</p>
<p>   尽管黑客们有蔑视简单问题和不友善的坏名声，有时看起来似乎我们对新手，对知识贫乏者怀有敌意，但其实不是那样的。</p>
<p>   我们不想掩饰对这样一些人的蔑视–他们不愿思考，或者在发问前不去完成他们应该做的事。这种人只会谋杀时间–他们只愿索取，从不付出，无端消耗我们的时间，而我们本可以把时间用在更有趣的问题或者更值得回答的人身上。我们称这样的人为“失败者”（由于历史原因，我们有时把它拼作“lusers”）。</p>
<p>   我们在很大程度上属于志愿者，从繁忙的生活中抽出时间来解惑答疑，而且时常被提问淹没。所以我们无情的滤掉一些话题，特别是抛弃那些看起来像失败者的家伙，以便更高效的利用时间来回答胜利者的问题。<br>   如果你觉得我们过于傲慢的态度让你不爽，让你委屈，不妨设身处地想想。我们并没有要求你向我们屈服–事实上，我们中的大多数人最喜欢公平交易不过了，只要你付出小小努力来满足最起码的要求，我们就会欢迎你加入到我们的文化中来。但让我们帮助那些不愿意帮助自己的人是没有意义的。如果你不能接受这种“歧视”，我们建议你花点钱找家商业公司签个技术支持协议得了，别向黑客乞求帮助。</p>
<p>   如果你决定向我们求助，当然不希望被视为失败者，更不愿成为失败者中的一员。立刻得到有效答案的最好方法，就是像胜利者那样提问–聪明、自信、有解决问题的思路，只是偶尔在特定的问题上需要获得一点帮助。</p>
<h3 id="提问之前"><a href="#提问之前" class="headerlink" title="======== 提问之前 ========"></a>======== 提问之前 ========</h3><p>   在通过电邮、新闻组或者聊天室提出技术问题前，检查你有没有做到：</p>
<ol>
<li>通读手册，试着自己找答案。</li>
<li>在FAQ里找答案(一份维护得好的FAQ可以包罗万象)。</li>
<li>在网上搜索(个人推荐google~~~)。</li>
<li>向你身边精于此道的朋友打听。</li>
</ol>
<p>当你提出问题的时候，首先要说明在此之前你干了些什么；这将有助于树立你的形象：你不是一个妄图不劳而获的乞讨者，不愿浪费别人的时间。如果提问者能从答案中学到东西，我们更乐于回答他的问题。</p>
<p>   周全的思考，准备好你的问题，草率的发问只能得到草率的回答，或者根本得不到任何答案。越表现出在寻求帮助前为解决问题付出的努力，你越能得到实质性的帮助。</p>
<p>   小心别问错了问题。如果你的问题基于错误的假设，普通黑客(J. Random Hacker)通常会用无意义的字面解释来答复你，心里想着“蠢问题…”，希望着你会从问题的回答(而非你想得到的答案)中汲取教训。</p>
<p>   决不要自以为够资格得到答案，你没这种资格。毕竟你没有为这种服务支付任何报酬。你要自己去“挣”回一个答案，靠提出一个有内涵的，有趣的，有思维激励作用的问题–一个对社区的经验有潜在贡献的问题，而不仅仅是被动的从他人处索要知识–去挣到这个答案。<br>   另一方面，表明你愿意在找答案的过程中做点什么，是一个非常好的开端。“谁能给点提示？”、“我这个例子里缺了什么？”以及“我应该检查什么地方？”比“请把确切的过程贴出来”更容易得到答复。因为你显得只要有人指点正确的方向，你就有完成它的能力和决心。</p>
<h3 id="怎样提问"><a href="#怎样提问" class="headerlink" title="======== 怎样提问 ========"></a>======== 怎样提问 ========</h3><p>   ☆ 谨慎选择论坛版块<br>   小心选择提问的场合。如果象下面描述的那样，你很可能被忽略掉或者被看作失败者：</p>
<ol>
<li>在风马牛不相及的论坛贴出你的问题</li>
<li>在探讨高级技巧的论坛张贴非常初级的问题；反之亦然</li>
<li>在太多的不同新闻组交叉张贴<br>☆ 用辞贴切，语法正确，拼写无误</li>
</ol>
<p>我们从经验中发现，粗心的写作者通常也是马虎的思考者(我敢打包票)。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。</p>
<p>   正确的拼写，标点符号和大小写很重要。更一般的说，如果你的提问写得象个半文盲，你很有可能被忽视。</p>
<p>   如果你在使用非母语的论坛提问，你可以犯点拼写和语法上的小错–但决不能在思考上马虎(没错，我们能弄清两者的分别)<br>   ☆ 使用含义丰富，描述准确的标题</p>
<p>   在邮件列表或者新闻组中，大约50字以内的主题标题是抓住资深专家注意力的黄金时机。别用喋喋不休的“帮帮忙”(更别说“救命啊！！！！！”这样让人反感的话)来浪费这个机会。不要妄想用你的痛苦程度来打动我们， 别用空格代替问题的描述，哪怕是极其简短的描述。</p>
<p>   蠢问题： 救命啊！我的膝上机不能正常显示了！<br>   聪明问题： XFree86 4.1下鼠标光标变形，FoowareMV1005的显示芯片。</p>
<p>   如果你在回复中提出问题，记得要修改内容标题，表明里面有一个问题。一个看起来象“Re：测试”或者“Re：新bug”的问题很难引起足够重视。另外，引用并删减前文的内容，给新来的读者留下线索。</p>
<p>   ☆ 精确描述，信息量大</p>
<ol>
<li>谨慎明确的描述症状。</li>
<li>提供问题发生的环境(机器配置、操作系统、应用程序以及别的什么)。</li>
<li>说明你在提问前是怎样去研究和理解这个问题的。</li>
<li>说明你在提问前采取了什么步骤去解决它。</li>
<li><p>罗列最近做过什么可能有影响的硬件、软件变更。<br>尽量想象一个黑客会怎样反问你，在提问的时候预先给他答案。</p>
<p>☆ 话不在多<br>你需要提供精确有效的信息。这并不是要求你简单的把成吨的出错代码或者数据完全转储摘录到你的提问中。如果你有庞大而复杂的测试条件，尽量把它剪裁得越小越好。<br>这样做的用处至少有三点。</p>
<p>第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加；<br>第二，简化问题使你得到有用答案的机会增加；<br>第三，在提炼你的bug报告的过程中，也许你自己就能找出问题所在或作出更正。</p>
<p>☆ 只说症状，不说猜想<br>告诉黑客们你认为问题是怎样引起的没什么帮助。(如果你的推断如此有效，还用向别人求助吗？)，因此要确信你原原本本告诉了他们问题的症状，不要加进你自己的理解和推论。让黑客们来诊断吧。<br>蠢问题： 我在内核编译中一次又一次遇到SIG11错误，我怀疑某条飞线搭在主板的走线上了， 这种情况应该怎样检查最好？<br>聪明问题： 我自制的一套K6/233系统，主板是FIC-PA2007(VIA Apollo VP2芯片组)，256MBCorsair PC133 SDRAM，在内核编译中频频产生SIG11错误，从开机20分钟以后就有这种情况，开机前20分钟内从没发生过。重启也没有用，但是关机一晚上就又能工作20分钟。所有内存都换过了，没有效果。相关部分的典型编译记录如下…。<br>☆ 按时间顺序列出症状</p>
<p>对找出问题最有帮助的线索，往往就是问题发生前的一系列操作，因此，你的说明应该包含操作步骤，以及电脑的反应，直到问题产生。<br>如果你的说明很长(超过四个段落)，在开头简述问题会有所帮助，接下来按时间顺序详述。这样黑客们就知道该在你的说明中找什么。<br>☆ 明白你想问什么</p>
<p>漫无边际的提问近乎无休无止的时间黑洞。最能给你有用答案的人也正是最忙的人(他们忙是因为要亲自完成大部分工作)。这样的人对无节制的时间黑洞不太感冒，因此也可以说他们对漫无边际的提问不大感冒。</p>
<p>如果你明确表述需要回答者做什么(提供建议，发送一段代码，检查你的补丁或是别的)，就最有可能得到有用的答案。这会定出一个时间和精力的上限，便于回答者集中精力来帮你，这很凑效。<br>要理解专家们生活的世界，要把专业技能想象为充裕的资源，而回复的时间则是贫乏的资源。解决你的问题需要的时间越少，越能从忙碌的专家口中掏出答案。</p>
<p>因此，优化问题的结构，尽量减少专家们解决它所需要的时间，会有很大的帮助–这通常和简化问题有所区别。因此，问“我想更好的理解X，能给点提示吗？”通常比问“你能解释一下X吗？”更好。如果你的代码不能工作，问问它有什么地方不对，比要求别人替你修改要明智得多。</p>
<p>☆ 别问应该自己解决的问题<br>黑客们总是善于分辨哪些问题应该由你自己解决；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由你来搞定，你会从中学到东西。</p>
<p>你可以要求给点提示，但别要求得到完整的解决方案。</p>
<p>☆ 去除无意义的疑问<br>别用无意义的话结束提问，例如“有人能帮我吗？”或者“有答案吗？”。</p>
<p>首先：如果你对问题的描述不很合适，这样问更是画蛇添足。其次：由于这样问是画蛇添足，黑客们会很厌烦你–而且通常会用逻辑上正确的回答来表示他们的蔑视，例如：“没错，有人能帮你”或者“不，没答案”。</p>
<p>☆ 谦逊绝没有害处，而且常帮大忙<br>彬彬有礼，多用“请”和“先道个谢了”。让大家都知道你对他们花费时间义务提供帮助心存感激。</p>
<p>然而，如果你有很多问题无法解决，礼貌将会增加你得到有用答案的机会。(我们注意到，自从本指南发布后，从资深黑客处得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些黑客觉得“先谢了”的言外之意是过后就不会再感谢任何人了。我们的建议是：都道谢。)</p>
<p>☆ 问题解决后，加个简短说明<br>问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个补充说明。</p>
<p>补充说明不必很长或是很深入；简单的一句“你好，原来是网线出了问题！谢谢大家–Bill”比什么也不说要强。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇学术论文更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。<br>除了表示礼貌和反馈信息以外，这种补充有助于他人在邮件列表/新闻组/论坛中搜索对你有过帮助的完整解决方案，这可能对他们也很有用。</p>
<p>最后(至少？)，这种补充有助于所有提供过帮助的人从中得到满足感。</p>
<p>如果你自己不是老手或者黑客，那就相信我们，这种感觉对于那些你向他们求助的导师或者专家而言，是非常重要的。问题久拖未决会让人灰心；黑客们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次贴出新问题时尝到甜头。</p>
<p>☆ 还是不懂<br>如果你不是很理解答案，别立刻要求对方解释。象你以前试着自己解决问题时那样(利用手册，FAQ，网络，身边的高手)，去理解它。如果你真的需要对方解释，记得表现出你已经学到了点什么。<br>比方说，如果我回答你：“看来似乎是zEntry被阻塞了；你应该先清除它。”，然后：一个很糟的后续问题：“zEntry是什么？”<br>聪明的问法应该是这样：“哦~~~我看过帮助了但是只有-z和-p两个参数中提到了zEntry而且还都没有清楚的解释:&lt;你是指这两个中的哪一个吗？还是我看漏了什么？”</p>
</li>
</ol>
<h3 id="三思而后问"><a href="#三思而后问" class="headerlink" title="======== 三思而后问 ========"></a>======== 三思而后问 ========</h3><p>   以下是几个经典蠢问题，以及黑客在拒绝回答时的心中所想：<br>   问题：我能在哪找到X程序？<br>   问题：我的程序/配置/SQL申明没有用<br>   问题：我的Windows有问题，你能帮我吗？<br>   问题：我在安装Linux(或者X)时有问题，你能帮我吗？<br>   问题：我怎么才能破解root帐号/窃取OP特权/读别人的邮件呢？<br>   提问：我能在哪找到X程序？ 回答：就在我找到它的地方啊蠢货–搜索引擎的那一头。天呐！还有人不会用Google吗？<br>   提问：我的程序(配置、SQL申明)没有用回答：这不算是问题吧，我对找出你的真正问题没兴趣–如果要我问你二十个问题才找得出来的话–我有更有意思的事要做呢。</p>
<p>   在看到这类问题的时候，我的反应通常不外如下三种：</p>
<ol>
<li>你还有什么要补充的吗？</li>
<li>真糟糕，希望你能搞定。</li>
<li>这跟我有什么鸟相关？</li>
</ol>
<p>提问：我的Windows有问题，你能帮我吗？ 回答：能啊，扔掉萎软的垃圾，换Linux吧。<br>   提问：我在安装Linux(或者X)时有问题，你能帮我吗？回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的Linux用户组寻求手把手的指导吧(你能在这儿找到用户组的清单)。<br>   提问：我怎么才能破解root帐号/窃取OP特权/读别人的邮件呢？回答：想要这样做，说明你是个卑鄙小人；想找个黑客帮你，说明你是个白痴！</p>
<h3 id="好问题，坏问题"><a href="#好问题，坏问题" class="headerlink" title="======== 好问题，坏问题 ========"></a>======== 好问题，坏问题 ========</h3><p>   最后，我举一些例子来说明，怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。<br>   蠢问题：我可以在哪儿找到关于Foonly Flurbamatic的资料？<br>这种问法无非想得到“STFW”这样的回答。</p>
<p>   聪明问题：我用Google搜索过“FoonlyFlurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？<br>   这个问题已经STFW过了，看起来他真的遇到了麻烦。</p>
<p>蠢问题：我从FOO项目找来的源码没法编译。它怎么这么烂？<br>   他觉得都是别人的错，这个傲慢自大的家伙</p>
<p>聪明问题：FOO项目代码在Nulix 6.2版下无法编译通过。我读过了FAQ，但里面没有提到跟Nulix有关的问题。这是我编译过程的记录，我有什么做得不对的地方吗？<br>   他讲明了环境，也读过了FAQ，还指明了错误，并且他没有把问题的责任推到别人头上，这个家伙值得留意。</p>
<p>蠢问题：我的主板有问题了，谁来帮我？<br>   普通黑客对这类问题的回答通常是：“好的，还要帮你拍拍背和换尿布吗？”，然后按下删除键。</p>
<p>聪明问题：我在S2464主板上试过了X、Y和Z，但没什么作用，我又试了A、B和C。请注意当我尝试C时的奇怪现象。显然边带传输中出现了收缩，但结果出人意料。在多处理器主板上引起边带泄漏的通常原因是什么？谁有好主意接下来我该做些什么测试才能找出问题？<br>   这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。</p>
<p>在最后一个问题中，注意“告诉我答案”和“给我启示，指出我还应该做什么诊断工作”之间微妙而又重要的区别。<br>   事实上，后一个问题源自于2001年8月在Linux内核邮件列表上的一个真实的提问。我(Eric)就是那个提出问题的人。我在Tyan S2464主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决那一问题的重要信息。</p>
<p> 通过我的提问方法，我给了大家值得玩味的东西；我让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，邀请他们与我共同探讨。我告诉他们我所走过的弯路，以避免他们再浪费时间，这是一种对他人时间价值的尊重。</p>
<p>后来，当我向每个人表示感谢，并且赞赏这套程序(指邮件列表中的讨论–译者注)运作得非常出色的时候，一个Linux内核邮件列表(lkml)成员表示，问题得到解决并非由于我是这个列表中的“名人”，而是因为我用了正确的方式来提问。</p>
<p>我们黑客从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我象个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，给编写这个指南的人一些指导。</p>
<h3 id="找不到答案怎么办"><a href="#找不到答案怎么办" class="headerlink" title="======== 找不到答案怎么办 ========"></a>======== 找不到答案怎么办 ========</h3><p>   如果仍得不到答案，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。</p>
<p>   总的说来，简单的重复张贴问题是个很糟的想法。这将被视为无意义的喧闹。你可以通过其它渠道获得帮助，这些渠道通常更适合初学者的需要。有许多网上的以及本地的用户组，由狂热的软件爱好者(即使他们可能从没亲自写过任何软件)组成。通常人们组建这样的团体来互相帮助并帮助新手。</p>
<p>另外，你可以向很多商业公司寻求帮助，不论公司大还是小(RedHat和LinuxCare就是两个最常见的例子)。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了–完全可能如此–你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。</p>
<p>对大众化的软件，就象Linux之类而言，每个开发者至少会有上万名用户。根本不可能由一个人来处理来自上万名用户的求助电话。要知道，即使你要为帮助付费，同你必须购买同类软件相比，你所付出的也是微不足道的(通常封闭源代码软件的技术支持费用比开放源代码软件要高得多，且内容也不那么丰富)。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-07-31T16:00:00.000Z"><a href="/19544/">2018-08-01</a></time>
        
  
    <h1 class="title"><a href="/19544/">Python爬虫代码———拉勾数据分析师岗位数据分析</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">fi = &apos;F:\cs\python\code\lagou_dataanalysis_craping\lagou3.0.txt&apos;</span><br><span class="line"></span><br><span class="line">#read_csv()表示读取csv格式文件，&apos;gb2312&apos;表示csv文件格式的编码</span><br><span class="line"></span><br><span class="line">df = pd.read_table(fi,  encoding=&apos;gbk&apos;)</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line">df = df.iloc[:,0].str.split(&apos;@@@&apos;, expand=True)</span><br><span class="line">df.columns = [&apos;city&apos;,&apos;companyFullName&apos;,&apos;companyId&apos;,&apos;companyLabelList&apos;,&apos;companyShortName&apos;,&apos;companySize&apos;,&apos;businessZones&apos;,&apos;firstType&apos;,&apos;secondType&apos;,&apos;education&apos;,&apos;industryField&apos;,&apos;positionId&apos;,&apos;positionAdvantage&apos;,&apos;positionName&apos;,&apos;positionLables&apos;,&apos;salary&apos;,&apos;workYear&apos;]</span><br><span class="line">#df = pd.DataFrame(df)</span><br><span class="line">#读取前五行</span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df_duplicates=df.drop_duplicates(subset=&apos;positionId&apos;,keep=&apos;first&apos;)#keep=&apos;first&apos;表示保留第一个，删除后面的重复值；keep=&apos;last&apos;表示保留最后一个，删除前面的重复值</span><br><span class="line">def cut_word(word,method):</span><br><span class="line">    position=word.find(&apos;-&apos;)       #查找“7k-8k”这种形式&quot;-&quot;的位置</span><br><span class="line">    length=len(word)         </span><br><span class="line">    if position !=-1:       # &quot;-1&quot; 是False的意思，表示字符串中存在&apos;-&apos;</span><br><span class="line">        bottomsalary=word[:position-1]</span><br><span class="line">        topsalary=word[position+1:length-1]</span><br><span class="line">    else:</span><br><span class="line">        bottomsalary=word[:word.upper().find(&apos;K&apos;)]    #这里是指不存在&apos;10k-15k&apos;这种形式，数据中存在7k以上，k有的大写有的小写</span><br><span class="line">        topsalary=bottomsalary</span><br><span class="line">    if method==&quot;bottom&quot;:        #获得工资下限</span><br><span class="line">        return bottomsalary</span><br><span class="line">    else:</span><br><span class="line">        return topsalary          #获得工资的上限</span><br><span class="line">df_duplicates[&apos;topsalary&apos;]=df_duplicates.salary.apply(cut_word,method=&quot;top&quot;)  # apply()函数形式：apply(func,*args,**kwargs)，*args相当于元组，**kwargs相当于字典</span><br><span class="line">df_duplicates[&quot;bottomsalary&quot;]=df_duplicates.salary.apply(cut_word,method=&quot;bottom&quot;)#apply()函数作用：用来间接的调用一个函数，并把参数传递给函数</span><br><span class="line">df_duplicates.bottomsalary.astype(&apos;int&apos;)# 字符串转为数值型</span><br><span class="line">df_duplicates.topsalary.astype(&apos;int&apos;)</span><br><span class="line">df_duplicates[&quot;avgsalary&quot;]=df_duplicates.apply(lambda x:(int(x.bottomsalary)+int(x.topsalary))/2,axis=1)  #lambda是一种函数，举例：lambda x:x+1,x是参数，x+1是表达式;axis=1表示作用于行</span><br><span class="line">df_duplicates</span><br><span class="line"></span><br><span class="line">#选出我们想要的内容进行后续分析</span><br><span class="line">#总体薪酬情况</span><br><span class="line">df_clean=df_duplicates[[&apos;city&apos;,&apos;companyShortName&apos;,&apos;companySize&apos;,&apos;education&apos;,&apos;positionName&apos;,&apos;positionLables&apos;,&apos;workYear&apos;,&apos;avgsalary&apos;,&apos;industryField&apos;]]</span><br><span class="line">import matplotlib.pyplot as plt       </span><br><span class="line">#matplotlib inline  #%matplotlib inline是jupyter自带的方式，允许图表在cell中输出。</span><br><span class="line">plt.style.use(&quot;ggplot&quot;)    #使用R语言中的ggplot2配色作为绘图风格，为好看</span><br><span class="line">from matplotlib.font_manager import FontProperties        #matplotlib.Font_manager 是一种字体管理工具</span><br><span class="line">zh_font = FontProperties(fname=&quot;C:\\WINDOWS\\Fonts\\simsun.ttc&quot;)#matplotlib.Font_manager.FontProperties(fname) 是指定一种字体，C:\\WINDOWS\\Fonts\\simsun.ttc 是字体路径，直接复制到电脑搜索，你看能不能找到</span><br><span class="line">fig=plt.figure(figsize=(8,5))        #关于绘图方面，文末放了一个链接，讲述的比较详细</span><br><span class="line">ax=plt.subplot(111)</span><br><span class="line">rect=ax.hist(df_duplicates[&quot;avgsalary&quot;],bins=30)</span><br><span class="line">ax.set_title(u&apos;薪酬分布&apos;,fontProperties=zh_font)</span><br><span class="line">ax.set_xlabel(u&apos;K/月&apos;,fontProperties=zh_font)     </span><br><span class="line">plt.xticks(range(5,100,5))     #xticks为x轴主刻度和次刻度设置颜色、大小、方向，以及标签大小。</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#不同城市薪酬分布情况</span><br><span class="line">ax=df_clean.boxplot(column=&apos;avgsalary&apos;,by=&apos;city&apos;,figsize=(9,7))</span><br><span class="line">for label in ax.get_xticklabels():</span><br><span class="line">    label.set_fontproperties(zh_font)</span><br><span class="line">    </span><br><span class="line">#不同学历的薪酬分布</span><br><span class="line">ax=df_clean.boxplot(column=&apos;avgsalary&apos;,by=&apos;education&apos;,figsize=(9,7))</span><br><span class="line">for label in ax.get_xticklabels():</span><br><span class="line">    label.set_fontproperties(zh_font)</span><br><span class="line"></span><br><span class="line">#招聘人数</span><br><span class="line">df_clean.groupby([&apos;city&apos;,&apos;education&apos;]).avgsalary.count().unstack()   #unstack()函数可进行行列转置，大家不妨去掉看下效果</span><br><span class="line"></span><br><span class="line">#北京上海工作经验不同薪酬分布情况</span><br><span class="line">df_bj_sh=df_clean[df_clean[&apos;city&apos;].isin([&apos;上海&apos;,&apos;北京&apos;])]</span><br><span class="line">ax=df_bj_sh.boxplot(column=&apos;avgsalary&apos;,by=[&apos;workYear&apos;,&apos;city&apos;],figsize=(19,6))</span><br><span class="line">for label_x in ax.get_xticklabels():</span><br><span class="line">    label_x.set_fontproperties(zh_font)</span><br><span class="line">    </span><br><span class="line">#北上广深对数据分析职位需求量</span><br><span class="line">def topN(df,n=5):</span><br><span class="line">    counts=df.value_counts()    #value_counts()统计所有非零元素的个数  </span><br><span class="line">    return counts.sort_values(ascending=False)[:n]    #sort_values()对数据进行排序，ascending是设置升序和降序</span><br><span class="line">df_bj_sh_gz_sz=df_clean[df_clean[&apos;city&apos;].isin([&apos;上海&apos;,&apos;北京&apos;,&apos;广州&apos;,&apos;深圳&apos;])]</span><br><span class="line">df_bj_sh_gz_sz.groupby(&apos;city&apos;).positionName.apply(topN)</span><br><span class="line"></span><br><span class="line">#公司所处行业领域词云图分析</span><br><span class="line">import re  #re模块提供了对正则表达式的支持</span><br><span class="line">import jieba as jb</span><br><span class="line">from wordcloud import WordCloud</span><br><span class="line">word_str = &apos;,&apos;.join(df_clean[&apos;industryField&apos;]) # 以&apos;,&apos;为分隔符，将所有的元素合并成一个新的字符串,注意：csv文件中，单元格之间有逗号。</span><br><span class="line">#对文本进行分词</span><br><span class="line">word_split = jb.cut(word_str) #精确模式</span><br><span class="line">#使用|作为分隔符</span><br><span class="line">word_split1 = &quot;|&quot;.join(word_split)</span><br><span class="line">pattern=re.compile(&quot;移动|互联网|其他|金融|企业|服务|电子商务|O2O|数据|服务|医疗健康|游戏|社交网络|招聘|生活服务|文化娱乐|旅游|广告营销|教育|硬件|信息安全&quot;)</span><br><span class="line">#匹配所有文本字符；pattern 我们可以理解为一个匹配模式，用re.compile()方法来获得这个模式</span><br><span class="line">word_w=pattern.findall(word_split1)   #搜索word_split1，以列表形式返回全部能匹配的子串</span><br><span class="line">word_s = str(word_w)</span><br><span class="line">my_wordcloud = WordCloud(font_path=&quot;C:\\WINDOWS\\Fonts\\simsun.ttc&quot;,width=900,height=400,background_color=&quot;white&quot;).generate(word_s)</span><br><span class="line">plt.imshow(my_wordcloud)</span><br><span class="line">plt.axis(&quot;off&quot;)    #取出坐标轴</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-17T16:00:00.000Z"><a href="/18671/">2018-06-18</a></time>
        
  
    <h1 class="title"><a href="/18671/">预测北京和伦敦两个城市的空气质量</a></h1>
  

    </header>

    <div class="entry">
      
        <p>源代码分享<br>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/18671/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-09T16:00:00.000Z"><a href="/54638/">2018-06-10</a></time>
        
  
    <h1 class="title"><a href="/54638/">机器学习数学基础(3)——概率论与数理统计</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><img src="https://i.imgur.com/uZxEGRS.jpg" alt=""></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-08T16:00:00.000Z"><a href="/16092/">2018-06-09</a></time>
        
  
    <h1 class="title"><a href="/16092/">机器学习数学基础(2)——线性代数</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><img src="https://i.imgur.com/RqAIyFu.jpg" alt=""></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-07T16:00:00.000Z"><a href="/11038/">2018-06-08</a></time>
        
  
    <h1 class="title"><a href="/11038/">机器学习数学基础(1)——高等数学</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><img src="https://i.imgur.com/9MPH6WS.jpg" alt=""></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-06T16:00:00.000Z"><a href="/31404/">2018-06-07</a></time>
        
  
    <h1 class="title"><a href="/31404/">机器学习数学基础(0)——目录</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><strong>高等数学</strong></p>
<p><strong>线性代数</strong><br>行列式<br>矩阵<br>向量<br>线性方程组<br>矩阵的特征值和特征向量<br>二次型</p>
<p><strong>概率论和数理统计</strong><br>随机事件和概率<br>随机变量及其概率分布<br>多维随机变量及其分布<br>随机变量的数字特征<br>数理统计的基本概念</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-05-06T16:00:00.000Z"><a href="/21048/">2018-05-07</a></time>
        
  
    <h1 class="title"><a href="/21048/">关于机器学习在大气科学的应用</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p>前阵子阅读了院里一位博士研究生师兄的一篇有关基于神经网络算法对北京近五年的常规探空数据进行自组织分类，并揭示出大气污染物在不同边界层结构下的演变规律和相关机制的文章<a href="https://www.atmos-chem-phys.net/18/6771/2018/" target="_blank" rel="noopener">《Self-organized classification of boundary layer meteorology and associated characteristics of air quality in Beijing》</a>，看完顿时心生膜拜之情；</p>
<p>然后恰巧也是那个时候吕教授在院群上也转发了一篇关于机器学习预测火势甚至天气的公众号文章<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODE1NDYyMA==&amp;mid=2653384819&amp;idx=2&amp;sn=523f27cb9442ab4af27137edd1280248&amp;chksm=bd1cc8608a6b4176d7cae939f794e082cf86b5bf0ac0deb53790f507f563f588b2148687957c&amp;mpshare=1&amp;scene=1&amp;srcid=0517RYcQWk5dWJCcqoI7jLCe#rd" target="_blank" rel="noopener">《机器学习成功解决“蝴蝶效应”！以后你终于可以相信天气预报了》</a>。</p>
<p>加之自己报名了一个<a href="https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;mid=2247487345&amp;idx=1&amp;sn=4acb8978a2d95f0a1926c0e07021bec3&amp;chksm=e89455fcdfe3dcea645499d9321177a99ea713ffe06fe4af9d18c8506dd285755be2a1640539&amp;mpshare=1&amp;scene=1&amp;srcid=04151pmRgGqnfZDpvBL9EKKk#rd" target="_blank" rel="noopener">“预测北京和伦敦两个城市的空气质量”的KDD Cup 2018</a>但是因为自己报名太晚，组队不成（其实更深层的是之前关于机器学习的内容已经忘得差不多了。。。）</p>
<p>如此的机缘巧合，感觉将机器学习应用于大气科学将前途无量。我自己也想在这一方向进行深入了解，接下来我会进行相关内容的学习。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-03-31T16:00:00.000Z"><a href="/5451/">2018-04-01</a></time>
        
  
    <h1 class="title"><a href="/5451/">统计推断(零) 章节简介</a></h1>
  

    </header>

    <div class="entry">
      
        <p>《统计推断(翻译版·原书第2版)》从概率论的基础开始，通过例子与习题的旁征博引，引进了大量近代统计处理的新技术和一些国内同类教材中不常见而又广为使用的分布。</p>
<p>其内容既包括工科概率入门、经典统计和现代统计的基础，又加进了不少近代统计中数据处理的实用方法和思想，例如：Bootstrap再抽样法、刀切(Jackkrlife)估计、EM算法、Logistic回归、稳健(Robest)回归、Markov链、Monte Carlo方法等。</p>
<p>它的统计内容与国内流行的教材相比，理论较深，模型较多，案例的涉及面要广，理论的应用面要丰富，统计思想的阐述与算法更为具体。</p>
<p>《统计推断(翻译版·原书第2版)》可作为工科、管理类学科专业本科生、研究生的教材或参考书，也可供教师、工程技术人员自学之用。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/5451/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-24T16:00:00.000Z"><a href="/40260/">2017-12-25</a></time>
        
  
    <h1 class="title"><a href="/40260/">机器学习预测房价代码</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br></pre></td><td class="code"><pre><span class="line">&apos;&apos;&apos;</span><br><span class="line">analysis</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#scaning data</span><br><span class="line">#train data:1460*81 </span><br><span class="line">#test data: 14559*80</span><br><span class="line"></span><br><span class="line">#transtype</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">#missing data processing</span><br><span class="line">#large in amount depose</span><br><span class="line">#little in amount avarage</span><br><span class="line">#middle of the missing data treat as one-hot</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line"></span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">types = all_df[missing.index].dtypes</span><br><span class="line"></span><br><span class="line">percent = (all_df[missing.index].isnull().sum()/all_df[missing.index].isnull().count()).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">missing_data = pd.concat([missing, percent,types], axis=1, keys=[&apos;Total&apos;, &apos;Percent&apos;,&apos;Types&apos;])</span><br><span class="line">missing_data.sort_values(&apos;Total&apos;,ascending=False,inplace=True)</span><br><span class="line">missing_data</span><br><span class="line"></span><br><span class="line">missing.plot.bar()</span><br><span class="line"></span><br><span class="line">#analysis</span><br><span class="line">#single var</span><br><span class="line">train_df.describe()[&apos;SalePrice&apos;]</span><br><span class="line"></span><br><span class="line">#skewness and kurtosis</span><br><span class="line">print(&quot;Skewness: %f&quot; % train_df[&apos;SalePrice&apos;].skew())</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % train_df[&apos;SalePrice&apos;].kurt())</span><br><span class="line"></span><br><span class="line">#conrver</span><br><span class="line">corrmat = train_df.corr()</span><br><span class="line"></span><br><span class="line">#saleprice correlation matrix</span><br><span class="line">k = 10 #number of variables for heatmap</span><br><span class="line">cols = corrmat.nlargest(k, &apos;SalePrice&apos;)[&apos;SalePrice&apos;].index</span><br><span class="line">cm = np.corrcoef(train_df[cols].values.T)</span><br><span class="line">sns.set(font_scale=1.25)</span><br><span class="line">hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&apos;.2f&apos;, annot_kws=&#123;&apos;size&apos;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">## both corr and missing</span><br><span class="line">missing_data.index.intersection(cols)</span><br><span class="line"></span><br><span class="line">missing_data.loc[missing_data.index.intersection(cols)]</span><br><span class="line"></span><br><span class="line">#dealing with missing data</span><br><span class="line">all_df = all_df.drop((missing_data[missing_data[&apos;Total&apos;] &gt; 1]).index,1)</span><br><span class="line"># df_train = df_train.drop(df_train.loc[df_train[&apos;Electrical&apos;].isnull()].index)</span><br><span class="line">all_df.isnull().sum().max() #just checking that there&apos;s no missing data missing...</span><br><span class="line"># missing 1 replace with average</span><br><span class="line"></span><br><span class="line">#normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#log</span><br><span class="line">train_df[&apos;SalePrice&apos;] = np.log(train_df[&apos;SalePrice&apos;])</span><br><span class="line"></span><br><span class="line">#histogram and normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#observe every var</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">f = pd.melt(all_df, value_vars=quantitative)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False)</span><br><span class="line">g = g.map(sns.distplot, &quot;value&quot;)</span><br><span class="line"></span><br><span class="line">#LotArea,BsmtUnfSF,1stFlrSF,TotalBsmtSF,KitchenAbvGr can be improved by log</span><br><span class="line">#skewness</span><br><span class="line">all_df[quantitative].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">#quantity charctive analysis</span><br><span class="line">#Analysis of variance</span><br><span class="line">train = all_df.loc[train_df.index]</span><br><span class="line">train[&apos;SalePrice&apos;] = train_df.SalePrice</span><br><span class="line"></span><br><span class="line">def anova(frame):</span><br><span class="line">    anv = pd.DataFrame()</span><br><span class="line">    anv[&apos;feature&apos;] = qualitative</span><br><span class="line">    pvals = []</span><br><span class="line">    for c in qualitative:</span><br><span class="line">        samples = []</span><br><span class="line">        for cls in frame[c].unique():</span><br><span class="line">            s = frame[frame[c] == cls][&apos;SalePrice&apos;].values</span><br><span class="line">            samples.append(s)</span><br><span class="line">        pval = stats.f_oneway(*samples)[1]</span><br><span class="line">        pvals.append(pval)</span><br><span class="line">    anv[&apos;pval&apos;] = pvals</span><br><span class="line">    return anv.sort_values(&apos;pval&apos;)</span><br><span class="line"></span><br><span class="line">a = anova(train)</span><br><span class="line">a[&apos;disparity&apos;] = np.log(1./a[&apos;pval&apos;].values)</span><br><span class="line">sns.barplot(data=a, x=&apos;feature&apos;, y=&apos;disparity&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#quality charctive analysis</span><br><span class="line">def encode(frame, feature):</span><br><span class="line">    ordering = pd.DataFrame()</span><br><span class="line">    ordering[&apos;val&apos;] = frame[feature].unique()</span><br><span class="line">    ordering.index = ordering.val</span><br><span class="line">    ordering[&apos;spmean&apos;] = frame[[feature, &apos;SalePrice&apos;]].groupby(feature).mean()[&apos;SalePrice&apos;]</span><br><span class="line">    ordering = ordering.sort_values(&apos;spmean&apos;)</span><br><span class="line">    ordering[&apos;ordering&apos;] = range(1, ordering.shape[0]+1)</span><br><span class="line">    ordering = ordering[&apos;ordering&apos;].to_dict()</span><br><span class="line">    </span><br><span class="line">    for cat, o in ordering.items():</span><br><span class="line">        frame.loc[frame[feature] == cat, feature+&apos;_E&apos;] = o</span><br><span class="line">    </span><br><span class="line">qual_encoded = []</span><br><span class="line">for q in qualitative:  </span><br><span class="line">    encode(train, q)</span><br><span class="line">    qual_encoded.append(q+&apos;_E&apos;)</span><br><span class="line">print(qual_encoded)</span><br><span class="line"></span><br><span class="line"># choose raws of having missing data</span><br><span class="line">missing_data = all_df.isnull().sum()</span><br><span class="line">missing_data = missing_data[missing_data&gt;0]</span><br><span class="line">ids = all_df[missing_data.index].isnull()</span><br><span class="line"># index (0), columns (1)</span><br><span class="line">all_df.loc[ids[ids.any(axis=1)].index][missing_data.index]</span><br><span class="line"></span><br><span class="line"># nan still nan</span><br><span class="line">train.loc[1379,&apos;Electrical_E&apos;]</span><br><span class="line"></span><br><span class="line">#corr computing</span><br><span class="line">def spearman(frame, features):</span><br><span class="line">    spr = pd.DataFrame()</span><br><span class="line">    spr[&apos;feature&apos;] = features</span><br><span class="line">    #Signature: a.corr(other, method=&apos;pearson&apos;, min_periods=None)</span><br><span class="line">    #Docstring:</span><br><span class="line">    #Compute correlation with `other` Series, excluding missing values</span><br><span class="line">    # 计算特征和 SalePrice的 斯皮尔曼 相关系数</span><br><span class="line">    spr[&apos;spearman&apos;] = [frame[f].corr(frame[&apos;SalePrice&apos;], &apos;spearman&apos;) for f in features]</span><br><span class="line">    spr = spr.sort_values(&apos;spearman&apos;)</span><br><span class="line">    plt.figure(figsize=(6, 0.25*len(features))) # width, height</span><br><span class="line">    sns.barplot(data=spr, y=&apos;feature&apos;, x=&apos;spearman&apos;, orient=&apos;h&apos;)</span><br><span class="line">    </span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">spearman(train, features)</span><br><span class="line"># OverallQual Neighborhood GrLiveArea have bing influence on price</span><br><span class="line"></span><br><span class="line">#corr between vars</span><br><span class="line">plt.figure(1)</span><br><span class="line">corr = train[quantitative+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(2)</span><br><span class="line">corr = train[qual_encoded+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(3)</span><br><span class="line"># [31,27]</span><br><span class="line">corr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded)+1]), index=quantitative+[&apos;SalePrice&apos;], columns=qual_encoded+[&apos;SalePrice&apos;])</span><br><span class="line">for q1 in quantitative+[&apos;SalePrice&apos;]:</span><br><span class="line">    for q2 in qual_encoded+[&apos;SalePrice&apos;]:</span><br><span class="line">        corr.loc[q1, q2] = train[q1].corr(train[q2])</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line"></span><br><span class="line">#Pairplots</span><br><span class="line">def pairplot(x, y, **kwargs):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ts = pd.DataFrame(&#123;&apos;time&apos;: x, &apos;val&apos;: y&#125;)</span><br><span class="line">    ts = ts.groupby(&apos;time&apos;).mean()</span><br><span class="line">    ts.plot(ax=ax)</span><br><span class="line">    plt.xticks(rotation=90)</span><br><span class="line">    </span><br><span class="line">f = pd.melt(train, id_vars=[&apos;SalePrice&apos;], value_vars=quantitative+qual_encoded)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False, size=5)</span><br><span class="line">g = g.map(pairplot, &quot;value&quot;, &quot;SalePrice&quot;)</span><br><span class="line"></span><br><span class="line">#price departing</span><br><span class="line">a = train[&apos;SalePrice&apos;]</span><br><span class="line">a.plot.hist()</span><br><span class="line"></span><br><span class="line">features = quantitative</span><br><span class="line"></span><br><span class="line">standard = train[train[&apos;SalePrice&apos;] &lt; np.log(200000)]</span><br><span class="line">pricey = train[train[&apos;SalePrice&apos;] &gt;= np.log(200000)]</span><br><span class="line"></span><br><span class="line">diff = pd.DataFrame()</span><br><span class="line">diff[&apos;feature&apos;] = features</span><br><span class="line">diff[&apos;difference&apos;] = [(pricey[f].fillna(0.).mean() - standard[f].fillna(0.).mean())/(standard[f].fillna(0.).mean())</span><br><span class="line">                      for f in features]</span><br><span class="line"></span><br><span class="line">sns.barplot(data=diff, x=&apos;feature&apos;, y=&apos;difference&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#classfing</span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">model = TSNE(n_components=2, random_state=0, perplexity=50)</span><br><span class="line">X = train[features].fillna(0.).values</span><br><span class="line">tsne = model.fit_transform(X)</span><br><span class="line"></span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line">pca = PCA(n_components=30)</span><br><span class="line">pca.fit(s)</span><br><span class="line">pc = pca.transform(s)</span><br><span class="line">kmeans = KMeans(n_clusters=5)</span><br><span class="line">kmeans.fit(pc)</span><br><span class="line"></span><br><span class="line">fr = pd.DataFrame(&#123;&apos;tsne1&apos;: tsne[:,0], &apos;tsne2&apos;: tsne[:, 1], &apos;cluster&apos;: kmeans.labels_&#125;)</span><br><span class="line">sns.lmplot(data=fr, x=&apos;tsne1&apos;, y=&apos;tsne2&apos;, hue=&apos;cluster&apos;, fit_reg=False)</span><br><span class="line">print(np.sum(pca.explained_variance_ratio_))</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">model</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#feature engineering</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#dealing missing data</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">#missing 1 replaced with average</span><br><span class="line">all_df = all_df.drop(missing[missing&gt;1].index,1)</span><br><span class="line"></span><br><span class="line">all_df.isnull().sum()[all_df.isnull().sum()&gt;0]</span><br><span class="line"></span><br><span class="line">#dealing log(GrLivArea、1stFlrSF、2ndFlrSF、TotalBsmtSF、LotArea、KitchenAbvGr、GarageArea )</span><br><span class="line">logfeatures = [&apos;GrLivArea&apos;,&apos;1stFlrSF&apos;,&apos;2ndFlrSF&apos;,&apos;TotalBsmtSF&apos;,&apos;LotArea&apos;,&apos;KitchenAbvGr&apos;,&apos;GarageArea&apos;]</span><br><span class="line"></span><br><span class="line">for logfeature in logfeatures:</span><br><span class="line">    all_df[logfeature] = np.log1p(all_df[logfeature].values)</span><br><span class="line"></span><br><span class="line">#dealing boolean var</span><br><span class="line">all_df[&apos;HasBasement&apos;] = all_df[&apos;TotalBsmtSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasGarage&apos;] = all_df[&apos;GarageArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;Has2ndFloor&apos;] = all_df[&apos;2ndFlrSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasWoodDeck&apos;] = all_df[&apos;WoodDeckSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPorch&apos;] = all_df[&apos;OpenPorchSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPool&apos;] = all_df[&apos;PoolArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;IsNew&apos;] = all_df[&apos;YearBuilt&apos;].apply(lambda x: 1 if x &gt; 2000 else 0)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#encode quanlity</span><br><span class="line">all_dummy_df = pd.get_dummies(all_df)</span><br><span class="line"></span><br><span class="line">#standize var</span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">mean_cols = all_dummy_df.mean()</span><br><span class="line">all_dummy_df = all_dummy_df.fillna(mean_cols)</span><br><span class="line"></span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">X = all_dummy_df[quantitative]</span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line"></span><br><span class="line">all_dummy_df[quantitative] = s</span><br><span class="line"></span><br><span class="line">dummy_train_df = all_dummy_df.loc[train_df.index]</span><br><span class="line">dummy_test_df = all_dummy_df.loc[test_df.index]</span><br><span class="line"></span><br><span class="line">y_train = np.log(train_df.SalePrice)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#model predicting</span><br><span class="line">#ridge regression</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">y_train.values</span><br><span class="line"></span><br><span class="line">def rmse_cv(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, dummy_train_df, y_train.values, scoring=&quot;neg_mean_squared_error&quot;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line">alphas = np.logspace(-3, 2, 50)</span><br><span class="line">cv_ridge = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Ridge(alpha = alpha)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_ridge.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">cv_ridge = pd.Series(cv_ridge, index = alphas)</span><br><span class="line">cv_ridge.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;)</span><br><span class="line"></span><br><span class="line">#ridge trace picture</span><br><span class="line"># matplotlib.rcParams[&apos;figure.figsize&apos;] = (12.0, 12.0)</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line"># ax.set_color_cycle([&apos;b&apos;, &apos;r&apos;, &apos;g&apos;, &apos;c&apos;, &apos;k&apos;, &apos;y&apos;, &apos;m&apos;])</span><br><span class="line"></span><br><span class="line">ax.plot(alphas, coefs)</span><br><span class="line">ax.set_xscale(&apos;log&apos;)</span><br><span class="line">ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span><br><span class="line">plt.xlabel(&apos;alpha&apos;)</span><br><span class="line">plt.ylabel(&apos;weights&apos;)</span><br><span class="line">plt.title(&apos;Ridge coefficients as a function of the regularization&apos;)</span><br><span class="line">plt.axis(&apos;tight&apos;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#lesso :can choose some of feature</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line"></span><br><span class="line"># alphas = np.logspace(-3, 2, 50)</span><br><span class="line"># alphas = [1, 0.1, 0.001, 0.0005]</span><br><span class="line">alphas = np.logspace(-4, -2, 100)</span><br><span class="line">cv_lasso = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Lasso(alpha = alpha,max_iter=5000)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_lasso.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line"></span><br><span class="line">cv_lasso = pd.Series(cv_lasso, index = alphas)</span><br><span class="line">cv_lasso.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;</span><br><span class="line"></span><br><span class="line">print(cv_lasso.min(), cv_lasso.argmin())</span><br><span class="line"></span><br><span class="line">model = Lasso(alpha = 0.00058,max_iter=5000)</span><br><span class="line">model.fit(dummy_train_df,y_train)</span><br><span class="line">Lasso(alpha=0.00058, copy_X=True, fit_intercept=True, max_iter=5000,</span><br><span class="line">   normalize=False, positive=False, precompute=False, random_state=None,</span><br><span class="line">   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</span><br><span class="line">coef = pd.Series(model.coef_, index = dummy_train_df.columns)</span><br><span class="line">print(&quot;Lasso picked &quot; + str(sum(coef != 0)) + &quot; variables and eliminated the other &quot; +  str(sum(coef == 0)) + &quot; variables&quot;)</span><br><span class="line"></span><br><span class="line">imp_coef = pd.concat([coef.sort_values().head(10),</span><br><span class="line">                     coef.sort_values().tail(10)])</span><br><span class="line">matplotlib.rcParams[&apos;figure.figsize&apos;] = (8.0, 10.0)</span><br><span class="line">imp_coef.plot(kind = &quot;barh&quot;)</span><br><span class="line">plt.title(&quot;Coefficients in the Lasso Model&quot;)</span><br><span class="line"></span><br><span class="line">#Elastic Net :connect with lasso and ridge</span><br><span class="line"></span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=5000)</span><br><span class="line">elastic.fit(dummy_train_df, y_train)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=5000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line">rmse_cv(elastic).mean()</span><br><span class="line"></span><br><span class="line">#feature engineering 2 (another methon)</span><br><span class="line">import utils</span><br><span class="line">train_df_munged,label_df,test_df_munged = utils.feature_engineering()</span><br><span class="line"></span><br><span class="line">test_df = pd.read_csv(&apos;../input/test.csv&apos;)</span><br><span class="line">from sklearn.metrics import mean_squared_error,make_scorer</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"># 定义自己的score函数</span><br><span class="line">def my_custom_loss_func(ground_truth, predictions):</span><br><span class="line">    return np.sqrt(mean_squared_error(np.exp(ground_truth), np.exp(predictions)))</span><br><span class="line"></span><br><span class="line">my_loss_func  = make_scorer(my_custom_loss_func, greater_is_better=False)</span><br><span class="line">def rmse_cv2(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, train_df_munged, label_df.SalePrice, scoring=&apos;neg_mean_squared_error&apos;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line"></span><br><span class="line">#ridge2</span><br><span class="line">from sklearn.linear_model import RidgeCV,Ridge</span><br><span class="line">alphas = np.logspace(-3, 2, 100)</span><br><span class="line">model_ridge = RidgeCV(alphas=alphas).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_ridge = model_ridge.predict(train_df_munged)</span><br><span class="line">print(&quot;Ridge score on training set: &quot;, model_ridge.score(train_df_munged,label_df.SalePrice))</span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_ridge).mean())</span><br><span class="line"></span><br><span class="line">#lasso2</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line">model_lasso = LassoCV(eps=0.0001,max_iter=20000).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_lasso = model_lasso.predict(train_df_munged)</span><br><span class="line">print(&quot;Lasso score on training set: &quot;, model_lasso.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_lasso).mean())</span><br><span class="line"></span><br><span class="line">#Elastic Net</span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">model_elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=10000)</span><br><span class="line">model_elastic.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=10000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_elastic = model_elastic.predict(train_df_munged)</span><br><span class="line">print(&quot;Elastic score on training set: &quot;, model_elastic.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_elastic).mean())</span><br><span class="line"></span><br><span class="line">#XGBoost</span><br><span class="line"># XGBoost -- I did some &quot;manual&quot; cross-validation here but should really find</span><br><span class="line"># these hyperparameters using CV. ;-)</span><br><span class="line"></span><br><span class="line">import xgboost as xgb</span><br><span class="line"></span><br><span class="line">model_xgb = xgb.XGBRegressor(</span><br><span class="line">                 colsample_bytree=0.2,</span><br><span class="line">                 gamma=0.0,</span><br><span class="line">                 learning_rate=0.05,</span><br><span class="line">                 max_depth=6,</span><br><span class="line">                 min_child_weight=1.5,</span><br><span class="line">                 n_estimators=7200,                                                                  </span><br><span class="line">                 reg_alpha=0.9,</span><br><span class="line">                 reg_lambda=0.6,</span><br><span class="line">                 subsample=0.2,</span><br><span class="line">                 seed=42,</span><br><span class="line">                 silent=1)</span><br><span class="line"></span><br><span class="line">model_xgb.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"></span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_xgb = model_xgb.predict(train_df_munged)</span><br><span class="line">print(&quot;XGBoost score on training set: &quot;, model_xgb.score(train_df_munged,label_df.SalePrice)) # 过拟合</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_xgb).mean())</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(model_xgb.predict(train_df_munged),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#Ensemble</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"># Create linear regression object</span><br><span class="line">regr = LinearRegression()</span><br><span class="line">train_x = np.concatenate(</span><br><span class="line">    (pred_Y_lasso[np.newaxis, :].T,pred_Y_ridge[np.newaxis, :].T,</span><br><span class="line">     pred_Y_elastic[np.newaxis, :].T,pred_Y_xgb[np.newaxis, :].T), axis=1)</span><br><span class="line">regr.fit(train_x,label_df.SalePrice)</span><br><span class="line">LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</span><br><span class="line">regr.coef_</span><br><span class="line"></span><br><span class="line">print(&quot;Ensemble score on training set: &quot;, regr.score(train_x,label_df.SalePrice)) # overfitting</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(regr.predict(train_x),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#submit</span><br><span class="line">model_lasso.predict(test_df_munged)[np.newaxis, :].T</span><br><span class="line"></span><br><span class="line">test_x = np.concatenate(</span><br><span class="line">(model_lasso.predict(test_df_munged)[np.newaxis, :].T,model_ridge.predict(test_df_munged)[np.newaxis, :].T,</span><br><span class="line">                           model_elastic.predict(test_df_munged)[np.newaxis, :].T, model_xgb.predict(test_df_munged)[np.newaxis, :].T)</span><br><span class="line">        ,axis=1)</span><br><span class="line">y_final = regr.predict(test_x)</span><br><span class="line">y_final</span><br><span class="line"></span><br><span class="line">submission_df = pd.DataFrame(data= &#123;&apos;Id&apos; : test_df.Id, &apos;SalePrice&apos;: np.exp(y_final)&#125;)</span><br><span class="line">submission_df.to_csv(&quot;bag-4.csv&quot;,index=False) # conceal index</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>
 
<nav id="pagination">
  
  
    <a href="/page/2/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav>
</div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据挖掘/">数据挖掘</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">25</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 12.5px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.75px;">Machine Learning 课程笔记</a> <a href="/tags/SQL/" style="font-size: 13.75px;">SQL</a> <a href="/tags/hexo/" style="font-size: 11.25px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.25px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/提问/" style="font-size: 10px;">提问</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.25px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 12.5px;">模型</a> <a href="/tags/爬虫/" style="font-size: 17.5px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.25px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2020 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>