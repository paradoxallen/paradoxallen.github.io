<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper">
    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-07-31T16:00:00.000Z"><a href="/19544/">2018-08-01</a></time>
        
  
    <h1 class="title"><a href="/19544/">Python爬虫代码———拉勾数据分析师岗位数据分析</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">fi = &apos;F:\cs\python\code\lagou_dataanalysis_craping\lagou3.0.txt&apos;</span><br><span class="line"></span><br><span class="line">#read_csv()表示读取csv格式文件，&apos;gb2312&apos;表示csv文件格式的编码</span><br><span class="line"></span><br><span class="line">df = pd.read_table(fi,  encoding=&apos;gbk&apos;)</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line">df = df.iloc[:,0].str.split(&apos;@@@&apos;, expand=True)</span><br><span class="line">df.columns = [&apos;city&apos;,&apos;companyFullName&apos;,&apos;companyId&apos;,&apos;companyLabelList&apos;,&apos;companyShortName&apos;,&apos;companySize&apos;,&apos;businessZones&apos;,&apos;firstType&apos;,&apos;secondType&apos;,&apos;education&apos;,&apos;industryField&apos;,&apos;positionId&apos;,&apos;positionAdvantage&apos;,&apos;positionName&apos;,&apos;positionLables&apos;,&apos;salary&apos;,&apos;workYear&apos;]</span><br><span class="line">#df = pd.DataFrame(df)</span><br><span class="line">#读取前五行</span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df_duplicates=df.drop_duplicates(subset=&apos;positionId&apos;,keep=&apos;first&apos;)#keep=&apos;first&apos;表示保留第一个，删除后面的重复值；keep=&apos;last&apos;表示保留最后一个，删除前面的重复值</span><br><span class="line">def cut_word(word,method):</span><br><span class="line">    position=word.find(&apos;-&apos;)       #查找“7k-8k”这种形式&quot;-&quot;的位置</span><br><span class="line">    length=len(word)         </span><br><span class="line">    if position !=-1:       # &quot;-1&quot; 是False的意思，表示字符串中存在&apos;-&apos;</span><br><span class="line">        bottomsalary=word[:position-1]</span><br><span class="line">        topsalary=word[position+1:length-1]</span><br><span class="line">    else:</span><br><span class="line">        bottomsalary=word[:word.upper().find(&apos;K&apos;)]    #这里是指不存在&apos;10k-15k&apos;这种形式，数据中存在7k以上，k有的大写有的小写</span><br><span class="line">        topsalary=bottomsalary</span><br><span class="line">    if method==&quot;bottom&quot;:        #获得工资下限</span><br><span class="line">        return bottomsalary</span><br><span class="line">    else:</span><br><span class="line">        return topsalary          #获得工资的上限</span><br><span class="line">df_duplicates[&apos;topsalary&apos;]=df_duplicates.salary.apply(cut_word,method=&quot;top&quot;)  # apply()函数形式：apply(func,*args,**kwargs)，*args相当于元组，**kwargs相当于字典</span><br><span class="line">df_duplicates[&quot;bottomsalary&quot;]=df_duplicates.salary.apply(cut_word,method=&quot;bottom&quot;)#apply()函数作用：用来间接的调用一个函数，并把参数传递给函数</span><br><span class="line">df_duplicates.bottomsalary.astype(&apos;int&apos;)# 字符串转为数值型</span><br><span class="line">df_duplicates.topsalary.astype(&apos;int&apos;)</span><br><span class="line">df_duplicates[&quot;avgsalary&quot;]=df_duplicates.apply(lambda x:(int(x.bottomsalary)+int(x.topsalary))/2,axis=1)  #lambda是一种函数，举例：lambda x:x+1,x是参数，x+1是表达式;axis=1表示作用于行</span><br><span class="line">df_duplicates</span><br><span class="line"></span><br><span class="line">#选出我们想要的内容进行后续分析</span><br><span class="line">#总体薪酬情况</span><br><span class="line">df_clean=df_duplicates[[&apos;city&apos;,&apos;companyShortName&apos;,&apos;companySize&apos;,&apos;education&apos;,&apos;positionName&apos;,&apos;positionLables&apos;,&apos;workYear&apos;,&apos;avgsalary&apos;,&apos;industryField&apos;]]</span><br><span class="line">import matplotlib.pyplot as plt       </span><br><span class="line">#matplotlib inline  #%matplotlib inline是jupyter自带的方式，允许图表在cell中输出。</span><br><span class="line">plt.style.use(&quot;ggplot&quot;)    #使用R语言中的ggplot2配色作为绘图风格，为好看</span><br><span class="line">from matplotlib.font_manager import FontProperties        #matplotlib.Font_manager 是一种字体管理工具</span><br><span class="line">zh_font = FontProperties(fname=&quot;C:\\WINDOWS\\Fonts\\simsun.ttc&quot;)#matplotlib.Font_manager.FontProperties(fname) 是指定一种字体，C:\\WINDOWS\\Fonts\\simsun.ttc 是字体路径，直接复制到电脑搜索，你看能不能找到</span><br><span class="line">fig=plt.figure(figsize=(8,5))        #关于绘图方面，文末放了一个链接，讲述的比较详细</span><br><span class="line">ax=plt.subplot(111)</span><br><span class="line">rect=ax.hist(df_duplicates[&quot;avgsalary&quot;],bins=30)</span><br><span class="line">ax.set_title(u&apos;薪酬分布&apos;,fontProperties=zh_font)</span><br><span class="line">ax.set_xlabel(u&apos;K/月&apos;,fontProperties=zh_font)     </span><br><span class="line">plt.xticks(range(5,100,5))     #xticks为x轴主刻度和次刻度设置颜色、大小、方向，以及标签大小。</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#不同城市薪酬分布情况</span><br><span class="line">ax=df_clean.boxplot(column=&apos;avgsalary&apos;,by=&apos;city&apos;,figsize=(9,7))</span><br><span class="line">for label in ax.get_xticklabels():</span><br><span class="line">    label.set_fontproperties(zh_font)</span><br><span class="line">    </span><br><span class="line">#不同学历的薪酬分布</span><br><span class="line">ax=df_clean.boxplot(column=&apos;avgsalary&apos;,by=&apos;education&apos;,figsize=(9,7))</span><br><span class="line">for label in ax.get_xticklabels():</span><br><span class="line">    label.set_fontproperties(zh_font)</span><br><span class="line"></span><br><span class="line">#招聘人数</span><br><span class="line">df_clean.groupby([&apos;city&apos;,&apos;education&apos;]).avgsalary.count().unstack()   #unstack()函数可进行行列转置，大家不妨去掉看下效果</span><br><span class="line"></span><br><span class="line">#北京上海工作经验不同薪酬分布情况</span><br><span class="line">df_bj_sh=df_clean[df_clean[&apos;city&apos;].isin([&apos;上海&apos;,&apos;北京&apos;])]</span><br><span class="line">ax=df_bj_sh.boxplot(column=&apos;avgsalary&apos;,by=[&apos;workYear&apos;,&apos;city&apos;],figsize=(19,6))</span><br><span class="line">for label_x in ax.get_xticklabels():</span><br><span class="line">    label_x.set_fontproperties(zh_font)</span><br><span class="line">    </span><br><span class="line">#北上广深对数据分析职位需求量</span><br><span class="line">def topN(df,n=5):</span><br><span class="line">    counts=df.value_counts()    #value_counts()统计所有非零元素的个数  </span><br><span class="line">    return counts.sort_values(ascending=False)[:n]    #sort_values()对数据进行排序，ascending是设置升序和降序</span><br><span class="line">df_bj_sh_gz_sz=df_clean[df_clean[&apos;city&apos;].isin([&apos;上海&apos;,&apos;北京&apos;,&apos;广州&apos;,&apos;深圳&apos;])]</span><br><span class="line">df_bj_sh_gz_sz.groupby(&apos;city&apos;).positionName.apply(topN)</span><br><span class="line"></span><br><span class="line">#公司所处行业领域词云图分析</span><br><span class="line">import re  #re模块提供了对正则表达式的支持</span><br><span class="line">import jieba as jb</span><br><span class="line">from wordcloud import WordCloud</span><br><span class="line">word_str = &apos;,&apos;.join(df_clean[&apos;industryField&apos;]) # 以&apos;,&apos;为分隔符，将所有的元素合并成一个新的字符串,注意：csv文件中，单元格之间有逗号。</span><br><span class="line">#对文本进行分词</span><br><span class="line">word_split = jb.cut(word_str) #精确模式</span><br><span class="line">#使用|作为分隔符</span><br><span class="line">word_split1 = &quot;|&quot;.join(word_split)</span><br><span class="line">pattern=re.compile(&quot;移动|互联网|其他|金融|企业|服务|电子商务|O2O|数据|服务|医疗健康|游戏|社交网络|招聘|生活服务|文化娱乐|旅游|广告营销|教育|硬件|信息安全&quot;)</span><br><span class="line">#匹配所有文本字符；pattern 我们可以理解为一个匹配模式，用re.compile()方法来获得这个模式</span><br><span class="line">word_w=pattern.findall(word_split1)   #搜索word_split1，以列表形式返回全部能匹配的子串</span><br><span class="line">word_s = str(word_w)</span><br><span class="line">my_wordcloud = WordCloud(font_path=&quot;C:\\WINDOWS\\Fonts\\simsun.ttc&quot;,width=900,height=400,background_color=&quot;white&quot;).generate(word_s)</span><br><span class="line">plt.imshow(my_wordcloud)</span><br><span class="line">plt.axis(&quot;off&quot;)    #取出坐标轴</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-09T16:00:00.000Z"><a href="/54638/">2018-06-10</a></time>
        
  
    <h1 class="title"><a href="/54638/">机器学习数学基础(3)——概率论与数理统计</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><img src="https://i.imgur.com/uZxEGRS.jpg" alt=""></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-08T16:00:00.000Z"><a href="/16092/">2018-06-09</a></time>
        
  
    <h1 class="title"><a href="/16092/">机器学习数学基础(2)——线性代数</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><img src="https://i.imgur.com/RqAIyFu.jpg" alt=""></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-07T16:00:00.000Z"><a href="/11038/">2018-06-08</a></time>
        
  
    <h1 class="title"><a href="/11038/">机器学习数学基础(1)——高等数学</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><img src="https://i.imgur.com/9MPH6WS.jpg" alt=""></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-06-06T16:00:00.000Z"><a href="/31404/">2018-06-07</a></time>
        
  
    <h1 class="title"><a href="/31404/">机器学习数学基础(0)——目录</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p><strong>高等数学</strong></p>
<p><strong>线性代数</strong><br>行列式<br>矩阵<br>向量<br>线性方程组<br>矩阵的特征值和特征向量<br>二次型</p>
<p><strong>概率论和数理统计</strong><br>随机事件和概率<br>随机变量及其概率分布<br>多维随机变量及其分布<br>随机变量的数字特征<br>数理统计的基本概念</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-05-06T16:00:00.000Z"><a href="/21048/">2018-05-07</a></time>
        
  
    <h1 class="title"><a href="/21048/">关于机器学习在大气科学的应用</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <p>前阵子阅读了院里一位博士研究生师兄的一篇有关基于神经网络算法对北京近五年的常规探空数据进行自组织分类，并揭示出大气污染物在不同边界层结构下的演变规律和相关机制的文章<a href="https://www.atmos-chem-phys.net/18/6771/2018/" target="_blank" rel="noopener">《Self-organized classification of boundary layer meteorology and associated characteristics of air quality in Beijing》</a>，看完顿时心生膜拜之情；</p>
<p>然后恰巧也是那个时候吕教授在院群上也转发了一篇关于机器学习预测火势甚至天气的公众号文章<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODE1NDYyMA==&amp;mid=2653384819&amp;idx=2&amp;sn=523f27cb9442ab4af27137edd1280248&amp;chksm=bd1cc8608a6b4176d7cae939f794e082cf86b5bf0ac0deb53790f507f563f588b2148687957c&amp;mpshare=1&amp;scene=1&amp;srcid=0517RYcQWk5dWJCcqoI7jLCe#rd" target="_blank" rel="noopener">《机器学习成功解决“蝴蝶效应”！以后你终于可以相信天气预报了》</a>。</p>
<p>加之自己报名了一个<a href="https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;mid=2247487345&amp;idx=1&amp;sn=4acb8978a2d95f0a1926c0e07021bec3&amp;chksm=e89455fcdfe3dcea645499d9321177a99ea713ffe06fe4af9d18c8506dd285755be2a1640539&amp;mpshare=1&amp;scene=1&amp;srcid=04151pmRgGqnfZDpvBL9EKKk#rd" target="_blank" rel="noopener">“预测北京和伦敦两个城市的空气质量”的KDD Cup 2018</a>但是因为自己报名太晚，组队不成（其实更深层的是之前关于机器学习的内容已经忘得差不多了。。。）</p>
<p>如此的机缘巧合，感觉将机器学习应用于大气科学将前途无量。我自己也想在这一方向进行深入了解，接下来我会进行相关内容的学习。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2018-03-31T16:00:00.000Z"><a href="/5451/">2018-04-01</a></time>
        
  
    <h1 class="title"><a href="/5451/">统计推断(零) 章节简介</a></h1>
  

    </header>

    <div class="entry">
      
        <p>《统计推断(翻译版·原书第2版)》从概率论的基础开始，通过例子与习题的旁征博引，引进了大量近代统计处理的新技术和一些国内同类教材中不常见而又广为使用的分布。</p>
<p>其内容既包括工科概率入门、经典统计和现代统计的基础，又加进了不少近代统计中数据处理的实用方法和思想，例如：Bootstrap再抽样法、刀切(Jackkrlife)估计、EM算法、Logistic回归、稳健(Robest)回归、Markov链、Monte Carlo方法等。</p>
<p>它的统计内容与国内流行的教材相比，理论较深，模型较多，案例的涉及面要广，理论的应用面要丰富，统计思想的阐述与算法更为具体。</p>
<p>《统计推断(翻译版·原书第2版)》可作为工科、管理类学科专业本科生、研究生的教材或参考书，也可供教师、工程技术人员自学之用。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/5451/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-24T16:00:00.000Z"><a href="/40260/">2017-12-25</a></time>
        
  
    <h1 class="title"><a href="/40260/">机器学习预测房价代码</a></h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        
    </div>

        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br></pre></td><td class="code"><pre><span class="line">&apos;&apos;&apos;</span><br><span class="line">analysis</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#scaning data</span><br><span class="line">#train data:1460*81 </span><br><span class="line">#test data: 14559*80</span><br><span class="line"></span><br><span class="line">#transtype</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">#missing data processing</span><br><span class="line">#large in amount depose</span><br><span class="line">#little in amount avarage</span><br><span class="line">#middle of the missing data treat as one-hot</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line"></span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">types = all_df[missing.index].dtypes</span><br><span class="line"></span><br><span class="line">percent = (all_df[missing.index].isnull().sum()/all_df[missing.index].isnull().count()).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">missing_data = pd.concat([missing, percent,types], axis=1, keys=[&apos;Total&apos;, &apos;Percent&apos;,&apos;Types&apos;])</span><br><span class="line">missing_data.sort_values(&apos;Total&apos;,ascending=False,inplace=True)</span><br><span class="line">missing_data</span><br><span class="line"></span><br><span class="line">missing.plot.bar()</span><br><span class="line"></span><br><span class="line">#analysis</span><br><span class="line">#single var</span><br><span class="line">train_df.describe()[&apos;SalePrice&apos;]</span><br><span class="line"></span><br><span class="line">#skewness and kurtosis</span><br><span class="line">print(&quot;Skewness: %f&quot; % train_df[&apos;SalePrice&apos;].skew())</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % train_df[&apos;SalePrice&apos;].kurt())</span><br><span class="line"></span><br><span class="line">#conrver</span><br><span class="line">corrmat = train_df.corr()</span><br><span class="line"></span><br><span class="line">#saleprice correlation matrix</span><br><span class="line">k = 10 #number of variables for heatmap</span><br><span class="line">cols = corrmat.nlargest(k, &apos;SalePrice&apos;)[&apos;SalePrice&apos;].index</span><br><span class="line">cm = np.corrcoef(train_df[cols].values.T)</span><br><span class="line">sns.set(font_scale=1.25)</span><br><span class="line">hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&apos;.2f&apos;, annot_kws=&#123;&apos;size&apos;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">## both corr and missing</span><br><span class="line">missing_data.index.intersection(cols)</span><br><span class="line"></span><br><span class="line">missing_data.loc[missing_data.index.intersection(cols)]</span><br><span class="line"></span><br><span class="line">#dealing with missing data</span><br><span class="line">all_df = all_df.drop((missing_data[missing_data[&apos;Total&apos;] &gt; 1]).index,1)</span><br><span class="line"># df_train = df_train.drop(df_train.loc[df_train[&apos;Electrical&apos;].isnull()].index)</span><br><span class="line">all_df.isnull().sum().max() #just checking that there&apos;s no missing data missing...</span><br><span class="line"># missing 1 replace with average</span><br><span class="line"></span><br><span class="line">#normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#log</span><br><span class="line">train_df[&apos;SalePrice&apos;] = np.log(train_df[&apos;SalePrice&apos;])</span><br><span class="line"></span><br><span class="line">#histogram and normal probability plot</span><br><span class="line">sns.distplot(train_df[&apos;SalePrice&apos;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(train_df[&apos;SalePrice&apos;], plot=plt)</span><br><span class="line"></span><br><span class="line">#observe every var</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line">print(&quot;quantitative: &#123;&#125;, qualitative: &#123;&#125;&quot; .format (len(quantitative),len(qualitative)))</span><br><span class="line"></span><br><span class="line">f = pd.melt(all_df, value_vars=quantitative)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False)</span><br><span class="line">g = g.map(sns.distplot, &quot;value&quot;)</span><br><span class="line"></span><br><span class="line">#LotArea,BsmtUnfSF,1stFlrSF,TotalBsmtSF,KitchenAbvGr can be improved by log</span><br><span class="line">#skewness</span><br><span class="line">all_df[quantitative].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)</span><br><span class="line"></span><br><span class="line">#quantity charctive analysis</span><br><span class="line">#Analysis of variance</span><br><span class="line">train = all_df.loc[train_df.index]</span><br><span class="line">train[&apos;SalePrice&apos;] = train_df.SalePrice</span><br><span class="line"></span><br><span class="line">def anova(frame):</span><br><span class="line">    anv = pd.DataFrame()</span><br><span class="line">    anv[&apos;feature&apos;] = qualitative</span><br><span class="line">    pvals = []</span><br><span class="line">    for c in qualitative:</span><br><span class="line">        samples = []</span><br><span class="line">        for cls in frame[c].unique():</span><br><span class="line">            s = frame[frame[c] == cls][&apos;SalePrice&apos;].values</span><br><span class="line">            samples.append(s)</span><br><span class="line">        pval = stats.f_oneway(*samples)[1]</span><br><span class="line">        pvals.append(pval)</span><br><span class="line">    anv[&apos;pval&apos;] = pvals</span><br><span class="line">    return anv.sort_values(&apos;pval&apos;)</span><br><span class="line"></span><br><span class="line">a = anova(train)</span><br><span class="line">a[&apos;disparity&apos;] = np.log(1./a[&apos;pval&apos;].values)</span><br><span class="line">sns.barplot(data=a, x=&apos;feature&apos;, y=&apos;disparity&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#quality charctive analysis</span><br><span class="line">def encode(frame, feature):</span><br><span class="line">    ordering = pd.DataFrame()</span><br><span class="line">    ordering[&apos;val&apos;] = frame[feature].unique()</span><br><span class="line">    ordering.index = ordering.val</span><br><span class="line">    ordering[&apos;spmean&apos;] = frame[[feature, &apos;SalePrice&apos;]].groupby(feature).mean()[&apos;SalePrice&apos;]</span><br><span class="line">    ordering = ordering.sort_values(&apos;spmean&apos;)</span><br><span class="line">    ordering[&apos;ordering&apos;] = range(1, ordering.shape[0]+1)</span><br><span class="line">    ordering = ordering[&apos;ordering&apos;].to_dict()</span><br><span class="line">    </span><br><span class="line">    for cat, o in ordering.items():</span><br><span class="line">        frame.loc[frame[feature] == cat, feature+&apos;_E&apos;] = o</span><br><span class="line">    </span><br><span class="line">qual_encoded = []</span><br><span class="line">for q in qualitative:  </span><br><span class="line">    encode(train, q)</span><br><span class="line">    qual_encoded.append(q+&apos;_E&apos;)</span><br><span class="line">print(qual_encoded)</span><br><span class="line"></span><br><span class="line"># choose raws of having missing data</span><br><span class="line">missing_data = all_df.isnull().sum()</span><br><span class="line">missing_data = missing_data[missing_data&gt;0]</span><br><span class="line">ids = all_df[missing_data.index].isnull()</span><br><span class="line"># index (0), columns (1)</span><br><span class="line">all_df.loc[ids[ids.any(axis=1)].index][missing_data.index]</span><br><span class="line"></span><br><span class="line"># nan still nan</span><br><span class="line">train.loc[1379,&apos;Electrical_E&apos;]</span><br><span class="line"></span><br><span class="line">#corr computing</span><br><span class="line">def spearman(frame, features):</span><br><span class="line">    spr = pd.DataFrame()</span><br><span class="line">    spr[&apos;feature&apos;] = features</span><br><span class="line">    #Signature: a.corr(other, method=&apos;pearson&apos;, min_periods=None)</span><br><span class="line">    #Docstring:</span><br><span class="line">    #Compute correlation with `other` Series, excluding missing values</span><br><span class="line">    # 计算特征和 SalePrice的 斯皮尔曼 相关系数</span><br><span class="line">    spr[&apos;spearman&apos;] = [frame[f].corr(frame[&apos;SalePrice&apos;], &apos;spearman&apos;) for f in features]</span><br><span class="line">    spr = spr.sort_values(&apos;spearman&apos;)</span><br><span class="line">    plt.figure(figsize=(6, 0.25*len(features))) # width, height</span><br><span class="line">    sns.barplot(data=spr, y=&apos;feature&apos;, x=&apos;spearman&apos;, orient=&apos;h&apos;)</span><br><span class="line">    </span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">spearman(train, features)</span><br><span class="line"># OverallQual Neighborhood GrLiveArea have bing influence on price</span><br><span class="line"></span><br><span class="line">#corr between vars</span><br><span class="line">plt.figure(1)</span><br><span class="line">corr = train[quantitative+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(2)</span><br><span class="line">corr = train[qual_encoded+[&apos;SalePrice&apos;]].corr()</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line">plt.figure(3)</span><br><span class="line"># [31,27]</span><br><span class="line">corr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded)+1]), index=quantitative+[&apos;SalePrice&apos;], columns=qual_encoded+[&apos;SalePrice&apos;])</span><br><span class="line">for q1 in quantitative+[&apos;SalePrice&apos;]:</span><br><span class="line">    for q2 in qual_encoded+[&apos;SalePrice&apos;]:</span><br><span class="line">        corr.loc[q1, q2] = train[q1].corr(train[q2])</span><br><span class="line">sns.heatmap(corr)</span><br><span class="line"></span><br><span class="line">#Pairplots</span><br><span class="line">def pairplot(x, y, **kwargs):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ts = pd.DataFrame(&#123;&apos;time&apos;: x, &apos;val&apos;: y&#125;)</span><br><span class="line">    ts = ts.groupby(&apos;time&apos;).mean()</span><br><span class="line">    ts.plot(ax=ax)</span><br><span class="line">    plt.xticks(rotation=90)</span><br><span class="line">    </span><br><span class="line">f = pd.melt(train, id_vars=[&apos;SalePrice&apos;], value_vars=quantitative+qual_encoded)</span><br><span class="line">g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False, size=5)</span><br><span class="line">g = g.map(pairplot, &quot;value&quot;, &quot;SalePrice&quot;)</span><br><span class="line"></span><br><span class="line">#price departing</span><br><span class="line">a = train[&apos;SalePrice&apos;]</span><br><span class="line">a.plot.hist()</span><br><span class="line"></span><br><span class="line">features = quantitative</span><br><span class="line"></span><br><span class="line">standard = train[train[&apos;SalePrice&apos;] &lt; np.log(200000)]</span><br><span class="line">pricey = train[train[&apos;SalePrice&apos;] &gt;= np.log(200000)]</span><br><span class="line"></span><br><span class="line">diff = pd.DataFrame()</span><br><span class="line">diff[&apos;feature&apos;] = features</span><br><span class="line">diff[&apos;difference&apos;] = [(pricey[f].fillna(0.).mean() - standard[f].fillna(0.).mean())/(standard[f].fillna(0.).mean())</span><br><span class="line">                      for f in features]</span><br><span class="line"></span><br><span class="line">sns.barplot(data=diff, x=&apos;feature&apos;, y=&apos;difference&apos;)</span><br><span class="line">x=plt.xticks(rotation=90)</span><br><span class="line"></span><br><span class="line">#classfing</span><br><span class="line">features = quantitative + qual_encoded</span><br><span class="line">model = TSNE(n_components=2, random_state=0, perplexity=50)</span><br><span class="line">X = train[features].fillna(0.).values</span><br><span class="line">tsne = model.fit_transform(X)</span><br><span class="line"></span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line">pca = PCA(n_components=30)</span><br><span class="line">pca.fit(s)</span><br><span class="line">pc = pca.transform(s)</span><br><span class="line">kmeans = KMeans(n_clusters=5)</span><br><span class="line">kmeans.fit(pc)</span><br><span class="line"></span><br><span class="line">fr = pd.DataFrame(&#123;&apos;tsne1&apos;: tsne[:,0], &apos;tsne2&apos;: tsne[:, 1], &apos;cluster&apos;: kmeans.labels_&#125;)</span><br><span class="line">sns.lmplot(data=fr, x=&apos;tsne1&apos;, y=&apos;tsne2&apos;, hue=&apos;cluster&apos;, fit_reg=False)</span><br><span class="line">print(np.sum(pca.explained_variance_ratio_))</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">model</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import seaborn as sns</span><br><span class="line">from scipy import stats</span><br><span class="line">from scipy.stats import skew</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import matplotlib</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/train.csv&quot;)</span><br><span class="line">test_df = pd.read_csv(&quot;F:/cs/python/code/houseprice/all/test.csv&quot;)</span><br><span class="line"></span><br><span class="line">#feature engineering</span><br><span class="line">all_df = pd.concat((train_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;], test_df.loc[:,&apos;MSSubClass&apos;:&apos;SaleCondition&apos;]), axis=0,ignore_index=True)</span><br><span class="line">all_df[&apos;MSSubClass&apos;] = all_df[&apos;MSSubClass&apos;].astype(str)</span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#dealing missing data</span><br><span class="line">missing = all_df.isnull().sum()</span><br><span class="line">missing.sort_values(inplace=True,ascending=False)</span><br><span class="line">missing = missing[missing &gt; 0]</span><br><span class="line"></span><br><span class="line">#missing 1 replaced with average</span><br><span class="line">all_df = all_df.drop(missing[missing&gt;1].index,1)</span><br><span class="line"></span><br><span class="line">all_df.isnull().sum()[all_df.isnull().sum()&gt;0]</span><br><span class="line"></span><br><span class="line">#dealing log(GrLivArea、1stFlrSF、2ndFlrSF、TotalBsmtSF、LotArea、KitchenAbvGr、GarageArea )</span><br><span class="line">logfeatures = [&apos;GrLivArea&apos;,&apos;1stFlrSF&apos;,&apos;2ndFlrSF&apos;,&apos;TotalBsmtSF&apos;,&apos;LotArea&apos;,&apos;KitchenAbvGr&apos;,&apos;GarageArea&apos;]</span><br><span class="line"></span><br><span class="line">for logfeature in logfeatures:</span><br><span class="line">    all_df[logfeature] = np.log1p(all_df[logfeature].values)</span><br><span class="line"></span><br><span class="line">#dealing boolean var</span><br><span class="line">all_df[&apos;HasBasement&apos;] = all_df[&apos;TotalBsmtSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasGarage&apos;] = all_df[&apos;GarageArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;Has2ndFloor&apos;] = all_df[&apos;2ndFlrSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasWoodDeck&apos;] = all_df[&apos;WoodDeckSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPorch&apos;] = all_df[&apos;OpenPorchSF&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;HasPool&apos;] = all_df[&apos;PoolArea&apos;].apply(lambda x: 1 if x &gt; 0 else 0)</span><br><span class="line">all_df[&apos;IsNew&apos;] = all_df[&apos;YearBuilt&apos;].apply(lambda x: 1 if x &gt; 2000 else 0)</span><br><span class="line"></span><br><span class="line">quantitative = [f for f in all_df.columns if all_df.dtypes[f] != &apos;object&apos;]</span><br><span class="line">qualitative = [f for f in all_df.columns if all_df.dtypes[f] == &apos;object&apos;]</span><br><span class="line"></span><br><span class="line">#encode quanlity</span><br><span class="line">all_dummy_df = pd.get_dummies(all_df)</span><br><span class="line"></span><br><span class="line">#standize var</span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">mean_cols = all_dummy_df.mean()</span><br><span class="line">all_dummy_df = all_dummy_df.fillna(mean_cols)</span><br><span class="line"></span><br><span class="line">all_dummy_df.isnull().sum().sum()</span><br><span class="line"></span><br><span class="line">X = all_dummy_df[quantitative]</span><br><span class="line">std = StandardScaler()</span><br><span class="line">s = std.fit_transform(X)</span><br><span class="line"></span><br><span class="line">all_dummy_df[quantitative] = s</span><br><span class="line"></span><br><span class="line">dummy_train_df = all_dummy_df.loc[train_df.index]</span><br><span class="line">dummy_test_df = all_dummy_df.loc[test_df.index]</span><br><span class="line"></span><br><span class="line">y_train = np.log(train_df.SalePrice)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#model predicting</span><br><span class="line">#ridge regression</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">y_train.values</span><br><span class="line"></span><br><span class="line">def rmse_cv(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, dummy_train_df, y_train.values, scoring=&quot;neg_mean_squared_error&quot;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line">alphas = np.logspace(-3, 2, 50)</span><br><span class="line">cv_ridge = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Ridge(alpha = alpha)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_ridge.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">cv_ridge = pd.Series(cv_ridge, index = alphas)</span><br><span class="line">cv_ridge.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;)</span><br><span class="line"></span><br><span class="line">#ridge trace picture</span><br><span class="line"># matplotlib.rcParams[&apos;figure.figsize&apos;] = (12.0, 12.0)</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line"># ax.set_color_cycle([&apos;b&apos;, &apos;r&apos;, &apos;g&apos;, &apos;c&apos;, &apos;k&apos;, &apos;y&apos;, &apos;m&apos;])</span><br><span class="line"></span><br><span class="line">ax.plot(alphas, coefs)</span><br><span class="line">ax.set_xscale(&apos;log&apos;)</span><br><span class="line">ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span><br><span class="line">plt.xlabel(&apos;alpha&apos;)</span><br><span class="line">plt.ylabel(&apos;weights&apos;)</span><br><span class="line">plt.title(&apos;Ridge coefficients as a function of the regularization&apos;)</span><br><span class="line">plt.axis(&apos;tight&apos;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#lesso :can choose some of feature</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line"></span><br><span class="line"># alphas = np.logspace(-3, 2, 50)</span><br><span class="line"># alphas = [1, 0.1, 0.001, 0.0005]</span><br><span class="line">alphas = np.logspace(-4, -2, 100)</span><br><span class="line">cv_lasso = []</span><br><span class="line">coefs = []</span><br><span class="line">for alpha in alphas:</span><br><span class="line">    model = Lasso(alpha = alpha,max_iter=5000)</span><br><span class="line">    model.fit(dummy_train_df,y_train)</span><br><span class="line">    cv_lasso.append(rmse_cv(model).mean())</span><br><span class="line">    coefs.append(model.coef_)</span><br><span class="line"></span><br><span class="line">cv_lasso = pd.Series(cv_lasso, index = alphas)</span><br><span class="line">cv_lasso.plot(title = &quot;Validation - Just Do It&quot;)</span><br><span class="line">plt.xlabel(&quot;alpha&quot;)</span><br><span class="line">plt.ylabel(&quot;rmse&quot;)</span><br><span class="line"># plt.plot(alphas, cv_ridge)</span><br><span class="line"># plt.title(&quot;Alpha vs CV Error&quot;</span><br><span class="line"></span><br><span class="line">print(cv_lasso.min(), cv_lasso.argmin())</span><br><span class="line"></span><br><span class="line">model = Lasso(alpha = 0.00058,max_iter=5000)</span><br><span class="line">model.fit(dummy_train_df,y_train)</span><br><span class="line">Lasso(alpha=0.00058, copy_X=True, fit_intercept=True, max_iter=5000,</span><br><span class="line">   normalize=False, positive=False, precompute=False, random_state=None,</span><br><span class="line">   selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)</span><br><span class="line">coef = pd.Series(model.coef_, index = dummy_train_df.columns)</span><br><span class="line">print(&quot;Lasso picked &quot; + str(sum(coef != 0)) + &quot; variables and eliminated the other &quot; +  str(sum(coef == 0)) + &quot; variables&quot;)</span><br><span class="line"></span><br><span class="line">imp_coef = pd.concat([coef.sort_values().head(10),</span><br><span class="line">                     coef.sort_values().tail(10)])</span><br><span class="line">matplotlib.rcParams[&apos;figure.figsize&apos;] = (8.0, 10.0)</span><br><span class="line">imp_coef.plot(kind = &quot;barh&quot;)</span><br><span class="line">plt.title(&quot;Coefficients in the Lasso Model&quot;)</span><br><span class="line"></span><br><span class="line">#Elastic Net :connect with lasso and ridge</span><br><span class="line"></span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=5000)</span><br><span class="line">elastic.fit(dummy_train_df, y_train)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=5000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line">rmse_cv(elastic).mean()</span><br><span class="line"></span><br><span class="line">#feature engineering 2 (another methon)</span><br><span class="line">import utils</span><br><span class="line">train_df_munged,label_df,test_df_munged = utils.feature_engineering()</span><br><span class="line"></span><br><span class="line">test_df = pd.read_csv(&apos;../input/test.csv&apos;)</span><br><span class="line">from sklearn.metrics import mean_squared_error,make_scorer</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"># 定义自己的score函数</span><br><span class="line">def my_custom_loss_func(ground_truth, predictions):</span><br><span class="line">    return np.sqrt(mean_squared_error(np.exp(ground_truth), np.exp(predictions)))</span><br><span class="line"></span><br><span class="line">my_loss_func  = make_scorer(my_custom_loss_func, greater_is_better=False)</span><br><span class="line">def rmse_cv2(model):</span><br><span class="line">    rmse= np.sqrt(-cross_val_score(model, train_df_munged, label_df.SalePrice, scoring=&apos;neg_mean_squared_error&apos;, cv = 5))</span><br><span class="line">    return(rmse)</span><br><span class="line"></span><br><span class="line">#ridge2</span><br><span class="line">from sklearn.linear_model import RidgeCV,Ridge</span><br><span class="line">alphas = np.logspace(-3, 2, 100)</span><br><span class="line">model_ridge = RidgeCV(alphas=alphas).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_ridge = model_ridge.predict(train_df_munged)</span><br><span class="line">print(&quot;Ridge score on training set: &quot;, model_ridge.score(train_df_munged,label_df.SalePrice))</span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_ridge).mean())</span><br><span class="line"></span><br><span class="line">#lasso2</span><br><span class="line">from sklearn.linear_model import Lasso,LassoCV</span><br><span class="line">model_lasso = LassoCV(eps=0.0001,max_iter=20000).fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_lasso = model_lasso.predict(train_df_munged)</span><br><span class="line">print(&quot;Lasso score on training set: &quot;, model_lasso.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_lasso).mean())</span><br><span class="line"></span><br><span class="line">#Elastic Net</span><br><span class="line">from sklearn.linear_model import ElasticNet,ElasticNetCV</span><br><span class="line">model_elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], </span><br><span class="line">                                    alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75], cv=5,max_iter=10000)</span><br><span class="line">model_elastic.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line">ElasticNetCV(alphas=[0.001, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],</span><br><span class="line">       copy_X=True, cv=5, eps=0.001, fit_intercept=True,</span><br><span class="line">       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=10000,</span><br><span class="line">       n_alphas=100, n_jobs=1, normalize=False, positive=False,</span><br><span class="line">       precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;,</span><br><span class="line">       tol=0.0001, verbose=0)</span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_elastic = model_elastic.predict(train_df_munged)</span><br><span class="line">print(&quot;Elastic score on training set: &quot;, model_elastic.score(train_df_munged,label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_elastic).mean())</span><br><span class="line"></span><br><span class="line">#XGBoost</span><br><span class="line"># XGBoost -- I did some &quot;manual&quot; cross-validation here but should really find</span><br><span class="line"># these hyperparameters using CV. ;-)</span><br><span class="line"></span><br><span class="line">import xgboost as xgb</span><br><span class="line"></span><br><span class="line">model_xgb = xgb.XGBRegressor(</span><br><span class="line">                 colsample_bytree=0.2,</span><br><span class="line">                 gamma=0.0,</span><br><span class="line">                 learning_rate=0.05,</span><br><span class="line">                 max_depth=6,</span><br><span class="line">                 min_child_weight=1.5,</span><br><span class="line">                 n_estimators=7200,                                                                  </span><br><span class="line">                 reg_alpha=0.9,</span><br><span class="line">                 reg_lambda=0.6,</span><br><span class="line">                 subsample=0.2,</span><br><span class="line">                 seed=42,</span><br><span class="line">                 silent=1)</span><br><span class="line"></span><br><span class="line">model_xgb.fit(train_df_munged, label_df.SalePrice)</span><br><span class="line"></span><br><span class="line"># Run prediction on training set to get a rough idea of how well it does.</span><br><span class="line">pred_Y_xgb = model_xgb.predict(train_df_munged)</span><br><span class="line">print(&quot;XGBoost score on training set: &quot;, model_xgb.score(train_df_munged,label_df.SalePrice)) # 过拟合</span><br><span class="line"></span><br><span class="line">print(&quot;cross_validation: &quot;,rmse_cv2(model_xgb).mean())</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(model_xgb.predict(train_df_munged),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#Ensemble</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"># Create linear regression object</span><br><span class="line">regr = LinearRegression()</span><br><span class="line">train_x = np.concatenate(</span><br><span class="line">    (pred_Y_lasso[np.newaxis, :].T,pred_Y_ridge[np.newaxis, :].T,</span><br><span class="line">     pred_Y_elastic[np.newaxis, :].T,pred_Y_xgb[np.newaxis, :].T), axis=1)</span><br><span class="line">regr.fit(train_x,label_df.SalePrice)</span><br><span class="line">LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</span><br><span class="line">regr.coef_</span><br><span class="line"></span><br><span class="line">print(&quot;Ensemble score on training set: &quot;, regr.score(train_x,label_df.SalePrice)) # overfitting</span><br><span class="line"></span><br><span class="line">print(&quot;score: &quot;,mean_squared_error(regr.predict(train_x),label_df.SalePrice))</span><br><span class="line"></span><br><span class="line">#submit</span><br><span class="line">model_lasso.predict(test_df_munged)[np.newaxis, :].T</span><br><span class="line"></span><br><span class="line">test_x = np.concatenate(</span><br><span class="line">(model_lasso.predict(test_df_munged)[np.newaxis, :].T,model_ridge.predict(test_df_munged)[np.newaxis, :].T,</span><br><span class="line">                           model_elastic.predict(test_df_munged)[np.newaxis, :].T, model_xgb.predict(test_df_munged)[np.newaxis, :].T)</span><br><span class="line">        ,axis=1)</span><br><span class="line">y_final = regr.predict(test_x)</span><br><span class="line">y_final</span><br><span class="line"></span><br><span class="line">submission_df = pd.DataFrame(data= &#123;&apos;Id&apos; : test_df.Id, &apos;SalePrice&apos;: np.exp(y_final)&#125;)</span><br><span class="line">submission_df.to_csv(&quot;bag-4.csv&quot;,index=False) # conceal index</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-12-01T16:00:00.000Z"><a href="/55836/">2017-12-02</a></time>
        
  
    <h1 class="title"><a href="/55836/">Python访问数据库</a></h1>
  

    </header>

    <div class="entry">
      
        <p>程序运行的时候，数据都是在内存中的。当程序终止的时候，通常都需要将数据保存到磁盘上，无论是保存到本地磁盘，还是通过网络保存到服务器上，最终都会将数据写入磁盘文件。</p>
<p>而如何定义数据的存储格式就是一个大问题。如果我们自己来定义存储格式，比如保存一个班级所有学生的成绩单：</p>
<p>名字    成绩<br>Michael    99<br>Bob        85<br>Bart    59<br>Lisa    87<br>你可以用一个文本文件保存，一行保存一个学生，用,隔开：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Michael,99</span><br><span class="line">Bob,85</span><br><span class="line">Bart,59</span><br><span class="line">Lisa,87</span><br></pre></td></tr></table></figure></p>
<p>你还可以用JSON格式保存，也是文本文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Michael&quot;,&quot;score&quot;:99&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Bob&quot;,&quot;score&quot;:85&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Bart&quot;,&quot;score&quot;:59&#125;,</span><br><span class="line">    &#123;&quot;name&quot;:&quot;Lisa&quot;,&quot;score&quot;:87&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<p>你还可以定义各种保存格式，但是问题来了：</p>
<p>存储和读取需要自己实现，JSON还是标准，自己定义的格式就各式各样了；</p>
<p>不能做快速查询，只有把数据全部读到内存中才能自己遍历，但有时候数据的大小远远超过了内存（比如蓝光电影，40GB的数据），根本无法全部读入内存。</p>
<p>为了便于程序保存和读取数据，而且，能直接通过条件快速查询到指定的数据，就出现了数据库（Database）这种专门用于集中存储和查询的软件。</p>
<p>数据库软件诞生的历史非常久远，早在1950年数据库就诞生了。经历了网状数据库，层次数据库，我们现在广泛使用的关系数据库是20世纪70年代基于关系模型的基础上诞生的。</p>
<p>关系模型有一套复杂的数学理论，但是从概念上是十分容易理解的。举个学校的例子：</p>
<p>假设某个XX省YY市ZZ县第一实验小学有3个年级，要表示出这3个年级，可以在Excel中用一个表格画出来</p>
<p>每个年级又有若干个班级，要把所有班级表示出来，可以在Excel中再画一个表格</p>
<p>这两个表格有个映射关系，就是根据Grade_ID可以在班级表中查找到对应的所有班级</p>
<p>也就是Grade表的每一行对应Class表的多行，在关系数据库中，这种基于表（Table）的一对多的关系就是关系数据库的基础。</p>
<p>根据某个年级的ID就可以查找所有班级的行，这种查询语句在关系数据库中称为SQL语句，可以写成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM classes WHERE grade_id = &apos;1&apos;;</span><br></pre></td></tr></table></figure></p>
<p>结果也是一个表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">grade_id | class_id | name</span><br><span class="line"></span><br><span class="line">1        | 11       | 一年级一班</span><br><span class="line"></span><br><span class="line">1        | 12       | 一年级二班</span><br><span class="line"></span><br><span class="line">1        | 13       | 一年级三班</span><br></pre></td></tr></table></figure>
<p>类似的，Class表的一行记录又可以关联到Student表的多行记录</p>
<h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><p>也许还听说过NoSQL数据库，很多NoSQL宣传其速度和规模远远超过关系数据库，所以很多同学觉得有了NoSQL是否就不需要SQL了呢？千万不要被忽悠了，连SQL都不明白怎么可能搞明白NoSQL呢？</p>
<h3 id="数据库类别"><a href="#数据库类别" class="headerlink" title="数据库类别"></a>数据库类别</h3><p>既然我们要使用关系数据库，就必须选择一个关系数据库。目前广泛使用的关系数据库也就这么几种：</p>
<p>付费的商用数据库：</p>
<p>Oracle，典型的高富帅；</p>
<p>SQL Server，微软自家产品，Windows定制专款；</p>
<p>DB2，IBM的产品，听起来挺高端；</p>
<p>Sybase，曾经跟微软是好基友，后来关系破裂，现在家境惨淡。</p>
<p>这些数据库都是不开源而且付费的，最大的好处是花了钱出了问题可以找厂家解决，不过在Web的世界里，常常需要部署成千上万的数据库服务器，当然不能把大把大把的银子扔给厂家，所以，无论是Google、Facebook，还是国内的BAT，无一例外都选择了免费的开源数据库：</p>
<p>MySQL，大家都在用，一般错不了；</p>
<p>PostgreSQL，学术气息有点重，其实挺不错，但知名度没有MySQL高；</p>
<p>sqlite，嵌入式数据库，适合桌面和移动应用。</p>
<p>作为Python开发工程师，选择哪个免费数据库呢？当然是MySQL。因为MySQL普及率最高，出了错，可以很容易找到解决方法。而且，围绕MySQL有一大堆监控和运维的工具，安装和使用很方便。</p>
<p>从MySQL官方网站下载并安装MySQL Community Server 5.6，这个版本是免费的，其他高级版本是要收钱的。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/55836/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>

    <article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-11-27T16:00:00.000Z"><a href="/53901/">2017-11-28</a></time>
        
  
    <h1 class="title"><a href="/53901/">Python电子邮件</a></h1>
  

    </header>

    <div class="entry">
      
        <p>Email的历史比Web还要久远，直到现在，Email也是互联网上应用非常广泛的服务。</p>
<p>几乎所有的编程语言都支持发送和接收电子邮件，但是，先等等，在我们开始编写代码之前，有必要搞清楚电子邮件是如何在互联网上运作的。</p>
<p>我们来看看传统邮件是如何运作的。假设你现在在北京，要给一个香港的朋友发一封信，怎么做呢？</p>
<p>首先你得写好信，装进信封，写上地址，贴上邮票，然后就近找个邮局，把信仍进去。</p>
<p>信件会从就近的小邮局转运到大邮局，再从大邮局往别的城市发，比如先发到天津，再走海运到达香港，也可能走京九线到香港，但是你不用关心具体路线，你只需要知道一件事，就是信件走得很慢，至少要几天时间。</p>
<p>信件到达香港的某个邮局，也不会直接送到朋友的家里，因为邮局的叔叔是很聪明的，他怕你的朋友不在家，一趟一趟地白跑，所以，信件会投递到你的朋友的邮箱里，邮箱可能在公寓的一层，或者家门口，直到你的朋友回家的时候检查邮箱，发现信件后，就可以取到邮件了。</p>
<p>电子邮件的流程基本上也是按上面的方式运作的，只不过速度不是按天算，而是按秒算。</p>
<p>现在我们回到电子邮件，假设我们自己的电子邮件地址是<a href="mailto:me@163.com" target="_blank" rel="noopener">me@163.com</a>，对方的电子邮件地址是<a href="mailto:friend@sina.com" target="_blank" rel="noopener">friend@sina.com</a>（注意地址都是虚构的哈），现在我们用Outlook或者Foxmail之类的软件写好邮件，填上对方的Email地址，点“发送”，电子邮件就发出去了。这些电子邮件软件被称为MUA：Mail User Agent——邮件用户代理。</p>
<p>Email从MUA发出去，不是直接到达对方电脑，而是发到MTA：Mail Transfer Agent——邮件传输代理，就是那些Email服务提供商，比如网易、新浪等等。由于我们自己的电子邮件是163.com，所以，Email首先被投递到网易提供的MTA，再由网易的MTA发到对方服务商，也就是新浪的MTA。这个过程中间可能还会经过别的MTA，但是我们不关心具体路线，我们只关心速度。</p>
<p>Email到达新浪的MTA后，由于对方使用的是@sina.com的邮箱，因此，新浪的MTA会把Email投递到邮件的最终目的地MDA：Mail Delivery Agent——邮件投递代理。Email到达MDA后，就静静地躺在新浪的某个服务器上，存放在某个文件或特殊的数据库里，我们将这个长期保存邮件的地方称之为电子邮箱。</p>
<p>同普通邮件类似，Email不会直接到达对方的电脑，因为对方电脑不一定开机，开机也不一定联网。对方要取到邮件，必须通过MUA从MDA上把邮件取到自己的电脑上。</p>
<p>所以，一封电子邮件的旅程就是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">发件人 -&gt; MUA -&gt; MTA -&gt; MTA -&gt; 若干个MTA -&gt; MDA &lt;- MUA &lt;- 收件人</span><br></pre></td></tr></table></figure></p>
<p>有了上述基本概念，要编写程序来发送和接收邮件，本质上就是：</p>
<ol>
<li><p>编写MUA把邮件发到MTA；</p>
</li>
<li><p>编写MUA从MDA上收邮件。</p>
</li>
</ol>
<p>发邮件时，MUA和MTA使用的协议就是<strong>SMTP</strong>：Simple Mail Transfer Protocol，后面的MTA到另一个MTA也是用SMTP协议。</p>
<p>收邮件时，MUA和MDA使用的协议有两种：<strong>POP</strong>：Post Office Protocol，目前版本是3，俗称POP3；<strong>IMAP</strong>：Internet Message Access Protocol，目前版本是4，优点是不但能取邮件，还可以直接操作MDA上存储的邮件，比如从收件箱移到垃圾箱，等等。</p>
<p>邮件客户端软件在发邮件时，会让你先配置SMTP服务器，也就是你要发到哪个MTA上。假设你正在使用163的邮箱，你就不能直接发到新浪的MTA上，因为它只服务新浪的用户，所以，你得填163提供的SMTP服务器地址：smtp.163.com，为了证明你是163的用户，SMTP服务器还要求你填写邮箱地址和邮箱口令，这样，MUA才能正常地把Email通过SMTP协议发送到MTA。</p>
<p>类似的，从MDA收邮件时，MDA服务器也要求验证你的邮箱口令，确保不会有人冒充你收取你的邮件，所以，Outlook之类的邮件客户端会要求你填写POP3或IMAP服务器地址、邮箱地址和口令，这样，MUA才能顺利地通过POP或IMAP协议从MDA取到邮件。</p>
<p>在使用Python收发邮件前，请先准备好至少两个电子邮件，如<a href="mailto:xxx@163.com" target="_blank" rel="noopener">xxx@163.com</a>，<a href="mailto:xxx@sina.com" target="_blank" rel="noopener">xxx@sina.com</a>，<a href="mailto:xxx@qq.com" target="_blank" rel="noopener">xxx@qq.com</a>等，注意两个邮箱不要用同一家邮件服务商。</p>
<p>最后特别注意，目前大多数邮件服务商都需要手动打开SMTP发信和POP收信的功能，否则只允许在网页登录</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/53901/#more" class="more-link">阅读全文</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div>
 
<nav id="pagination">
  
  
    <a href="/page/2/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav>
</div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">24</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 13.33px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18.33px;">Machine Learning 课程笔记</a> <a href="/tags/hexo/" style="font-size: 11.67px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 11.67px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16.67px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 13.33px;">模型</a> <a href="/tags/爬虫/" style="font-size: 11.67px;">爬虫</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 11.67px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2018 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>