<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Andrew Ng Machine Learning (5) Neural Network Part2 | RP&#39;s Blog</title>
  <meta name="author" content="LRP">
  
  <meta name="description" content="此文是斯坦福大学 Andrew Ng 所开设的 Coursera 课程：Machine Learning 的课程笔记。课程网址：https://www.coursera.org/learn/machine-learning/home/welcome">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Andrew Ng Machine Learning (5) Neural Network Part2"/>
  <meta property="og:site_name" content="RP&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="alternate" href="/atom.xml" title="RP&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <!-- wumiiVerification -->
  <meta name="wumiiVerification" content="fb50a101-84fe-4ca2-91a7-ae8cf792978b" />
  <meta name="wumiiVerification" content="d73b5866-c390-4156-a4dd-51b526b5335e" />
  <!-- favicon -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">

</head>

<body>
  <header id="header"><div class= "header-content inner">
	<div class = "alignleft col-one">
		
			<div class='avatar'>
				<img src = "/img/default/avatar.jpg">
              </div>
		
		<div class="header-div">
		    <h1><a href="/">RP&#39;s Blog</a></h1>
		    <h2><a href="/">学习总结  思考感悟</a></h2>
		</div>
	</div>
	<div class = "alignright col-two">
		
	</div>
	<div class="clearfix"></div>
</div>

<div class= "header-nav">
	<div class='header-nav-content inner'>
		<div id="main-nav" class="alignleft">
		    		
		    		  <a href="/"><i class="fa fa-home"></i>首页</a>
		    		
		    		  <a href="/archives"><i class="fa fa-archive"></i>归档</a>
		    		
		</div>
		<div id="sub-nav" class="alignright">
		    
		      <a href="/atom.xml"><i class="fa fa-rss"></i>订阅</a>
		    
		      <a href="/about"><i class="fa fa-user"></i>关于</a>
		    
		</div>
	</div>
	<div class="clearfix"></div>
</div>
</header>
    <div id="content" class="inner">
      <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
        <div class="icon"></div>
        
        <time datetime="2017-08-29T16:00:00.000Z"><a href="/53070/">2017-08-30</a></time>
        
  
    <h1 class="title">Andrew Ng Machine Learning (5) Neural Network Part2</h1>
  

    </header>

    <div class="entry">
      
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Cost-Function"><span class="toc-text">1. Cost Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Backpropagation"><span class="toc-text">2. Backpropagation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Gradient-Checking"><span class="toc-text">3. Gradient Checking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Backpropagation-in-Practice"><span class="toc-text">4. Backpropagation in Practice</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Put-it-together"><span class="toc-text">5. Put it together</span></a></li></ol>
    </div>

        <p>此文是斯坦福大学 Andrew Ng 所开设的 Coursera 课程：Machine Learning 的课程笔记。<br>课程网址：<br><a href="https://www.coursera.org/learn/machine-learning/home/welcome" target="_blank" rel="noopener">https://www.coursera.org/learn/machine-learning/home/welcome</a></p>
<a id="more"></a>
<hr>
<p>上一篇文章，介绍了<strong>前向传播(forward propagation)</strong>的过程，以及神经网络计算非线性问题的例子(XOR问题)</p>
<p>这一篇文章，开始介绍，如何来计算神经网络中各种参数的方法：<strong>后向传播(backward propagation)</strong></p>
<h3 id="1-Cost-Function"><a href="#1-Cost-Function" class="headerlink" title="1. Cost Function"></a>1. Cost Function</h3><p>为了拟合神经网络的各个参数，我们首先需要规定一些变量：<br><img src="https://i.imgur.com/GxSynvL.png" alt=""></p>
<p>不同分类问题：</p>
<p>若分为2类，其实用一个神经元作为输出层就可以了，用y=0和y=1区分；</p>
<p>多类问题，利用以前说过的，分为K类则最终的y∈R^K，例如分为三类的问题输出可选择为<img src="https://i.imgur.com/ariPfuP.png" alt=""></p>
<p>因为同样是分类问题，我们回想一下逻辑回归的cost function，其实神经网络的相同，只不过是对于分为K类问题的版本而已：<br><img src="https://i.imgur.com/9XJbSNE.png" alt=""></p>
<p>是不是……太复杂了，如果用 cost function 计算梯度之后梯度直接梯度下降法来计算神经网络参数，明显不如接下来介绍的这种方法简单快捷。</p>
<h3 id="2-Backpropagation"><a href="#2-Backpropagation" class="headerlink" title="2. Backpropagation"></a>2. Backpropagation</h3><p><strong>后向传播</strong>，是神经网络中用于替代直接计算梯度下降法，来设定各层参数的方法。方法的精髓在于，<strong>训练网络时先根据初始化的参数（一般是随机设定），计算得到最后一层（输出层）的输出，计算与实际网络输出之间的差，再根据当前层的差，反推出上一层的差，逐渐反推到第一层。每一层根据自身层的差，来逼近真实参数</strong>。</p>
<p>首先我们设定某l层的某j个神经元，与真实的神经元的值，两者的差距为<img src="https://i.imgur.com/Nc3lrrH.png" alt="">，the error of node j in layer l.</p>
<p>对于输出层的每个神经元来说，可以直接计算：<img src="https://i.imgur.com/3Ds9vuD.png" alt="">，向量化表示为<img src="https://i.imgur.com/cgaxaK5.png" alt=""></p>
<p>对于其他层的每个神经元而言，就需要依靠上一层神经元的计算结果来反推，<strong>反推的过程可以视为原本 Forwardpropagation 过程中分散到各个下一层神经元的水流沿着同样的道路再次汇聚到上一层的神经元中</strong>：<img src="https://i.imgur.com/9XmWAoL.png" alt=""></p>
<p>对于g′(t)的计算，这里需要一点点小技巧：<br><img src="https://i.imgur.com/CqMnQoj.png" alt=""></p>
<p>推导过程见下：<br><img src="https://i.imgur.com/Or2ogvB.png" alt=""></p>
<p>不存在δ(1)，因为<strong>输入层没有误差</strong></p>
<p>我们首先不考虑正则化项（最小化各个系数<img src="https://i.imgur.com/AbSeYkS.png" alt="">，得到计算各层各个单元的误差项之和</p>
<p>因此，我们得到求出神经网络各层参数的方法：<br><img src="https://i.imgur.com/SKUhVtK.png" alt=""></p>
<h3 id="3-Gradient-Checking"><a href="#3-Gradient-Checking" class="headerlink" title="3. Gradient Checking"></a>3. Gradient Checking</h3><p>当我们需要验证求出的神经网络工作的对不对呢？可以使用 gradient checking，通过check梯度判断我们的code有没有问题</p>
<p>对于下面这个[θ−J(θ)]图，取θ点左右各一点(θ−ϵ)与(θ+ϵ)，则点θ的梯度近似等于<img src="https://i.imgur.com/xliVzIX.png" alt=""></p>
<p><img src="https://i.imgur.com/XvkBIeh.png" alt=""></p>
<p>对于神经网络中的情况，则有：<br><img src="https://i.imgur.com/SPV9RtR.png" alt=""></p>
<p>由于在backpropagation算法中我们一直能得到J(θ)的导数D（derivative），那么就可以将这个近似值与D进行比较</p>
<p><strong>Summary: </strong><br>(1) 在backpropagation中计算出J(θ)对θ的导数D并组成vector（Dvec） </p>
<p>(2) 用numerical gradient checking方法计算大概的梯度<img src="https://i.imgur.com/xa4LZR9.png" alt=""></p>
<p>(3) 看是否得到相同（or相近）的结果 </p>
<p>(4) <strong>（非常重要）</strong>停止checking，只用 backpropagation 进行神经网络学习，否则会非常非常慢</p>
<h3 id="4-Backpropagation-in-Practice"><a href="#4-Backpropagation-in-Practice" class="headerlink" title="4. Backpropagation in Practice"></a>4. Backpropagation in Practice</h3><p>这一节我们来看看实际 octave/MATLAB 编程中的一些技巧，例如对于神经网络如下：<br><img src="https://i.imgur.com/e2uWpzX.png" alt=""><br>当s1=10,s2=10时，则有θ(1)∈R10×11,θ(2)∈R10×11，一般来说，为了方便变形与传递参数，我们是将所有θ展开成一个完整的变量：<br>    thetaVec=[Theta1(:);Theta2(:);Theta3(:)] </p>
<p>再次展开的时候，例如重组为θ(1)时，取出其中前110个重组就好：<br>    Theta1=reshape(thetaVec(1:110),10,11)</p>
<p>如何初始化各层的参数呢？这同样是一个需要注意的地方：<strong>不能将各层的各个神经元的参数赋值为相同的数</strong>。</p>
<p>有兴趣的同学可以计算一下，这样神经网络的某一层内的所有神经元计算都变得相同，这样神经网络的非线性程度就降低了。<strong>一般来说，都是在(+ϵ,−ϵ)之间随机赋值</strong></p>
<p>我的神经网络需要有多少层呢？同样是个有趣的问题，一般来说，<strong>三层结构（仅仅一个隐藏层）</strong>已经足够来处理大部分非线性情况。如果分类效果不好，可以尝试使用更多的隐藏层，但需要保证每个隐藏层的神经元个数相同，层数越多就越慢，当然一般来说分类效果就更好</p>
<p>每层神经网络需要多少个神经元？能确定的只有输入层与输出层：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">No. of input units: Dimension of features</span><br><span class="line">No. output units: Number of classes</span><br><span class="line">Other units: who knows… usually the more the better</span><br></pre></td></tr></table></figure></p>
<h3 id="5-Put-it-together"><a href="#5-Put-it-together" class="headerlink" title="5. Put it together"></a>5. Put it together</h3><p>最终我们回顾一下神经网络的主要步骤： </p>
<p><strong>randomly initialize weights</strong></p>
<p><strong>(for 1 to m) forward-propagation</strong></p>
<p><strong>(for 1 to m) cost function</strong></p>
<p><strong>(for 1 to m) backward-propogation</strong></p>
<p><strong>gradient checking, then stop</strong></p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/机器学习/">机器学习</a>
  </div>

        
  <div class="tags">
    <a href="/tags/Machine-Learning-课程笔记/">Machine Learning 课程笔记</a>
  </div>

        
  <div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a><a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a></div>
  <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- 返回顶部 -->
<div id="toTop">
	<a href="#">▲</a>
	<a href="#footer">▼</a>
</div></div></div>
      <aside id="sidebar" class="alignright">
        
           <div class="search">
  <form action="/search/index.html" method="get" accept-charset="utf-8">
<!--     <input type="search" name="wd"results="0" placeholder="搜索">
    <input type="hidden" name="wd" value="site:paradoxallen.github.io"> -->
     <input type="text" id="search" class="st-default-search-input" placeholder="搜索" style="height: 100%" />
  </form>
</div> 
        
          
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人随笔/">个人随笔</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客开发/">博客开发</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/应用统计/">应用统计</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学基础/">数学基础</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程相关/">编程相关</a><span class="category-list-count">23</span></li></ul> 
</div>
 

        
          
<div class="widget tagcloud">
  <h3 class="title">标签</h3>
  <div class="entry">
    <a href="/tags/Excel/" style="font-size: 14px;">Excel</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/Machine-Learning/" style="font-size: 16px;">Machine Learning</a> <a href="/tags/Machine-Learning-课程笔记/" style="font-size: 18px;">Machine Learning 课程笔记</a> <a href="/tags/hexo/" style="font-size: 12px;">hexo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/博客/" style="font-size: 12px;">博客</a> <a href="/tags/可视化/" style="font-size: 10px;">可视化</a> <a href="/tags/大气科学/" style="font-size: 10px;">大气科学</a> <a href="/tags/数据类型/" style="font-size: 10px;">数据类型</a> <a href="/tags/机器学习/" style="font-size: 16px;">机器学习</a> <a href="/tags/概率论与数理统计/" style="font-size: 10px;">概率论与数理统计</a> <a href="/tags/模型/" style="font-size: 14px;">模型</a> <a href="/tags/目录/" style="font-size: 10px;">目录</a> <a href="/tags/算法/" style="font-size: 12px;">算法</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/统计/" style="font-size: 10px;">统计</a> <a href="/tags/编码/" style="font-size: 10px;">编码</a> <a href="/tags/高等数学/" style="font-size: 10px;">高等数学</a>
  </div>
</div>

        
          
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">4</span></li></ul>
  </div>

        
      </aside>
      <div class="clearfix"></div>
    </div>
  <footer id="footer"><div class="footer-content inner">
  <div class="alignleft">
  
    &copy; 2018 LRP
    
  </div>

  <!--
  <div class="alignright">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme
    <a href="https://github.com/pengloo53/Hexo-theme-light_cn">light_cn</a>
  </div>
  -->

  <!--
  <div>
    Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
  </div>
  -->
  
  <div class="clearfix"></div>
</div></footer>
  <script src="http://libs.baidu.com/jquery/2.1.1/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<!-- calendar widget -->


<!-- 百度统计 -->

	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?9acf0cedd48dc53be256ede5a98c2aaa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


<!-- fancybox -->

<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>